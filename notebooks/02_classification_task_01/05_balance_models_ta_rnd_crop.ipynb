{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f32ebf",
   "metadata": {
    "id": "d9f32ebf"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c92e86b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c92e86b3",
    "outputId": "e71a72b7-c55c-457f-9f45-29b574aaff1d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path['project'] : D:\\projects\\skin-lesion-classification\n",
      "path['images'] : D:\\projects\\skin-lesion-classification\\images\n",
      "path['models'] : D:\\projects\\skin-lesion-classification\\models\n",
      "path['expository'] : D:\\projects\\skin-lesion-classification\\expository\n",
      "path['literature'] : D:\\projects\\skin-lesion-classification\\literature\n",
      "path['notebooks'] : D:\\projects\\skin-lesion-classification\\notebooks\n",
      "path['presentation'] : D:\\projects\\skin-lesion-classification\\presentation\n",
      "path['scripts'] : D:\\projects\\skin-lesion-classification\\scripts\n",
      "path['streamlit'] : D:\\projects\\skin-lesion-classification\\streamlit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# If we're using Google Colab, we set the environment variable to point to the relevant folder in our Google Drive:\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.environ['SKIN_LESION_CLASSIFICATION'] = '/content/drive/MyDrive/Colab Notebooks/skin-lesion-classification'\n",
    "\n",
    "# Otherwise, we use the environment variable on our local system:\n",
    "project_environment_variable = \"SKIN_LESION_CLASSIFICATION\"\n",
    "\n",
    "# Path to the root directory of the project:\n",
    "project_path = Path(os.environ.get(project_environment_variable))\n",
    "\n",
    "# Relative path to /scripts (from where custom modules will be imported):\n",
    "scripts_path = project_path.joinpath(\"scripts\")\n",
    "\n",
    "# Add this path to sys.path so that Python will look there for modules:\n",
    "sys.path.append(str(scripts_path))\n",
    "\n",
    "# Now import path_step from our custom utils module to create a dictionary to all subdirectories in our root directory:\n",
    "from utils import path_setup\n",
    "path = path_setup.subfolders(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1af769c",
   "metadata": {
    "id": "e1af769c"
   },
   "source": [
    "<a id='model_setup'></a>\n",
    "# Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5f08207",
   "metadata": {
    "id": "f5f08207"
   },
   "outputs": [],
   "source": [
    "from typing import Type, Union      # For type hints\n",
    "from processing import process      # Custom module for processing metadata\n",
    "\n",
    "data_dir: Path = path[\"images\"]     # Path to directory containing metadata.csv file\n",
    "csv_filename: str = \"metadata.csv\"  # The filename\n",
    "\n",
    "tvr: int = 3              # Ratio of training set to validation set. See discussion below for explanation.\n",
    "seed: int = 0             # Random seed for parts of the process where randomness is called for.\n",
    "keep_first: bool = False  # If False, then, for each lesion, we choose a random image to assign to our training set.\n",
    "stratified: bool = True   # If True, we stratify classes so that the proportions remain as stable as possible after train/val split.\n",
    "                          # If False, the proportions will be roughly similar.\n",
    "\n",
    "to_classify: Union[list, dict] = [\"mel\",   # These are the lesion types we are interested in classifying.\n",
    "                                  \"bcc\",   # Any missing ones will be grouped together as the 0-label class: no need to write \"other\" here.\n",
    "                                  \"akiec\", # If 'other' is not desired, use restrict_to attribute above\n",
    "                                  \"nv\",]   # Can also be a dictionary, like { 'malignant' : ['mel', 'bcc'], 'benign' : ['nv', 'bkl']}\n",
    "\n",
    "train_one_img_per_lesion: Union[None, bool] = False\n",
    "\n",
    "val_expansion_factor: Union[None,int] = 3\n",
    "\n",
    "sample_size: Union[None, dict] = {\"mel\": 2000,     # Handling class imbalance by upsampling minority classes/downsampling majority classes\n",
    "                                  \"bcc\": 2000,     # Specify how many images of each lesion diagnosis we want in our training set.\n",
    "                                  \"akiec\": 2000,\n",
    "                                  \"nv\": 2000,\n",
    "                                  \"other\" : 2000,} # Could also leave out \"other\" here, and include e.g. \"df: 2000\" if we wanted to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e2538b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2e2538b",
    "outputId": "a4bcf415-5b81-490a-b255-8a46eab84848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded file 'D:\\projects\\skin-lesion-classification\\images\\metadata.csv'.\n",
      "- Inserted 'num_images' column in dataframe, to the right of 'lesion_id' column.\n",
      "- Inserted 'label' column in dataframe, to the right of 'dx' column: \n",
      "  {'bkl': 0, 'df': 0, 'vasc': 0, 'akiec': 1, 'bcc': 2, 'mel': 3, 'nv': 4}\n",
      "- Added 'set' column to dataframe, with values 't1', 'v1', 'ta', and 'va', to the right of 'localization' column.\n",
      "- Basic, overall dataframe (pre-train/test split): self.df\n",
      "- Balancing classes in training set.\n",
      "- Balanced training set (uses as many different images per lesion as possible): self.df_train\n",
      "- Expanding validation set: will combine 3 predictions into one, for each lesion in val set.\n",
      "- Expanded validation set (one image per lesion, repeated 3 times): self.df_val1\n",
      "- Expanded validation set (use up to 3 different images per lesion, if available): self.df_val_a\n",
      "- Small sample dataframes for code testing: self._df_train_code_test, self._df_val1_code_test, self._df_val_a_code_test\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the process class with attribute values as above.\n",
    "balance_ta = process(data_dir=data_dir,\n",
    "                  csv_filename=csv_filename,\n",
    "                  tvr=tvr,\n",
    "                  seed=seed,\n",
    "                  keep_first=keep_first,\n",
    "                  stratified=stratified,\n",
    "                  to_classify=to_classify,\n",
    "                  train_one_img_per_lesion=train_one_img_per_lesion,\n",
    "                  val_expansion_factor=val_expansion_factor,\n",
    "                  sample_size=sample_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a312c5d",
   "metadata": {
    "id": "7a312c5d"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose([\n",
    "transforms.RandomCrop((300, 300)),\n",
    "# transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "transforms.Resize((224,224)), # Resize images to fit ResNet input size\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet stats\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "812d42e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "812d42e8",
    "outputId": "ba6eaaf4-e4e6-4f5d-871c-7468864c42f6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Union, List, Callable\n",
    "import torchvision.models as models\n",
    "\n",
    "source: Union[process, pd.DataFrame] = balance_ta        # Processed data to be fed into model for training.\n",
    "                                                      # Must either be an instance of the process class, or a dataframe of the same format as source.df if source were an instance of the process class.\n",
    "model_dir: Path = path[\"models\"]                      # Path to directory where models/model info/model results are stored.\n",
    "\n",
    "transform: Union[None,\n",
    "                 transforms.Compose,\n",
    "                 List[Callable]] = transform     # Transform to be applied to images before feeding into neural network.\n",
    "\n",
    "filename_stem: Union[None, str] = \"rn18\"         # For saving model and related files. Default \"rn18\" (if ResNet model) or \"EffNet\" (if EfficientNet), or \"cnn\".\n",
    "filename_suffix: Union[None, str] = \"rndcrop\" # Something descriptive and unique for future reference. Default empty string \"\".\n",
    "\n",
    "# model: Union[None, models.ResNet, models.EfficientNet] = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT) # Pre-trained model. Default: ResNet18.\n",
    "model: Union[None, models.ResNet, models.EfficientNet] = models.resnet18(weights=\"ResNet18_Weights.DEFAULT\")\n",
    "unfreeze_last: Union[None, bool] = True\n",
    "# overwrite: Union[None, bool] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6549485",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6549485",
    "outputId": "7dfd8b51-7e23-4ba9-de6b-c0a40ef2c6c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New files will be created. \n",
      "Base filename: rn18_ta_bal_uflast_10e_rndcrop_01\n",
      "Attributes saved to file: D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_uflast_10e_rndcrop_01_attributes.json\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the resnet18 class with attribute values as above.\n",
    "from multiclass_models import cnn\n",
    "\n",
    "rn18_balance_ta = cnn(source=source,\n",
    "                    model_dir=model_dir,\n",
    "                    transform=transform,\n",
    "                    filename_stem=filename_stem,\n",
    "                    filename_suffix=filename_suffix,\n",
    "                    model=model,\n",
    "                    unfreeze_last=unfreeze_last,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "WqOT_GSELriP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WqOT_GSELriP",
    "outputId": "0a24a0d8-2a1b-4ca0-aebc-0ce8bbb964d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, running loss: 1.9465781450271606\n",
      "Batch: 10, running loss: 17.1575368642807\n",
      "Batch: 20, running loss: 31.424762725830078\n",
      "Batch: 30, running loss: 43.69475656747818\n",
      "Batch: 40, running loss: 56.3113357424736\n",
      "Batch: 50, running loss: 67.72473001480103\n",
      "Batch: 60, running loss: 78.468190908432\n",
      "Batch: 70, running loss: 88.24344402551651\n",
      "Batch: 80, running loss: 98.05416315793991\n",
      "Batch: 90, running loss: 107.93140667676926\n",
      "Batch: 100, running loss: 118.76514822244644\n",
      "Batch: 110, running loss: 129.4298613667488\n",
      "Batch: 120, running loss: 140.29228848218918\n",
      "Batch: 130, running loss: 150.32756447792053\n",
      "Batch: 140, running loss: 160.5912516117096\n",
      "Batch: 150, running loss: 169.9141914844513\n",
      "Batch: 160, running loss: 179.27331912517548\n",
      "Batch: 170, running loss: 189.30784785747528\n",
      "Batch: 180, running loss: 198.5714014172554\n",
      "Batch: 190, running loss: 207.40415370464325\n",
      "Batch: 200, running loss: 215.76420772075653\n",
      "Batch: 210, running loss: 224.59464305639267\n",
      "Batch: 220, running loss: 233.6562870144844\n",
      "Batch: 230, running loss: 242.28658068180084\n",
      "Batch: 240, running loss: 250.48435616493225\n",
      "Batch: 250, running loss: 259.08565843105316\n",
      "Batch: 260, running loss: 268.66253685951233\n",
      "Batch: 270, running loss: 276.33321273326874\n",
      "Batch: 280, running loss: 284.96099984645844\n",
      "Batch: 290, running loss: 293.47635185718536\n",
      "Batch: 300, running loss: 302.25987154245377\n",
      "Batch: 310, running loss: 311.0132944583893\n",
      "Epoch 0, train_loss: 0.9991463460861304\n",
      "Epoch 0, val1_loss: 1.156947471614165\n",
      "Epoch 0, val_a_loss: 1.153050551667217\n",
      "Epoch 1/10, Training Loss: 0.9991, Validation Loss 1: 1.1569, Validation Loss a: 1.1531\n",
      "Batch: 0, running loss: 0.8401488661766052\n",
      "Batch: 10, running loss: 9.41660338640213\n",
      "Batch: 20, running loss: 17.72041267156601\n",
      "Batch: 30, running loss: 27.050431072711945\n",
      "Batch: 40, running loss: 36.09408128261566\n",
      "Batch: 50, running loss: 44.33839970827103\n",
      "Batch: 60, running loss: 52.86574697494507\n",
      "Batch: 70, running loss: 61.178724229335785\n",
      "Batch: 80, running loss: 68.89390155673027\n",
      "Batch: 90, running loss: 76.75788775086403\n",
      "Batch: 100, running loss: 85.04164305329323\n",
      "Batch: 110, running loss: 93.34912768006325\n",
      "Batch: 120, running loss: 101.95399507880211\n",
      "Batch: 130, running loss: 109.12499037384987\n",
      "Batch: 140, running loss: 116.79650381207466\n",
      "Batch: 150, running loss: 124.39049795269966\n",
      "Batch: 160, running loss: 131.90441659092903\n",
      "Batch: 170, running loss: 139.16881185770035\n",
      "Batch: 180, running loss: 146.6904581785202\n",
      "Batch: 190, running loss: 154.92823606729507\n",
      "Batch: 200, running loss: 161.53482407331467\n",
      "Batch: 210, running loss: 169.67752468585968\n",
      "Batch: 220, running loss: 177.91384983062744\n",
      "Batch: 230, running loss: 185.03898006677628\n",
      "Batch: 240, running loss: 192.77856066823006\n",
      "Batch: 250, running loss: 199.76473954319954\n",
      "Batch: 260, running loss: 207.68131485581398\n",
      "Batch: 270, running loss: 215.91510853171349\n",
      "Batch: 280, running loss: 223.3238396346569\n",
      "Batch: 290, running loss: 230.11607322096825\n",
      "Batch: 300, running loss: 238.3079795539379\n",
      "Batch: 310, running loss: 245.72087186574936\n",
      "Epoch 1, train_loss: 0.7889880284714622\n",
      "Epoch 1, val1_loss: 0.7474318763812665\n",
      "Epoch 1, val_a_loss: 0.7414343407594557\n",
      "Epoch 2/10, Training Loss: 0.7890, Validation Loss 1: 0.7474, Validation Loss a: 0.7414\n",
      "Batch: 0, running loss: 0.7753558158874512\n",
      "Batch: 10, running loss: 9.478710889816284\n",
      "Batch: 20, running loss: 16.236630588769913\n",
      "Batch: 30, running loss: 23.639390379190445\n",
      "Batch: 40, running loss: 30.722544729709625\n",
      "Batch: 50, running loss: 36.730529844760895\n",
      "Batch: 60, running loss: 43.33712857961655\n",
      "Batch: 70, running loss: 50.096898674964905\n",
      "Batch: 80, running loss: 57.68720239400864\n",
      "Batch: 90, running loss: 64.02472627162933\n",
      "Batch: 100, running loss: 71.0070008635521\n",
      "Batch: 110, running loss: 77.12099379301071\n",
      "Batch: 120, running loss: 83.78037291765213\n",
      "Batch: 130, running loss: 90.09780663251877\n",
      "Batch: 140, running loss: 98.10159230232239\n",
      "Batch: 150, running loss: 106.31187373399734\n",
      "Batch: 160, running loss: 113.94032829999924\n",
      "Batch: 170, running loss: 120.53666722774506\n",
      "Batch: 180, running loss: 127.15213477611542\n",
      "Batch: 190, running loss: 133.91103845834732\n",
      "Batch: 200, running loss: 140.5597022175789\n",
      "Batch: 210, running loss: 147.43385356664658\n",
      "Batch: 220, running loss: 154.8169885277748\n",
      "Batch: 230, running loss: 160.4249585866928\n",
      "Batch: 240, running loss: 167.08156192302704\n",
      "Batch: 250, running loss: 172.84536090493202\n",
      "Batch: 260, running loss: 178.5471332669258\n",
      "Batch: 270, running loss: 185.37253886461258\n",
      "Batch: 280, running loss: 192.2695204615593\n",
      "Batch: 290, running loss: 199.64800202846527\n",
      "Batch: 300, running loss: 205.33892926573753\n",
      "Batch: 310, running loss: 213.06755682826042\n",
      "Epoch 2, train_loss: 0.6868163041603832\n",
      "Epoch 2, val1_loss: 0.8180025992597538\n",
      "Epoch 2, val_a_loss: 0.8258629115351307\n",
      "Epoch 3/10, Training Loss: 0.6868, Validation Loss 1: 0.8180, Validation Loss a: 0.8259\n",
      "Batch: 0, running loss: 0.8672806620597839\n",
      "Batch: 10, running loss: 7.335976839065552\n",
      "Batch: 20, running loss: 13.202694535255432\n",
      "Batch: 30, running loss: 19.673507392406464\n",
      "Batch: 40, running loss: 26.346520751714706\n",
      "Batch: 50, running loss: 33.52969563007355\n",
      "Batch: 60, running loss: 39.5667769908905\n",
      "Batch: 70, running loss: 46.51384022831917\n",
      "Batch: 80, running loss: 52.1491414308548\n",
      "Batch: 90, running loss: 57.747135668992996\n",
      "Batch: 100, running loss: 62.56457880139351\n",
      "Batch: 110, running loss: 68.75485023856163\n",
      "Batch: 120, running loss: 74.04879015684128\n",
      "Batch: 130, running loss: 79.28820371627808\n",
      "Batch: 140, running loss: 85.64496663212776\n",
      "Batch: 150, running loss: 91.94327241182327\n",
      "Batch: 160, running loss: 97.85121208429337\n",
      "Batch: 170, running loss: 104.45185166597366\n",
      "Batch: 180, running loss: 111.45213615894318\n",
      "Batch: 190, running loss: 116.87729719281197\n",
      "Batch: 200, running loss: 122.21801328659058\n",
      "Batch: 210, running loss: 127.56608441472054\n",
      "Batch: 220, running loss: 133.71980169415474\n",
      "Batch: 230, running loss: 141.01552429795265\n",
      "Batch: 240, running loss: 147.89094558358192\n",
      "Batch: 250, running loss: 154.18566486239433\n",
      "Batch: 260, running loss: 161.21732577681541\n",
      "Batch: 270, running loss: 167.87577757239342\n",
      "Batch: 280, running loss: 173.6483112871647\n",
      "Batch: 290, running loss: 179.55682507157326\n",
      "Batch: 300, running loss: 184.9559028148651\n",
      "Batch: 310, running loss: 190.4354462325573\n",
      "Epoch 3, train_loss: 0.6122396044647351\n",
      "Epoch 3, val1_loss: 0.8908278138604312\n",
      "Epoch 3, val_a_loss: 0.9112645055505378\n",
      "Epoch 4/10, Training Loss: 0.6122, Validation Loss 1: 0.8908, Validation Loss a: 0.9113\n",
      "Batch: 0, running loss: 0.6208537817001343\n",
      "Batch: 10, running loss: 6.075978875160217\n",
      "Batch: 20, running loss: 11.468053132295609\n",
      "Batch: 30, running loss: 16.926148772239685\n",
      "Batch: 40, running loss: 22.60177208483219\n",
      "Batch: 50, running loss: 27.999443724751472\n",
      "Batch: 60, running loss: 33.25700385868549\n",
      "Batch: 70, running loss: 39.06657047569752\n",
      "Batch: 80, running loss: 45.602154448628426\n",
      "Batch: 90, running loss: 50.943238601088524\n",
      "Batch: 100, running loss: 56.303955152630806\n",
      "Batch: 110, running loss: 60.48741801083088\n",
      "Batch: 120, running loss: 65.89217440783978\n",
      "Batch: 130, running loss: 72.41279362142086\n",
      "Batch: 140, running loss: 78.69301037490368\n",
      "Batch: 150, running loss: 83.53084303438663\n",
      "Batch: 160, running loss: 88.30356466770172\n",
      "Batch: 170, running loss: 93.89979842305183\n",
      "Batch: 180, running loss: 98.83947974443436\n",
      "Batch: 190, running loss: 104.64365357160568\n",
      "Batch: 200, running loss: 110.27982464432716\n",
      "Batch: 210, running loss: 116.66083207726479\n",
      "Batch: 220, running loss: 121.95226401090622\n",
      "Batch: 230, running loss: 126.10297256708145\n",
      "Batch: 240, running loss: 131.15386034548283\n",
      "Batch: 250, running loss: 135.95365138351917\n",
      "Batch: 260, running loss: 140.6358818858862\n",
      "Batch: 270, running loss: 145.62096850574017\n",
      "Batch: 280, running loss: 150.6735598295927\n",
      "Batch: 290, running loss: 156.11380039155483\n",
      "Batch: 300, running loss: 160.59401835501194\n",
      "Batch: 310, running loss: 166.53483746945858\n",
      "Epoch 4, train_loss: 0.5362694739057614\n",
      "Epoch 4, val1_loss: 0.746369184490959\n",
      "Epoch 4, val_a_loss: 0.7416439510333145\n",
      "Epoch 5/10, Training Loss: 0.5363, Validation Loss 1: 0.7464, Validation Loss a: 0.7416\n",
      "Batch: 0, running loss: 0.6109104156494141\n",
      "Batch: 10, running loss: 5.913363724946976\n",
      "Batch: 20, running loss: 10.993201196193695\n",
      "Batch: 30, running loss: 16.160683408379555\n",
      "Batch: 40, running loss: 21.08598755300045\n",
      "Batch: 50, running loss: 25.918270140886307\n",
      "Batch: 60, running loss: 31.37174043059349\n",
      "Batch: 70, running loss: 35.51885849237442\n",
      "Batch: 80, running loss: 40.10322839021683\n",
      "Batch: 90, running loss: 45.226053804159164\n",
      "Batch: 100, running loss: 49.955752700567245\n",
      "Batch: 110, running loss: 54.69223627448082\n",
      "Batch: 120, running loss: 59.298098772764206\n",
      "Batch: 130, running loss: 64.70061215758324\n",
      "Batch: 140, running loss: 68.88541489839554\n",
      "Batch: 150, running loss: 73.2030123770237\n",
      "Batch: 160, running loss: 77.60331262648106\n",
      "Batch: 170, running loss: 82.4870666116476\n",
      "Batch: 180, running loss: 87.26481528580189\n",
      "Batch: 190, running loss: 92.31729234755039\n",
      "Batch: 200, running loss: 96.6547274440527\n",
      "Batch: 210, running loss: 101.31033451855183\n",
      "Batch: 220, running loss: 105.19104938209057\n",
      "Batch: 230, running loss: 109.82402296364307\n",
      "Batch: 240, running loss: 115.09987692534924\n",
      "Batch: 250, running loss: 119.31862889230251\n",
      "Batch: 260, running loss: 124.10338066518307\n",
      "Batch: 270, running loss: 128.77807207405567\n",
      "Batch: 280, running loss: 134.26722480356693\n",
      "Batch: 290, running loss: 139.992244258523\n",
      "Batch: 300, running loss: 144.9110616594553\n",
      "Batch: 310, running loss: 149.96356032788754\n",
      "Epoch 5, train_loss: 0.48168310427818056\n",
      "Epoch 5, val1_loss: 0.6103228253811143\n",
      "Epoch 5, val_a_loss: 0.6165547028543766\n",
      "Epoch 6/10, Training Loss: 0.4817, Validation Loss 1: 0.6103, Validation Loss a: 0.6166\n",
      "Batch: 0, running loss: 0.4212436079978943\n",
      "Batch: 10, running loss: 4.769335135817528\n",
      "Batch: 20, running loss: 8.74658451974392\n",
      "Batch: 30, running loss: 13.0724286288023\n",
      "Batch: 40, running loss: 17.296403482556343\n",
      "Batch: 50, running loss: 21.06334613263607\n",
      "Batch: 60, running loss: 24.66866721212864\n",
      "Batch: 70, running loss: 29.513824954628944\n",
      "Batch: 80, running loss: 34.180284813046455\n",
      "Batch: 90, running loss: 38.41038282215595\n",
      "Batch: 100, running loss: 42.7393306940794\n",
      "Batch: 110, running loss: 46.55858959257603\n",
      "Batch: 120, running loss: 51.328950211405754\n",
      "Batch: 130, running loss: 56.21209801733494\n",
      "Batch: 140, running loss: 61.20582114160061\n",
      "Batch: 150, running loss: 66.50351367890835\n",
      "Batch: 160, running loss: 70.65678034722805\n",
      "Batch: 170, running loss: 74.50580550730228\n",
      "Batch: 180, running loss: 79.5858972221613\n",
      "Batch: 190, running loss: 84.29515539109707\n",
      "Batch: 200, running loss: 88.73643544316292\n",
      "Batch: 210, running loss: 93.86873933672905\n",
      "Batch: 220, running loss: 97.7075343132019\n",
      "Batch: 230, running loss: 101.83781036734581\n",
      "Batch: 240, running loss: 105.99625360965729\n",
      "Batch: 250, running loss: 110.21989041566849\n",
      "Batch: 260, running loss: 115.6324651837349\n",
      "Batch: 270, running loss: 119.94748342037201\n",
      "Batch: 280, running loss: 124.46053022146225\n",
      "Batch: 290, running loss: 128.22731801867485\n",
      "Batch: 300, running loss: 131.70849013328552\n",
      "Batch: 310, running loss: 135.6524935811758\n",
      "Epoch 6, train_loss: 0.4359226829042069\n",
      "Epoch 6, val1_loss: 0.8802814177046954\n",
      "Epoch 6, val_a_loss: 0.9021512844536285\n",
      "Epoch 7/10, Training Loss: 0.4359, Validation Loss 1: 0.8803, Validation Loss a: 0.9022\n",
      "Batch: 0, running loss: 0.3370071351528168\n",
      "Batch: 10, running loss: 4.147858947515488\n",
      "Batch: 20, running loss: 7.580003648996353\n",
      "Batch: 30, running loss: 11.85126531124115\n",
      "Batch: 40, running loss: 16.065020620822906\n",
      "Batch: 50, running loss: 20.50441724061966\n",
      "Batch: 60, running loss: 24.56507496535778\n",
      "Batch: 70, running loss: 29.503666266798973\n",
      "Batch: 80, running loss: 34.45904703438282\n",
      "Batch: 90, running loss: 38.953728184103966\n",
      "Batch: 100, running loss: 42.7880804091692\n",
      "Batch: 110, running loss: 47.85693734884262\n",
      "Batch: 120, running loss: 52.26815935969353\n",
      "Batch: 130, running loss: 55.82252222299576\n",
      "Batch: 140, running loss: 60.361518651247025\n",
      "Batch: 150, running loss: 64.3122301697731\n",
      "Batch: 160, running loss: 68.39913320541382\n",
      "Batch: 170, running loss: 72.14727501571178\n",
      "Batch: 180, running loss: 76.53276912868023\n",
      "Batch: 190, running loss: 79.91149494051933\n",
      "Batch: 200, running loss: 84.09808364510536\n",
      "Batch: 210, running loss: 87.8990863263607\n",
      "Batch: 220, running loss: 92.02942571043968\n",
      "Batch: 230, running loss: 95.59193700551987\n",
      "Batch: 240, running loss: 99.54413625597954\n",
      "Batch: 250, running loss: 104.10321208834648\n",
      "Batch: 260, running loss: 107.45700527727604\n",
      "Batch: 270, running loss: 111.45070852339268\n",
      "Batch: 280, running loss: 115.22560754418373\n",
      "Batch: 290, running loss: 118.85584846138954\n",
      "Batch: 300, running loss: 122.1001220792532\n",
      "Batch: 310, running loss: 126.65392570197582\n",
      "Epoch 7, train_loss: 0.40662133136686807\n",
      "Epoch 7, val1_loss: 0.6874399251801978\n",
      "Epoch 7, val_a_loss: 0.6956000020727515\n",
      "Epoch 8/10, Training Loss: 0.4066, Validation Loss 1: 0.6874, Validation Loss a: 0.6956\n",
      "Batch: 0, running loss: 0.36493197083473206\n",
      "Batch: 10, running loss: 4.083342373371124\n",
      "Batch: 20, running loss: 7.675276339054108\n",
      "Batch: 30, running loss: 10.97676657140255\n",
      "Batch: 40, running loss: 14.949946463108063\n",
      "Batch: 50, running loss: 18.376383766531944\n",
      "Batch: 60, running loss: 21.511584863066673\n",
      "Batch: 70, running loss: 24.79432651400566\n",
      "Batch: 80, running loss: 29.28384245187044\n",
      "Batch: 90, running loss: 33.06471010297537\n",
      "Batch: 100, running loss: 37.34486608952284\n",
      "Batch: 110, running loss: 40.88837941735983\n",
      "Batch: 120, running loss: 44.79266417771578\n",
      "Batch: 130, running loss: 48.849757350981236\n",
      "Batch: 140, running loss: 52.19185418635607\n",
      "Batch: 150, running loss: 55.42430043965578\n",
      "Batch: 160, running loss: 59.03586760908365\n",
      "Batch: 170, running loss: 62.87759409099817\n",
      "Batch: 180, running loss: 66.31787697225809\n",
      "Batch: 190, running loss: 70.32874887436628\n",
      "Batch: 200, running loss: 73.59001056104898\n",
      "Batch: 210, running loss: 77.0579976066947\n",
      "Batch: 220, running loss: 80.52672966569662\n",
      "Batch: 230, running loss: 84.67533428221941\n",
      "Batch: 240, running loss: 88.74212009459734\n",
      "Batch: 250, running loss: 92.32638394087553\n",
      "Batch: 260, running loss: 95.45146790891886\n",
      "Batch: 270, running loss: 99.1517266407609\n",
      "Batch: 280, running loss: 103.08770725876093\n",
      "Batch: 290, running loss: 107.3953064456582\n",
      "Batch: 300, running loss: 111.26438323408365\n",
      "Batch: 310, running loss: 115.25417350977659\n",
      "Epoch 8, train_loss: 0.37536838638801545\n",
      "Epoch 8, val1_loss: 0.8312929767598689\n",
      "Epoch 8, val_a_loss: 0.840061212781703\n",
      "Epoch 9/10, Training Loss: 0.3754, Validation Loss 1: 0.8313, Validation Loss a: 0.8401\n",
      "Batch: 0, running loss: 0.3651313781738281\n",
      "Batch: 10, running loss: 5.436726808547974\n",
      "Batch: 20, running loss: 9.98507907986641\n",
      "Batch: 30, running loss: 13.609845504164696\n",
      "Batch: 40, running loss: 17.288720294833183\n",
      "Batch: 50, running loss: 20.828245267271996\n",
      "Batch: 60, running loss: 24.518867820501328\n",
      "Batch: 70, running loss: 28.408134415745735\n",
      "Batch: 80, running loss: 32.02807226777077\n",
      "Batch: 90, running loss: 34.77333441376686\n",
      "Batch: 100, running loss: 38.03368158638477\n",
      "Batch: 110, running loss: 41.48563472926617\n",
      "Batch: 120, running loss: 45.357266277074814\n",
      "Batch: 130, running loss: 49.43602705001831\n",
      "Batch: 140, running loss: 52.070728577673435\n",
      "Batch: 150, running loss: 55.13841012865305\n",
      "Batch: 160, running loss: 58.4075293764472\n",
      "Batch: 170, running loss: 62.90464172512293\n",
      "Batch: 180, running loss: 67.19662130624056\n",
      "Batch: 190, running loss: 70.13203602284193\n",
      "Batch: 200, running loss: 73.2466351762414\n",
      "Batch: 210, running loss: 76.78494534641504\n",
      "Batch: 220, running loss: 80.73017353564501\n",
      "Batch: 230, running loss: 83.92760027199984\n",
      "Batch: 240, running loss: 87.42676732689142\n",
      "Batch: 250, running loss: 90.84567803889513\n",
      "Batch: 260, running loss: 95.16202948242426\n",
      "Batch: 270, running loss: 99.04417712241411\n",
      "Batch: 280, running loss: 102.05136796087027\n",
      "Batch: 290, running loss: 105.17983024567366\n",
      "Batch: 300, running loss: 108.39491256326437\n",
      "Batch: 310, running loss: 111.64427853375673\n",
      "Epoch 9, train_loss: 0.3589892059136123\n",
      "Epoch 9, val1_loss: 0.6630872393130134\n",
      "Epoch 9, val_a_loss: 0.6566807949037122\n",
      "Epoch 10/10, Training Loss: 0.3590, Validation Loss 1: 0.6631, Validation Loss a: 0.6567\n",
      "Saving model.state_dict() as /content/drive/MyDrive/Colab Notebooks/skin-lesion-classification/models/rn18_ta_bal_uflast_10e_rndcrop_00.pth.\n",
      "model.state_dict() can now be accessed through state_dict attribute.\n",
      "Train/val losses can now be accessed through epoch_losses attribute.\n",
      "Epoch losses dictionary save as /content/drive/MyDrive/Colab Notebooks/skin-lesion-classification/models/rn18_ta_bal_uflast_10e_rndcrop_00_epoch_losses.json\n",
      "Elapsed time: 9250.010692119598\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "\n",
    "# tic = time.time()\n",
    "# rn18_balance_ta.train()\n",
    "# toc = time.time()\n",
    "# print(f\"Elapsed time: {toc - tic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f19b2b",
   "metadata": {
    "id": "d8f19b2b"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# instance = rn18_balance_ta\n",
    "\n",
    "# model = models.resnet18()\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "\n",
    "# file_path_pth = instance.model_dir.joinpath(instance._filename + \".pth\")\n",
    "# state_dict = torch.load(file_path_pth)\n",
    "# model.load_state_dict(state_dict)\n",
    "\n",
    "# # model = models.efficientnet_b0()\n",
    "# # num_ftrs = model.classifier[1].in_features\n",
    "# # model.classifier[1] = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "\n",
    "# instance.model = model\n",
    "# instance.state_dict = state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f89e26a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4f89e26a",
    "outputId": "8a8a63ce-e23b-4850-d50f-775b11fb0e9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving probabilities: /content/drive/MyDrive/Colab Notebooks/skin-lesion-classification/models/rn18_ta_bal_uflast_10e_rndcrop_00_val1_probabilities.csv\n",
      "Elapsed time: 76.36412167549133\n",
      "Saving probabilities: /content/drive/MyDrive/Colab Notebooks/skin-lesion-classification/models/rn18_ta_bal_uflast_10e_rndcrop_00_val_a_probabilities.csv\n",
      "Elapsed time: 76.4004967212677\n"
     ]
    }
   ],
   "source": [
    "# # from utils import print_header\n",
    "# from multiclass_models import get_probabilities\n",
    "\n",
    "# instance = rn18_balance_ta\n",
    "\n",
    "# tic = time.time()\n",
    "\n",
    "# instance.df_probabilities_val1 = get_probabilities(df=instance.df_val1,\n",
    "#                                                    data_dir=instance.data_dir,\n",
    "#                                                    model_dir=instance.model_dir,\n",
    "#                                                    model=instance.model,\n",
    "#                                                    filename=instance._filename,\n",
    "#                                                    label_codes=instance.label_codes,\n",
    "#                                                    transform=instance.transform,\n",
    "#                                                    batch_size=instance.batch_size,\n",
    "#                                                    Print=False,\n",
    "#                                                    save_as=instance._filename + \"_val1\",)\n",
    "\n",
    "# toc = time.time()\n",
    "\n",
    "# print(f\"Elapsed time: {toc - tic}\")\n",
    "\n",
    "# instance.df_probabilities_val_a = get_probabilities(df=instance.df_val_a,\n",
    "#                                                     data_dir=instance.data_dir,\n",
    "#                                                     model_dir=instance.model_dir,\n",
    "#                                                     model=instance.model,\n",
    "#                                                     filename=instance._filename,\n",
    "#                                                     label_codes=instance.label_codes,\n",
    "#                                                     transform=instance.transform,\n",
    "#                                                     batch_size=instance.batch_size,\n",
    "#                                                     Print=False,\n",
    "#                                                     save_as=instance._filename + \"_val_a\",)\n",
    "# tic = time.time()\n",
    "\n",
    "# print(f\"Elapsed time: {tic - toc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb08376c",
   "metadata": {
    "id": "bb08376c"
   },
   "outputs": [],
   "source": [
    "instance = rn18_balance_ta\n",
    "\n",
    "file_path1 = instance.model_dir.joinpath(\"rn18_ta_bal_uflast_10e_rndcrop_00_val1_probabilities.csv\")\n",
    "file_path_a = instance.model_dir.joinpath(\"rn18_ta_bal_uflast_10e_rndcrop_00_val_a_probabilities.csv\")\n",
    "\n",
    "instance.df_probabilities_val1 = pd.read_csv(file_path1, index_col=0)\n",
    "instance.df_probabilities_val_a = pd.read_csv(file_path_a, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8096a8d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "a8096a8d",
    "outputId": "6c3f71fc-e03e-4185-c86b-d34e03311dda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================\n",
      "VALIDATION SET: ONE IMAGE PER LESION\n",
      "====================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_nv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.196147</td>\n",
       "      <td>0.057795</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.724161</td>\n",
       "      <td>0.005296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.247946</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.012981</td>\n",
       "      <td>0.716585</td>\n",
       "      <td>0.007287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.365886</td>\n",
       "      <td>0.045827</td>\n",
       "      <td>0.013421</td>\n",
       "      <td>0.569576</td>\n",
       "      <td>0.005289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0027850</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.582575</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>0.193693</td>\n",
       "      <td>0.185775</td>\n",
       "      <td>0.030167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0027850</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.000204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx  prob_other  prob_akiec  prob_bcc  prob_mel  \\\n",
       "0  HAM_0002730  ISIC_0025661  bkl    0.196147    0.057795  0.016602  0.724161   \n",
       "1  HAM_0002730  ISIC_0025661  bkl    0.247946    0.015202  0.012981  0.716585   \n",
       "2  HAM_0002730  ISIC_0025661  bkl    0.365886    0.045827  0.013421  0.569576   \n",
       "3  HAM_0001466  ISIC_0027850  bkl    0.582575    0.007791  0.193693  0.185775   \n",
       "4  HAM_0001466  ISIC_0027850  bkl    0.000759    0.000004  0.000032  0.999000   \n",
       "\n",
       "    prob_nv  \n",
       "0  0.005296  \n",
       "1  0.007287  \n",
       "2  0.005289  \n",
       "3  0.030167  \n",
       "4  0.000204  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================\n",
      "VALIDATION SET: ALL IMAGES PER LESION\n",
      "=====================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_nv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.036362</td>\n",
       "      <td>9.617091e-01</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.035796</td>\n",
       "      <td>9.373081e-01</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.025693</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.552345</td>\n",
       "      <td>8.390885e-03</td>\n",
       "      <td>0.031259</td>\n",
       "      <td>0.397282</td>\n",
       "      <td>0.010724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.015292</td>\n",
       "      <td>1.135414e-04</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.981527</td>\n",
       "      <td>0.001068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0027850</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>5.629219e-07</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.998866</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx  prob_other    prob_akiec  prob_bcc  \\\n",
       "0  HAM_0002730  ISIC_0026769  bkl    0.036362  9.617091e-01  0.000780   \n",
       "1  HAM_0002730  ISIC_0026769  bkl    0.035796  9.373081e-01  0.000950   \n",
       "2  HAM_0002730  ISIC_0025661  bkl    0.552345  8.390885e-03  0.031259   \n",
       "3  HAM_0001466  ISIC_0031633  bkl    0.015292  1.135414e-04  0.002000   \n",
       "4  HAM_0001466  ISIC_0027850  bkl    0.000478  5.629219e-07  0.000431   \n",
       "\n",
       "   prob_mel   prob_nv  \n",
       "0  0.000977  0.000171  \n",
       "1  0.025693  0.000254  \n",
       "2  0.397282  0.010724  \n",
       "3  0.981527  0.001068  \n",
       "4  0.998866  0.000225  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import print_header\n",
    "\n",
    "instance = rn18_balance_ta\n",
    "\n",
    "print_header(\"Validation set: one image per lesion\")\n",
    "display_columns = ['lesion_id', 'image_id', 'dx'] + [col for col in instance.df_probabilities_val1.columns if col.startswith('prob')]\n",
    "display(instance.df_probabilities_val1[display_columns].head())\n",
    "\n",
    "print_header(\"Validation set: all images per lesion\")\n",
    "display(instance.df_probabilities_val_a[display_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c397a32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "4c397a32",
    "outputId": "00bab7b4-dee5-4596-8410-4cbc7e4a5196"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================\n",
      "VALIDATION SET, ONE IMAGE PER LESION: COMBINING PROBABILITIES AND MAKING PREDICTIONS\n",
      "====================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.196147</td>\n",
       "      <td>0.057795</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.724161</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.247946</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.012981</td>\n",
       "      <td>0.716585</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.365886</td>\n",
       "      <td>0.045827</td>\n",
       "      <td>0.013421</td>\n",
       "      <td>0.569576</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0027850</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.582575</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>0.193693</td>\n",
       "      <td>0.185775</td>\n",
       "      <td>0.030167</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0027850</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx  prob_other  prob_akiec  prob_bcc  prob_mel  \\\n",
       "0  HAM_0002730  ISIC_0025661  bkl    0.196147    0.057795  0.016602  0.724161   \n",
       "1  HAM_0002730  ISIC_0025661  bkl    0.247946    0.015202  0.012981  0.716585   \n",
       "2  HAM_0002730  ISIC_0025661  bkl    0.365886    0.045827  0.013421  0.569576   \n",
       "3  HAM_0001466  ISIC_0027850  bkl    0.582575    0.007791  0.193693  0.185775   \n",
       "4  HAM_0001466  ISIC_0027850  bkl    0.000759    0.000004  0.000032  0.999000   \n",
       "\n",
       "    prob_nv  pred  pred_final  \n",
       "0  0.005296     3           3  \n",
       "1  0.007287     3           3  \n",
       "2  0.005289     3           3  \n",
       "3  0.030167     0           3  \n",
       "4  0.000204     3           3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================================================================================\n",
      "VALIDATION SET, ALL IMAGES PER LESION: COMBINING PROBABILITIES, MAKING PREDICTIONS, AND COMBINING PREDICTIONS\n",
      "=============================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.036362</td>\n",
       "      <td>9.617091e-01</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.035796</td>\n",
       "      <td>9.373081e-01</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.025693</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.552345</td>\n",
       "      <td>8.390885e-03</td>\n",
       "      <td>0.031259</td>\n",
       "      <td>0.397282</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.015292</td>\n",
       "      <td>1.135414e-04</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.981527</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0027850</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>5.629219e-07</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.998866</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx  prob_other    prob_akiec  prob_bcc  \\\n",
       "0  HAM_0002730  ISIC_0026769  bkl    0.036362  9.617091e-01  0.000780   \n",
       "1  HAM_0002730  ISIC_0026769  bkl    0.035796  9.373081e-01  0.000950   \n",
       "2  HAM_0002730  ISIC_0025661  bkl    0.552345  8.390885e-03  0.031259   \n",
       "3  HAM_0001466  ISIC_0031633  bkl    0.015292  1.135414e-04  0.002000   \n",
       "4  HAM_0001466  ISIC_0027850  bkl    0.000478  5.629219e-07  0.000431   \n",
       "\n",
       "   prob_mel   prob_nv  pred  pred_final  \n",
       "0  0.000977  0.000171     1           1  \n",
       "1  0.025693  0.000254     1           1  \n",
       "2  0.397282  0.010724     0           1  \n",
       "3  0.981527  0.001068     3           3  \n",
       "4  0.998866  0.000225     3           3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List\n",
    "from multiclass_models import final_prediction\n",
    "\n",
    "instance = rn18_balance_ta\n",
    "\n",
    "raw_probabilities_df1: pd.DataFrame = instance.df_probabilities_val1\n",
    "raw_probabilities_df_a: pd.DataFrame = instance.df_probabilities_val_a\n",
    "aggregate_method: Union[None, Dict[str, List[str]]] = None#{ 'max' : ['mel', 'bcc', 'akiec'], 'min' : ['nv'], 'mean' : ['other']}\n",
    "threshold_dict_help: Union[None, OrderedDict[str, float]] = None# OrderedDict([('mel',0.4), ('bcc', 0.4), ('akiec', 0.4)])\n",
    "threshold_dict_hinder: Union[None, OrderedDict[str, float]] = None#OrderedDict([('nv',0.6)])\n",
    "votes_to_win_dict: Union[None, OrderedDict[str, int]] = None #OrderedDict([('mel',1), ('bcc',1), ('akiec',1)])\n",
    "label_codes: Dict[int, str] = instance.label_codes\n",
    "prefix: Union[None, str] = 'prob_'\n",
    "\n",
    "print_header(\"Validation set, one image per lesion: combining probabilities and making predictions\")\n",
    "\n",
    "instance.df_pred_val1 = final_prediction(raw_probabilities_df=raw_probabilities_df1,\n",
    "                                          threshold_dict_help=threshold_dict_help,\n",
    "                                          threshold_dict_hinder=threshold_dict_hinder,\n",
    "                                          votes_to_win_dict=votes_to_win_dict,\n",
    "                                          label_codes=label_codes,)\n",
    "display_columns = ['lesion_id', 'image_id', 'dx'] + [col for col in instance.df_probabilities_val1.columns if col.startswith('prob')] + ['pred', 'pred_final']\n",
    "display(instance.df_pred_val1[display_columns].head())\n",
    "\n",
    "print_header(\"Validation set, all images per lesion: combining probabilities, making predictions, and combining predictions\")\n",
    "\n",
    "instance.df_pred_val_a = final_prediction(raw_probabilities_df=raw_probabilities_df_a,\n",
    "                                          threshold_dict_help=threshold_dict_help,\n",
    "                                          threshold_dict_hinder=threshold_dict_hinder,\n",
    "                                          votes_to_win_dict=votes_to_win_dict,\n",
    "                                          label_codes=label_codes,)\n",
    "\n",
    "display(instance.df_pred_val_a[display_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feffd04b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 757
    },
    "id": "feffd04b",
    "outputId": "22742e7a-b480-4d93-c372-85f66e673a93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================\n",
      "CONFUSION MATRIX: VALIDATION SET, ONE IMAGE PER LESION\n",
      "======================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>akiec</th>\n",
       "      <th>bcc</th>\n",
       "      <th>mel</th>\n",
       "      <th>nv</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>145</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>225</td>\n",
       "      <td>0.644444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>0.560976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>20</td>\n",
       "      <td>154</td>\n",
       "      <td>0.707792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>69</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>150</td>\n",
       "      <td>1,102</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0.815692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>247</td>\n",
       "      <td>94</td>\n",
       "      <td>68</td>\n",
       "      <td>315</td>\n",
       "      <td>1,145</td>\n",
       "      <td>1,869</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.587045</td>\n",
       "      <td>0.414894</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.346032</td>\n",
       "      <td>0.962445</td>\n",
       "      <td>_</td>\n",
       "      <td>0.649045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted     other     akiec       bcc       mel        nv    All    recall\n",
       "actual                                                                      \n",
       "other           145        17         2        45        16    225  0.644444\n",
       "akiec             6        39         7         2         3     57  0.684211\n",
       "bcc               8        15        46         9         4     82  0.560976\n",
       "mel              19         5         1       109        20    154  0.707792\n",
       "nv               69        18        12       150     1,102  1,351  0.815692\n",
       "All             247        94        68       315     1,145  1,869         _\n",
       "precision  0.587045  0.414894  0.676471  0.346032  0.962445      _  0.649045"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "CONFUSION MATRIX: VALIDATION SET, ALL IMAGES PER LESION\n",
      "=======================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>akiec</th>\n",
       "      <th>bcc</th>\n",
       "      <th>mel</th>\n",
       "      <th>nv</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>153</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "      <td>225</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "      <td>0.649123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>82</td>\n",
       "      <td>0.597561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>16</td>\n",
       "      <td>154</td>\n",
       "      <td>0.74026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>74</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>158</td>\n",
       "      <td>1,094</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0.809771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>259</td>\n",
       "      <td>83</td>\n",
       "      <td>70</td>\n",
       "      <td>323</td>\n",
       "      <td>1,134</td>\n",
       "      <td>1,869</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.590734</td>\n",
       "      <td>0.445783</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.964727</td>\n",
       "      <td>_</td>\n",
       "      <td>0.662832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted     other     akiec  bcc       mel        nv    All    recall\n",
       "actual                                                                 \n",
       "other           153        16    1        39        16    225      0.68\n",
       "akiec             6        37    9         2         3     57  0.649123\n",
       "bcc               8        10   49        10         5     82  0.597561\n",
       "mel              18         5    1       114        16    154   0.74026\n",
       "nv               74        15   10       158     1,094  1,351  0.809771\n",
       "All             259        83   70       323     1,134  1,869         _\n",
       "precision  0.590734  0.445783  0.7  0.352941  0.964727      _  0.662832"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from evaluation import weighted_average_f, confusion_matrix_with_metric\n",
    "\n",
    "instance = rn18_balance_ta\n",
    "map_labels = instance.label_codes\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label']\n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final']\n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']\n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']\n",
    "\n",
    "txp1 = pd.crosstab(target1,prediction1,margins=True,dropna=False)\n",
    "txp_a = pd.crosstab(target_a,prediction_a,margins=True,dropna=False)\n",
    "\n",
    "beta = 2\n",
    "# Weights inversely proportional to relative class size in the training set, giving more importance to smaller classes.\n",
    "weights = 1/instance.df_train['label'].value_counts(normalize=True).sort_index().values # None\n",
    "\n",
    "instance.cm1 = confusion_matrix_with_metric(AxB=txp1,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "instance.cm_a = confusion_matrix_with_metric(AxB=txp_a,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "print_header(\"Confusion matrix: validation set, one image per lesion\")\n",
    "display(instance.cm1.fillna('_'))\n",
    "\n",
    "print_header(\"Confusion matrix: validation set, all images per lesion\")\n",
    "display(instance.cm_a.fillna('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e98fa3a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "e98fa3a3",
    "outputId": "e036a3cc-ddfa-41eb-b440-b3370c30e7bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================\n",
      "BASELINE MODEL: OTHER METRICS\n",
      "=============================\n",
      "\n",
      "\n",
      "ONE IMAGE PER LESION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.771001</td>\n",
       "      <td>0.682623</td>\n",
       "      <td>0.597377</td>\n",
       "      <td>0.682623</td>\n",
       "      <td>0.602441</td>\n",
       "      <td>0.618426</td>\n",
       "      <td>0.649045</td>\n",
       "      <td>0.578273</td>\n",
       "      <td>0.933157</td>\n",
       "      <td>0.934257</td>\n",
       "      <td>0.913871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC      BACC  precision    recall      F1/2        F1        F2  \\\n",
       "0  0.771001  0.682623   0.597377  0.682623  0.602441  0.618426  0.649045   \n",
       "\n",
       "        MCC  ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0  0.578273     0.933157    0.934257     0.913871  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ALL IMAGES PER LESION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.774211</td>\n",
       "      <td>0.695343</td>\n",
       "      <td>0.610837</td>\n",
       "      <td>0.695343</td>\n",
       "      <td>0.616478</td>\n",
       "      <td>0.632802</td>\n",
       "      <td>0.662832</td>\n",
       "      <td>0.588672</td>\n",
       "      <td>0.931156</td>\n",
       "      <td>0.937441</td>\n",
       "      <td>0.910373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC      BACC  precision    recall      F1/2        F1        F2  \\\n",
       "0  0.774211  0.695343   0.610837  0.695343  0.616478  0.632802  0.662832   \n",
       "\n",
       "        MCC  ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0  0.588672     0.931156    0.937441     0.910373  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from evaluation import metric_dictionary\n",
    "# import pandas as pd\n",
    "\n",
    "instance = rn18_balance_ta\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label']\n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final']\n",
    "probabilities1 = instance.df_probabilities_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']\n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']\n",
    "probabilities_a = instance.df_probabilities_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "\n",
    "beta = 2\n",
    "# Weights inversely proportional to relative class size, giving more importance to smaller classes.\n",
    "weights = 1/instance.df_train['label'].value_counts(normalize=True).sort_index().values # None\n",
    "\n",
    "print_header(\"Baseline model: other metrics\")\n",
    "\n",
    "instance.metric_dict1 = metric_dictionary(target=target1,\n",
    "                                          prediction=prediction1,\n",
    "                                          probabilities=probabilities1)\n",
    "\n",
    "instance.metric_dict_a = metric_dictionary(target=target_a,\n",
    "                                          prediction=prediction_a,\n",
    "                                          probabilities=probabilities_a)\n",
    "\n",
    "print(\"\\nOne image per lesion\".upper())\n",
    "display(pd.DataFrame(instance.metric_dict1))\n",
    "\n",
    "print(\"\\nAll images per lesion\".upper())\n",
    "display(pd.DataFrame(instance.metric_dict_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "qi2QhQOtY9Kk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "qi2QhQOtY9Kk",
    "outputId": "5b2b7437-4184-4ffb-8f85-abc62fc45311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================\n",
      "VALIDATION SET, ONE IMAGE PER LESION: COMBINING PROBABILITIES AND MAKING PREDICTIONS\n",
      "====================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.196147</td>\n",
       "      <td>0.057795</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.724161</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.247946</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.012981</td>\n",
       "      <td>0.716585</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.365886</td>\n",
       "      <td>0.045827</td>\n",
       "      <td>0.013421</td>\n",
       "      <td>0.569576</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0027850</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.582575</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>0.193693</td>\n",
       "      <td>0.185775</td>\n",
       "      <td>0.030167</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0027850</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx  prob_other  prob_akiec  prob_bcc  prob_mel  \\\n",
       "0  HAM_0002730  ISIC_0025661  bkl    0.196147    0.057795  0.016602  0.724161   \n",
       "1  HAM_0002730  ISIC_0025661  bkl    0.247946    0.015202  0.012981  0.716585   \n",
       "2  HAM_0002730  ISIC_0025661  bkl    0.365886    0.045827  0.013421  0.569576   \n",
       "3  HAM_0001466  ISIC_0027850  bkl    0.582575    0.007791  0.193693  0.185775   \n",
       "4  HAM_0001466  ISIC_0027850  bkl    0.000759    0.000004  0.000032  0.999000   \n",
       "\n",
       "    prob_nv  pred  pred_final  \n",
       "0  0.005296     3           3  \n",
       "1  0.007287     3           3  \n",
       "2  0.005289     3           3  \n",
       "3  0.030167     0           3  \n",
       "4  0.000204     3           3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================================================================================\n",
      "VALIDATION SET, ALL IMAGES PER LESION: COMBINING PROBABILITIES, MAKING PREDICTIONS, AND COMBINING PREDICTIONS\n",
      "=============================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.036362</td>\n",
       "      <td>9.617091e-01</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.035796</td>\n",
       "      <td>9.373081e-01</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.025693</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.552345</td>\n",
       "      <td>8.390885e-03</td>\n",
       "      <td>0.031259</td>\n",
       "      <td>0.397282</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.015292</td>\n",
       "      <td>1.135414e-04</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.981527</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0027850</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>5.629219e-07</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.998866</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx  prob_other    prob_akiec  prob_bcc  \\\n",
       "0  HAM_0002730  ISIC_0026769  bkl    0.036362  9.617091e-01  0.000780   \n",
       "1  HAM_0002730  ISIC_0026769  bkl    0.035796  9.373081e-01  0.000950   \n",
       "2  HAM_0002730  ISIC_0025661  bkl    0.552345  8.390885e-03  0.031259   \n",
       "3  HAM_0001466  ISIC_0031633  bkl    0.015292  1.135414e-04  0.002000   \n",
       "4  HAM_0001466  ISIC_0027850  bkl    0.000478  5.629219e-07  0.000431   \n",
       "\n",
       "   prob_mel   prob_nv  pred  pred_final  \n",
       "0  0.000977  0.000171     1           1  \n",
       "1  0.025693  0.000254     1           1  \n",
       "2  0.397282  0.010724     0           1  \n",
       "3  0.981527  0.001068     3           3  \n",
       "4  0.998866  0.000225     3           3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List\n",
    "from multiclass_models import final_prediction\n",
    "\n",
    "instance = rn18_balance_ta\n",
    "\n",
    "raw_probabilities_df1: pd.DataFrame = instance.df_probabilities_val1\n",
    "raw_probabilities_df_a: pd.DataFrame = instance.df_probabilities_val_a\n",
    "aggregate_method: Union[None, Dict[str, List[str]]] = { 'max' : ['mel', 'bcc', 'akiec'], 'min' : ['nv'], 'mean' : ['other']}\n",
    "threshold_dict_help: Union[None, OrderedDict[str, float]] = OrderedDict([('mel',0.4), ('bcc', 0.4), ('akiec', 0.4)])\n",
    "threshold_dict_hinder: Union[None, OrderedDict[str, float]] = None#OrderedDict([('nv',0.6)])\n",
    "votes_to_win_dict: Union[None, OrderedDict[str, int]] = None #OrderedDict([('mel',1), ('bcc',1), ('akiec',1)])\n",
    "label_codes: Dict[int, str] = instance.label_codes\n",
    "prefix: Union[None, str] = 'prob_'\n",
    "\n",
    "print_header(\"Validation set, one image per lesion: combining probabilities and making predictions\")\n",
    "\n",
    "instance.df_pred_val1 = final_prediction(raw_probabilities_df=raw_probabilities_df1,\n",
    "                                          threshold_dict_help=threshold_dict_help,\n",
    "                                          threshold_dict_hinder=threshold_dict_hinder,\n",
    "                                          votes_to_win_dict=votes_to_win_dict,\n",
    "                                          label_codes=label_codes,)\n",
    "display_columns = ['lesion_id', 'image_id', 'dx'] + [col for col in instance.df_probabilities_val1.columns if col.startswith('prob')] + ['pred', 'pred_final']\n",
    "display(instance.df_pred_val1[display_columns].head())\n",
    "\n",
    "print_header(\"Validation set, all images per lesion: combining probabilities, making predictions, and combining predictions\")\n",
    "\n",
    "instance.df_pred_val_a = final_prediction(raw_probabilities_df=raw_probabilities_df_a,\n",
    "                                          threshold_dict_help=threshold_dict_help,\n",
    "                                          threshold_dict_hinder=threshold_dict_hinder,\n",
    "                                          votes_to_win_dict=votes_to_win_dict,\n",
    "                                          label_codes=label_codes,)\n",
    "\n",
    "display(instance.df_pred_val_a[display_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "GmUmQaKKZDsv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 757
    },
    "id": "GmUmQaKKZDsv",
    "outputId": "d13ffb7d-1c10-4d37-f38f-1bcdc4dbd817"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================\n",
      "CONFUSION MATRIX: VALIDATION SET, ONE IMAGE PER LESION\n",
      "======================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>akiec</th>\n",
       "      <th>bcc</th>\n",
       "      <th>mel</th>\n",
       "      <th>nv</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>143</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>0.635556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>0.560976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>16</td>\n",
       "      <td>154</td>\n",
       "      <td>0.74026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>68</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>175</td>\n",
       "      <td>1,079</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0.798668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>242</td>\n",
       "      <td>95</td>\n",
       "      <td>67</td>\n",
       "      <td>350</td>\n",
       "      <td>1,115</td>\n",
       "      <td>1,869</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.410526</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>0.325714</td>\n",
       "      <td>0.967713</td>\n",
       "      <td>_</td>\n",
       "      <td>0.645946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted     other     akiec       bcc       mel        nv    All    recall\n",
       "actual                                                                      \n",
       "other           143        18         2        49        13    225  0.635556\n",
       "akiec             6        39         7         2         3     57  0.684211\n",
       "bcc               7        15        46        10         4     82  0.560976\n",
       "mel              18         5         1       114        16    154   0.74026\n",
       "nv               68        18        11       175     1,079  1,351  0.798668\n",
       "All             242        95        67       350     1,115  1,869         _\n",
       "precision  0.590909  0.410526  0.686567  0.325714  0.967713      _  0.645946"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "CONFUSION MATRIX: VALIDATION SET, ALL IMAGES PER LESION\n",
      "=======================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>akiec</th>\n",
       "      <th>bcc</th>\n",
       "      <th>mel</th>\n",
       "      <th>nv</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>151</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>225</td>\n",
       "      <td>0.671111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>82</td>\n",
       "      <td>0.597561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>14</td>\n",
       "      <td>154</td>\n",
       "      <td>0.753247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>72</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>169</td>\n",
       "      <td>1,085</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0.803109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>253</td>\n",
       "      <td>85</td>\n",
       "      <td>70</td>\n",
       "      <td>339</td>\n",
       "      <td>1,122</td>\n",
       "      <td>1,869</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.596838</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.342183</td>\n",
       "      <td>0.967023</td>\n",
       "      <td>_</td>\n",
       "      <td>0.666403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted     other     akiec  bcc       mel        nv    All    recall\n",
       "actual                                                                 \n",
       "other           151        16    1        42        15    225  0.671111\n",
       "akiec             4        39    9         2         3     57  0.684211\n",
       "bcc               8        10   49        10         5     82  0.597561\n",
       "mel              18         5    1       116        14    154  0.753247\n",
       "nv               72        15   10       169     1,085  1,351  0.803109\n",
       "All             253        85   70       339     1,122  1,869         _\n",
       "precision  0.596838  0.458824  0.7  0.342183  0.967023      _  0.666403"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from evaluation import weighted_average_f, confusion_matrix_with_metric\n",
    "\n",
    "instance = rn18_balance_ta\n",
    "map_labels = instance.label_codes\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label']\n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final']\n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']\n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']\n",
    "\n",
    "txp1 = pd.crosstab(target1,prediction1,margins=True,dropna=False)\n",
    "txp_a = pd.crosstab(target_a,prediction_a,margins=True,dropna=False)\n",
    "\n",
    "beta = 2\n",
    "# Weights inversely proportional to relative class size in the training set, giving more importance to smaller classes.\n",
    "weights = 1/instance.df_train['label'].value_counts(normalize=True).sort_index().values # None\n",
    "\n",
    "instance.cm1 = confusion_matrix_with_metric(AxB=txp1,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "instance.cm_a = confusion_matrix_with_metric(AxB=txp_a,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "print_header(\"Confusion matrix: validation set, one image per lesion\")\n",
    "display(instance.cm1.fillna('_'))\n",
    "\n",
    "print_header(\"Confusion matrix: validation set, all images per lesion\")\n",
    "display(instance.cm_a.fillna('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0KG-c3IpZJUu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "0KG-c3IpZJUu",
    "outputId": "66953330-8ac0-4527-d92c-646edd9aeb0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================\n",
      "BASELINE MODEL: OTHER METRICS\n",
      "=============================\n",
      "\n",
      "\n",
      "ONE IMAGE PER LESION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7603</td>\n",
       "      <td>0.683934</td>\n",
       "      <td>0.596286</td>\n",
       "      <td>0.683934</td>\n",
       "      <td>0.599581</td>\n",
       "      <td>0.614102</td>\n",
       "      <td>0.645946</td>\n",
       "      <td>0.57103</td>\n",
       "      <td>0.933157</td>\n",
       "      <td>0.934257</td>\n",
       "      <td>0.913871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ACC      BACC  precision    recall      F1/2        F1        F2  \\\n",
       "0  0.7603  0.683934   0.596286  0.683934  0.599581  0.614102  0.645946   \n",
       "\n",
       "       MCC  ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0  0.57103     0.933157    0.934257     0.913871  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ALL IMAGES PER LESION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.770465</td>\n",
       "      <td>0.701848</td>\n",
       "      <td>0.612974</td>\n",
       "      <td>0.701848</td>\n",
       "      <td>0.618306</td>\n",
       "      <td>0.634779</td>\n",
       "      <td>0.666403</td>\n",
       "      <td>0.586954</td>\n",
       "      <td>0.931156</td>\n",
       "      <td>0.937441</td>\n",
       "      <td>0.910373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC      BACC  precision    recall      F1/2        F1        F2  \\\n",
       "0  0.770465  0.701848   0.612974  0.701848  0.618306  0.634779  0.666403   \n",
       "\n",
       "        MCC  ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0  0.586954     0.931156    0.937441     0.910373  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from evaluation import metric_dictionary\n",
    "# import pandas as pd\n",
    "\n",
    "instance = rn18_balance_ta\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label']\n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final']\n",
    "probabilities1 = instance.df_probabilities_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']\n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']\n",
    "probabilities_a = instance.df_probabilities_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "\n",
    "beta = 2\n",
    "# Weights inversely proportional to relative class size, giving more importance to smaller classes.\n",
    "weights = 1/instance.df_train['label'].value_counts(normalize=True).sort_index().values # None\n",
    "\n",
    "print_header(\"Baseline model: other metrics\")\n",
    "\n",
    "instance.metric_dict1 = metric_dictionary(target=target1,\n",
    "                                          prediction=prediction1,\n",
    "                                          probabilities=probabilities1)\n",
    "\n",
    "instance.metric_dict_a = metric_dictionary(target=target_a,\n",
    "                                          prediction=prediction_a,\n",
    "                                          probabilities=probabilities_a)\n",
    "\n",
    "print(\"\\nOne image per lesion\".upper())\n",
    "display(pd.DataFrame(instance.metric_dict1))\n",
    "\n",
    "print(\"\\nAll images per lesion\".upper())\n",
    "display(pd.DataFrame(instance.metric_dict_a))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
