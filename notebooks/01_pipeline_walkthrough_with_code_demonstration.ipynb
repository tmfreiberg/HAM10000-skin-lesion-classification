{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e87e96cb",
   "metadata": {},
   "source": [
    "<a id='contents'></a>\n",
    "## Contents\n",
    "\n",
    "* [Setup](#setup)\n",
    "* [Loading and processing metadata](#loading_and)\n",
    "* [Class distribution](#class_distribution)\n",
    "* [Train/val split](#trainval_split)\n",
    "* [Balancing the training set](#balancing)\n",
    "* [Expanding the validation set](#expanding)\n",
    "* [Fine-tuning EfficientNet or ResNet18](#fine-tuning)\n",
    "* [Small sample for testing code](#small_sample)\n",
    "* [Model architecture and state dictionary](#model_architecture)\n",
    "* [Inference: getting probabilities](#inference1)\n",
    "* [Inference: combining probabilities](#inference2)\n",
    "* [Inference: combining predictions](#inference3)\n",
    "* [Evaluation](#evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d048e7",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## Setup\n",
    "↑↑ [Contents](#contents) ↓ [Loading and processing metadata](#loading_and)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd75325",
   "metadata": {},
   "source": [
    "The code cell below appears at the top of each notebook. \n",
    "\n",
    "1. **Environment Variable Setup:**\n",
    "   - Checks if running on Google Colab (`COLAB_GPU` in `os.environ`).\n",
    "   - If on Colab, mounts Google Drive and sets `SKIN_LESION_CLASSIFICATION` environment variable.\n",
    "   - If not on Colab, expects `SKIN_LESION_CLASSIFICATION` environment variable set to project root on local system.\n",
    "\n",
    "2. **Path Definitions:**\n",
    "   - Defines `project_path` as a `Path` object representing project root using environment variable.\n",
    "\n",
    "3. **Custom Module Import Setup:**\n",
    "   - Defines `scripts_path` as relative path to `/scripts` directory within project.\n",
    "\n",
    "4. **Module Import Configuration:**\n",
    "   - Adds `scripts_path` to `sys.path` for Python module import search.\n",
    "\n",
    "5. **Importing Custom Modules:**\n",
    "   - Imports `path_setup.subfolders` function from custom `utils` module in `/scripts` directory.\n",
    "   - This function likely sets up a dictionary containing paths to all subdirectories in project root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c92e86b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path['project'] : D:\\projects\\skin-lesion-classification\n",
      "path['images'] : D:\\projects\\skin-lesion-classification\\images\n",
      "path['models'] : D:\\projects\\skin-lesion-classification\\models\n",
      "path['expository'] : D:\\projects\\skin-lesion-classification\\expository\n",
      "path['literature'] : D:\\projects\\skin-lesion-classification\\literature\n",
      "path['notebooks'] : D:\\projects\\skin-lesion-classification\\notebooks\n",
      "path['presentation'] : D:\\projects\\skin-lesion-classification\\presentation\n",
      "path['scripts'] : D:\\projects\\skin-lesion-classification\\scripts\n",
      "path['streamlit'] : D:\\projects\\skin-lesion-classification\\streamlit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# If we're using Google Colab, we set the environment variable to point to the relevant folder in our Google Drive:\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.environ['SKIN_LESION_CLASSIFICATION'] = '/content/drive/MyDrive/Colab Notebooks/skin-lesion-classification'\n",
    "\n",
    "# Otherwise, we use the environment variable on our local system:\n",
    "project_environment_variable = \"SKIN_LESION_CLASSIFICATION\"\n",
    "\n",
    "# Path to the root directory of the project:\n",
    "project_path = Path(os.environ.get(project_environment_variable))\n",
    "\n",
    "# Relative path to /scripts (from where custom modules will be imported):\n",
    "scripts_path = project_path.joinpath(\"scripts\")\n",
    "\n",
    "# Add this path to sys.path so that Python will look there for modules:\n",
    "sys.path.append(str(scripts_path))\n",
    "\n",
    "# Now import path_step from our custom utils module to create a dictionary to all subdirectories in our root directory:\n",
    "from utils import path_setup\n",
    "path = path_setup.subfolders(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16849006",
   "metadata": {},
   "source": [
    "<a id='loading_and'></a>\n",
    "## Loading and processing metadata\n",
    "↑↑ [Contents](#contents) ↑ [Setup](#setup) ↓ [Class distribution](#class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613a5669",
   "metadata": {},
   "source": [
    "We use the ```process``` class of our custom ```processing``` module to facilitate processing of metadata (metadata for all images is contained in the ```metadata.csv``` file). Most of the attributes of the ```process``` can be seen in the code cell below: we typically won't need to set all of them, but we list them to show the possibilities. \n",
    "\n",
    "For instance, we could specify ```restrict_to = {'dx' : ['mel', 'nv']}``` and ```to_classify = {'melanoma' : ['mel'], 'mole' : ['nv'] }```. This would effectively restrict our dataset to all images of all lesions with ```dx``` class either ```mel``` or ```nv```, then set up a ```mel``` versus ```nv``` binary classification problem. (Indeed, this will be one of things we do.)\n",
    "\n",
    "* ```tvr```: 'training set to validation set' ratio. This refers to the lesions in our dataset (7470 of them if we use the entire dataset). ```tvr = 3``` will result in approximately 75% of the lesions in our dataset being represented in the training set (that's 5601 lesions if we start with the whole dataset).\n",
    "\n",
    "* ```seed```: sets a random seed to be used whenever randomness is used in a processing step, such as shuffling the records at the beginning of the train/val split.\n",
    "\n",
    "* ```keep_first```: there are 7470 distinct lesions represented by 10015 different images, because some lesions are represented by multiple images. Thus, when performing the train/val split, for each lesion, we have a choice as to which image to select as the 'first' representative image of the lesion (which we'll label as ```t1```, but more on this later). If ```keep_first``` is ```True```, we select the first image corresponding to each lesion as its principal representative; if ```False```, we select a random image corresponding to each lesion as its principal representative.\n",
    "\n",
    "* ```stratified```: if ```True```, we perform a stratified train/val split, meaning that we first select lesions within each class according to ```tvr```/```seed```/```keep_first``` logic, then combine them; if ```False```, we select lesions from the dataset globally according to ```tvr```/```seed```/```keep_first``` logic. Either way, the overall distribution of lesions by class will be more-or-less preserved in the training and validation sets, but it will be more exact if we perform a stratified split (as we always will).\n",
    "\n",
    "* ```train_one_img_per_lesion```: if ```True```, each lesion will be represented by precisely one image in the training set, meaning that a model will only ever see one image of each lesion during training; if ```False```, each lesion may be represented by more than one image in the training set (if there is more than one image of the lesion in our original dataset), and a model therefore may see more than one image of the lesion. If we balance the training set (see below), by upsampling lesions, this will be done by sampling one single image of each lesion multiple times if ```train_one_img_per_lesion``` is ```True```. However, if ```train_one_img_per_lesion``` is ```False``` and we balance the training set, for any given lesion we will select all the different images we have of it before sampling the exact same image another time. We'll go into this in detail below.\n",
    "\n",
    "* ```val_expansion_factor```: if a positive integer $n$, this will cause each lesion in the validation set to be repeated $n$ times, meaning that $n$ images (not necessarily all different) of the lesion will be passed to the model in the evaluation stage, to obtain $n$ sets of probabilities for each of the classes. If $n > 1$, we would combine the $n$ sets of probabilities and predictions into a single prediction for each lesion. As with balancing the training set, there are two ways we can 'expand' the validation set: we can have the exact same image of the lesion repeated $n$ times, or we can use all available images before repeating an image another time. There's no attribute for specifying, becase we will always just do both. If ```val_expansion_factor``` is ```None```, the 'all images per lesion' validation set will use all available images of each lesion (which will vary from lesion to lesion), and combine predictions into a single prediction for each lesion. Note that if we apply a random transformation to an image before it is fed to our model, that means the model will give different sets of probabilities for each image of a lesion, even if we're validating on the exact same image repeated $n$ times. We'll go into this in more detail below.\n",
    "\n",
    "* ```sample_size```: we can specify how many images from each lesion class we want to use to train our model. We've just discussed the two different ways we can oversample lesions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1200a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type, Union      # For type hints\n",
    "from processing import process      # Custom module for processing metadata\n",
    "\n",
    "data_dir: Path = path[\"images\"]     # Path to directory containing metadata.csv file\n",
    "csv_filename: str = \"metadata.csv\"  # The filename\n",
    "    \n",
    "restrict_to: Union[dict, None] = None                   # Remove all records *unless* column k lies in list v, for k : v in restrict_to dictionary.    \n",
    "remove_if: Union[dict, None] = None                     # Remove all records if column k lies in list v, for k : v in remove_if dictionary.    \n",
    "drop_row_if_missing_value_in: Union[list, None] = None  # We drop all rows for which there is a missing value in a column from this list.   \n",
    "                                    \n",
    "tvr: int = 3              # Ratio of training set to validation set. See discussion below for explanation.\n",
    "seed: int = 0             # Random seed for parts of the process where randomness is called for.\n",
    "keep_first: bool = False  # If False, then, for each lesion, we choose a random image to assign to our training set. \n",
    "stratified: bool = True   # If True, we stratify classes so that the proportions remain as stable as possible after train/val split. \n",
    "                          # If False, the proportions will be roughly similar.\n",
    "\n",
    "to_classify: Union[list, dict] = [\"mel\",   # These are the lesion types we are interested in classifying. \n",
    "                                  \"bcc\",   # Any missing ones will be grouped together as the 0-label class: no need to write \"other\" here.\n",
    "                                  \"akiec\", # If 'other' is not desired, use restrict_to attribute above\n",
    "                                  \"nv\",]   # Can also be a dictionary, like { 'malignant' : ['mel', 'bcc'], 'benign' : ['nv', 'bkl']}\n",
    "\n",
    "train_one_img_per_lesion: Union[bool, None] = False # If False, we take advantage of the (in some cases) multiple images of a lesion in our dataset\n",
    "val_expansion_factor: Union[int, None] = 3          # A random transformation may be applied to an image before making a prediction.\n",
    "                                                    # For a given lesion, we may make multiple predictions (as specified here), and combine them into a single prediction.\n",
    "    \n",
    "sample_size: Union[None, dict] = {\"mel\": 2000,     # Handling class imbalance by upsampling minority classes/downsampling majority classes     \n",
    "                                  \"bcc\": 2000,     # Specify how many images of each lesion diagnosis we want in our training set.\n",
    "                                  \"akiec\": 2000, \n",
    "                                  \"nv\": 2000,\n",
    "                                  \"other\" : 2000,} # Could also leave out \"other\" here, and include e.g. \"df: 2000\" if we wanted to.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdac7831",
   "metadata": {},
   "source": [
    "Having set the attributes above, we can now create an isntance of the ```process``` class, as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbcb4935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded file 'D:\\projects\\skin-lesion-classification\\images\\metadata.csv'.\n",
      "- Inserted 'num_images' column in dataframe, to the right of 'lesion_id' column.\n",
      "- Inserted 'label' column in dataframe, to the right of 'dx' column: \n",
      "  {'bkl': 0, 'df': 0, 'vasc': 0, 'akiec': 1, 'bcc': 2, 'mel': 3, 'nv': 4}\n",
      "- Added 'set' column to dataframe, with values 't1', 'v1', 'ta', and 'va', to the right of 'localization' column.\n",
      "- Basic, overall dataframe (pre-train/test split): self.df\n",
      "- Balancing classes in training set.\n",
      "- Balanced training set (uses as many different images per lesion as possible): self.df_train\n",
      "- Expanding validation set: will combine 3 predictions into one, for each lesion in val set.\n",
      "- Expanded validation set (one image per lesion, repeated 3 times): self.df_val1\n",
      "- Expanded validation set (use up to 3 different images per lesion, if available): self.df_val_a\n",
      "- Small sample dataframes for code testing: self._df_train_code_test, self._df_val1_code_test, self._df_val_a_code_test\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the process class with attribute values as above.\n",
    "demo = process(data_dir=data_dir,\n",
    "               csv_filename=csv_filename,\n",
    "               restrict_to=restrict_to,\n",
    "               remove_if=remove_if,\n",
    "               drop_row_if_missing_value_in=drop_row_if_missing_value_in,\n",
    "               tvr=tvr,\n",
    "               seed=seed,\n",
    "               keep_first=keep_first,\n",
    "               stratified=stratified,\n",
    "               to_classify=to_classify,\n",
    "               train_one_img_per_lesion=train_one_img_per_lesion,\n",
    "               val_expansion_factor=val_expansion_factor,\n",
    "               sample_size=sample_size,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f101b2",
   "metadata": {},
   "source": [
    "At this stage, we will just point out the mappings ```{'bkl': 0, 'df': 0, 'vasc': 0, 'akiec': 1, 'bcc': 2, 'mel': 3, 'nv': 4}``` (in this example). The three lesion classes get mapped to ```other``` in this classification task we've specified. It's important to maintain consistency of the mappings across the entire training and validation process, which is why we've taken care to order the lesion classes alphabetically, regardless of the way a user might specify the ```to_classify``` attribute. Labels are encoded according the the ```label_codes``` attribute of the ```process``` class: if there is an ```other``` class, it is always encoded as ```0```, then the other class names are encoded in alphabetical order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3850216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'other', 1: 'akiec', 2: 'bcc', 3: 'mel', 4: 'nv'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.label_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0205ff",
   "metadata": {},
   "source": [
    "<a id='class_distribution'></a>\n",
    "## Class distribution\n",
    "↑↑ [Contents](#contents) ↑ [Loading and processing metadata](#loading_and) ↓ [Train/val split](#trainval_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fcffca",
   "metadata": {},
   "source": [
    "We can use the ```dx_dist``` method of the ```process``` class to tabulate the distribution of lesions by class, and also of images by class. Below, we can see that our stratified train/val split has preserved relative proportions of the five classes by lesion. We can also see the distribution of images by class: note that it is different from the distribution of lesions by class, and not necessarily preserved, because for certain classes (like melanoma) there are more likely to be multiple images per lesion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b841851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "DISTRIBUTION OF LESIONS BY DIAGNOSIS: OVERALL\n",
      "=============================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5403.00</td>\n",
       "      <td>898.00</td>\n",
       "      <td>614.00</td>\n",
       "      <td>327.00</td>\n",
       "      <td>228.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>72.33</td>\n",
       "      <td>12.02</td>\n",
       "      <td>8.22</td>\n",
       "      <td>4.38</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv   other     mel     bcc   akiec\n",
       "freq  5403.00  898.00  614.00  327.00  228.00\n",
       "%       72.33   12.02    8.22    4.38    3.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lesions: 7470.\n",
      "\n",
      "\n",
      "===========================================\n",
      "DISTRIBUTION OF LESIONS BY DIAGNOSIS: TRAIN\n",
      "===========================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4052.00</td>\n",
       "      <td>673.00</td>\n",
       "      <td>460.00</td>\n",
       "      <td>245.00</td>\n",
       "      <td>171.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>72.34</td>\n",
       "      <td>12.02</td>\n",
       "      <td>8.21</td>\n",
       "      <td>4.37</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv   other     mel     bcc   akiec\n",
       "freq  4052.00  673.00  460.00  245.00  171.00\n",
       "%       72.34   12.02    8.21    4.37    3.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lesions: 5601 (74.98% of all lesions).\n",
      "\n",
      "\n",
      "=========================================\n",
      "DISTRIBUTION OF LESIONS BY DIAGNOSIS: VAL\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1351.00</td>\n",
       "      <td>225.00</td>\n",
       "      <td>154.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>57.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>72.28</td>\n",
       "      <td>12.04</td>\n",
       "      <td>8.24</td>\n",
       "      <td>4.39</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv   other     mel    bcc  akiec\n",
       "freq  1351.00  225.00  154.00  82.00  57.00\n",
       "%       72.28   12.04    8.24   4.39   3.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lesions: 1869 (25.02% of all lesions).\n",
      "\n",
      "\n",
      "============================================\n",
      "DISTRIBUTION OF IMAGES BY DIAGNOSIS: OVERALL\n",
      "============================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6705.00</td>\n",
       "      <td>1356.00</td>\n",
       "      <td>1113.00</td>\n",
       "      <td>514.00</td>\n",
       "      <td>327.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>66.95</td>\n",
       "      <td>13.54</td>\n",
       "      <td>11.11</td>\n",
       "      <td>5.13</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv    other      mel     bcc   akiec\n",
       "freq  6705.00  1356.00  1113.00  514.00  327.00\n",
       "%       66.95    13.54    11.11    5.13    3.27"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 10015.\n",
      "\n",
      "\n",
      "==========================================\n",
      "DISTRIBUTION OF IMAGES BY DIAGNOSIS: TRAIN\n",
      "==========================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5007.00</td>\n",
       "      <td>1008.00</td>\n",
       "      <td>831.00</td>\n",
       "      <td>384.00</td>\n",
       "      <td>250.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>66.94</td>\n",
       "      <td>13.48</td>\n",
       "      <td>11.11</td>\n",
       "      <td>5.13</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv    other     mel     bcc   akiec\n",
       "freq  5007.00  1008.00  831.00  384.00  250.00\n",
       "%       66.94    13.48   11.11    5.13    3.34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 7480 (74.69% of all images).\n",
      "\n",
      "\n",
      "========================================\n",
      "DISTRIBUTION OF IMAGES BY DIAGNOSIS: VAL\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1698.00</td>\n",
       "      <td>348.00</td>\n",
       "      <td>282.00</td>\n",
       "      <td>130.00</td>\n",
       "      <td>77.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>66.98</td>\n",
       "      <td>13.73</td>\n",
       "      <td>11.12</td>\n",
       "      <td>5.13</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv   other     mel     bcc  akiec\n",
       "freq  1698.00  348.00  282.00  130.00  77.00\n",
       "%       66.98   13.73   11.12    5.13   3.04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 2535 (25.31% of all images).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for across in [\"lesions\", \"images\"]:\n",
    "    for subset in [\"all\", \"train\", \"val\"]:\n",
    "        process.dx_dist(demo, subset = subset, across = across)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86793889",
   "metadata": {},
   "source": [
    "<a id='trainval_split'></a>\n",
    "## Train/val split\n",
    "↑↑ [Contents](#contents) ↑ [Class distribution](#class_distribution) ↓ [Balancing the training set](#balancing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efbbd9e",
   "metadata": {},
   "source": [
    "<!-- <details>\n",
    "    <summary><b><i>Train test split explanation: click here to expand/collapse</i></b></summary> -->\n",
    "    \n",
    "We partition our dataset based on ```lesion_id```, **not** on ```image_id```: that way, every lesion will be represented in training or in validation, but not both.\n",
    "\n",
    "For each classification task, we will train a model by making use of\n",
    "* **exactly one** image for every lesion in our training set;\n",
    "* **all** images of every lesion in our training set.\n",
    "\n",
    "In both cases, we will vaildate our model by making use of \n",
    "* **exactly one** image for every lesion in our validation set;\n",
    "* **all** images of every lesion in our validation set (at least, _potentially_ all of them). \n",
    "\n",
    "**However**, we will make only one prediction per lesion (```lesion_id```) in our validation set: if there are multiple images of a lesion in the validation set, we will combine the predictions for the multiple images into a single prediction for the lesion.\n",
    "\n",
    "Accordingly, we proceed as follows. We'll explain by example, assuming the dataset is not filtered before splitting (if it is, the number of distinct lesions will be less than $7470$, and the proportions will be different).\n",
    "1. Randomly select (without replacement) a proportion of our $7470$ distinct ```lesion_id```s and label them with ```t``` (train). \n",
    "2. Label the remaining ```lesion_id```s with ```v``` (validate).\n",
    "3. For each ```lesion_id``` labeled with a ```t```:\n",
    "    * Select an ```image_id``` and label it ```t1```.\n",
    "    * Label all (if any) remaining ```image_id```s corresponding to this ```lesion_id``` with ```ta```.\n",
    "4.  For each ```lesion_id``` labeled with a ```v```:\n",
    "    * Select an ```image_id``` and label it ```v1```.\n",
    "    * Label all (if any) remaining ```image_id```s corresponding to this ```lesion_id``` with ```va```.\n",
    "\n",
    "In Step 1, the number of ```lesion_id```s randomly selected to be labeled ```t``` will be such that the ratio of ```t```s to ```v```s is as close as possible to a specified ratio ```tvr``` (we default to $3$, i.e. $\\approx75\\%$ of lesions are represented in training). In Steps 3 and 4, the first substep can be done randomly (our default choice), or we can simply choose the \"first\" image in our table that corresponds to the lesion (see ```keep_first``` attribute of the ```process``` class). \n",
    "\n",
    "The four train/val scenarios we could consider are:\n",
    "* ```t1v1```: train on precisely those images labeled ```t1``` and validate on precisely those labeled ```v1```.\n",
    "* ```t1va```: train on precisely those images labeled ```t1``` and validate on precisely those labeled ```v1``` **or** ```va```.\n",
    "* ```tav1```: train on precisely those images labeled ```t1``` **or** ```ta``` and validate on precisely those labeled ```v1```.\n",
    "* ```tava```: train on precisely those images labeled ```t1``` **or** ```ta``` and validate on precisely those labeled ```v1``` ***or*** ```va```.\n",
    "\n",
    "The mnemonic is ```t``` for training, ```v``` for validation, ```1``` for one-image-per-lesion, and ```a``` for all images.\n",
    "<!-- </details> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f71744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================\n",
      "FIRST FIVE ROWS OF METADATA TABLE\n",
      "=================================\n",
      "\n",
      "ADDED COLUMNS\n",
      "\n",
      "- 'num_images': number of images of lesion in dataset\n",
      "- 'label': class to which lesion belongs\n",
      "- 'set': train/val assignment\n",
      "- 't*': lesion is in the training set\n",
      "- 'v*': lesion is in the validation set\n",
      "- 't1': we would train on this image if training a model on exactly one, or on all, image(s) per lesion in the training set\n",
      "- If training set is balanced using one image per lesion, this one image would be re-used as many times as necessary.\n",
      "- 'ta': we would train on this image if training a model on all images of each lesion in the training set\n",
      "- If training set is balanced using all images per lesion, images labeled ta would all be used before any image is repeated.\n",
      "- 'v1': we'd use this image if validating a model on exactly one, or on all, image(s) per lesion in the validation set\n",
      "- If a validation expansion factor is given, this one image would be re-used that many times\n",
      "- 'va': we'd use this image if validating on all images of each lesion in the validation set\n",
      "- If a validation expansion factor is given, iamges labeled va would all be used before any image is repeated.\n",
      "- NB: if more than one image is used for any lesion in validation, the predictions will be combined into a single prediction\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  num_images      image_id   dx  label dx_type   age   sex  \\\n",
       "0  HAM_0000118           2  ISIC_0027419  bkl      0   histo  80.0  male   \n",
       "1  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "2  HAM_0002730           2  ISIC_0026769  bkl      0   histo  80.0  male   \n",
       "3  HAM_0002730           2  ISIC_0025661  bkl      0   histo  80.0  male   \n",
       "4  HAM_0001466           2  ISIC_0031633  bkl      0   histo  75.0  male   \n",
       "\n",
       "  localization set  \n",
       "0        scalp  ta  \n",
       "1        scalp  t1  \n",
       "2        scalp  va  \n",
       "3        scalp  v1  \n",
       "4          ear  va  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's have a look at our metadata dataframe, which is now just an attribute of the metadata instance of the process class.\n",
    "from utils import print_header\n",
    "\n",
    "instance = demo\n",
    "df = instance.df\n",
    "\n",
    "print_header(\"First five rows of metadata table\")\n",
    "\n",
    "to_print = [\"Added columns\\n\".upper(), \n",
    "            \"\\'num_images\\': number of images of lesion in dataset\", \n",
    "            \"\\'label\\': class to which lesion belongs\",\n",
    "            \"\\'set\\': train/val assignment\",\n",
    "            \"\\'t*\\': lesion is in the training set\",\n",
    "            \"\\'v*\\': lesion is in the validation set\",\n",
    "            \"\\'t1\\': we would train on this image if training a model on exactly one, or on all, image(s) per lesion in the training set\",\n",
    "            \"If training set is balanced using one image per lesion, this one image would be re-used as many times as necessary.\",\n",
    "            \"\\'ta\\': we would train on this image if training a model on all images of each lesion in the training set\",\n",
    "            \"If training set is balanced using all images per lesion, images labeled ta would all be used before any image is repeated.\",\n",
    "            \"\\'v1': we\\'d use this image if validating a model on exactly one, or on all, image(s) per lesion in the validation set\",\n",
    "            \"If a validation expansion factor is given, this one image would be re-used that many times\",\n",
    "            \"\\'va': we\\'d use this image if validating on all images of each lesion in the validation set\" ,\n",
    "            \"If a validation expansion factor is given, iamges labeled va would all be used before any image is repeated.\",\n",
    "            \"NB: if more than one image is used for any lesion in validation, the predictions will be combined into a single prediction\"\n",
    "           ]\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb0736c",
   "metadata": {},
   "source": [
    "<a id='balancing'></a>\n",
    "## Balancing the training set\n",
    "↑↑ [Contents](#contents) ↑ [Train/val split](#trainval_split) ↓ [Expanding the validation set](#expanding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f4cb43",
   "metadata": {},
   "source": [
    "<!-- <details>\n",
    "    <summary><b><i>Balancing/upsampling explanation: click here to expand/collapse</i></b></summary> -->\n",
    "\n",
    "We explain the balancing procedure by way of example. (This is performed by the ```balance``` method of the ```process``` class in our ```processing``` module.) We assume the dataset has not been filtered, training to validation ratio is $3$, etc. There are $460$ distinct melanoma lesions represented in our training set. As most melanoma are represented by multiple distinct images, there are a total of $831$ distinct images of melanoma lesions in our training set. Suppose we want our training set to contain $2000$ melanoma images: each of the $460$ distinct melanoma lesions will be represented by $2000/460 \\approx 4.35$ images on average. We do not merely sample with replacement.\n",
    "\n",
    "The goal is to (a) have as little variance as possible in the number of times a lesion is represented, and (b) use as many distinct images as possible (taking advantage of the fact that there are multiple _distinct_ images of most melanoma). Thus, we note that $2000 = 4\\times 460 + 160$, so we will use each of the $460$ distinct melanoma lesions four times, and make the remainder up by randomly sample $160$ distinct lesions from the $160$. In other words, exactly $300$ distinct lesions will each be represented by exactly four images, and exactly $160$ distinct lesions will each be represented by exactly five images: $2000 = 300 \\times 4 + 160 \\times 5$. \n",
    "\n",
    "How do we select the four images of each distinct melanoma lesion (plus another one image for $160$ of them)? Consider lesion id ```HAM_0000871``` for example: there are three distinct images of this lesion in our data set. Thus, if ```train_one_img_per_lesion``` is ```False```, we will use all three of them, and then randomly select one more (or two more if this particular lesion were to be one of the $160$ that are represented five times). See below. On the other hand, if ```train_one_img_per_lesion``` is ```True```, we have no choice but to use the one image (label ```t1```) four times.\n",
    "    \n",
    "<!-- </details> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c4a51e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "EG: REPRESENTATIONS OF LESION HAM_0000871 IN BALANCED TRAINING SET\n",
      "==================================================================\n",
      "\n",
      "HAM_0000871 REPRESENTED BY FOUR IMAGES\n",
      "\n",
      "- Three distinct images of this lesion to choose from: ISIC_0025964, ISIC_0030623, and ISIC_0025964\n",
      "- Use ISIC_0025964 once, ISIC_0030623 twice, and ISIC_0025964 once\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0025964</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0025964</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0030623</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3088</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0026506</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>trunk</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id  lesion_mult  num_images      image_id  img_mult   dx  \\\n",
       "1773  HAM_0000871            4           3  ISIC_0025964         2  mel   \n",
       "1774  HAM_0000871            4           3  ISIC_0025964         2  mel   \n",
       "1775  HAM_0000871            4           3  ISIC_0030623         1  mel   \n",
       "3088  HAM_0000871            4           3  ISIC_0026506         1  mel   \n",
       "\n",
       "      label dx_type   age     sex localization set  \n",
       "1773      3   histo  40.0  female        chest  ta  \n",
       "1774      3   histo  40.0  female        chest  ta  \n",
       "1775      3   histo  40.0  female        chest  t1  \n",
       "3088      3   histo  40.0  female        trunk  ta  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "\n",
    "# The specific numbers in this example assume a certain choice for the attributes, including \n",
    "# sample_size: Union[None, dict] = {\"mel\": 2000,         \n",
    "#                                   \"bcc\": 2000, \n",
    "#                                   \"akiec\": 2000, \n",
    "#                                   \"nv\": 2000,\n",
    "#                                   \"other\" : 2000,}\n",
    "\n",
    "instance = demo\n",
    "df = demo.df_train\n",
    "\n",
    "print_header(\"Eg: Representations of lesion HAM_0000871 in balanced training set\")\n",
    "\n",
    "to_print = [\"HAM_0000871 represented by four images\\n\".upper(),\n",
    "            \"Three distinct images of this lesion to choose from: ISIC_0025964, ISIC_0030623, and ISIC_0025964\",\n",
    "            \"Use ISIC_0025964 once, ISIC_0030623 twice, and ISIC_0025964 once\",]\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "display(df[df['lesion_id'] == 'HAM_0000871'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a797a173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================\n",
      "EG: MELANOMA IN BALANCED TRAINING SET\n",
      "=====================================\n",
      "\n",
      "VALUE COUNTS FOR 'LESION_MULT' COLUMN\n",
      "\n",
      "- 300 distinct melanoma lesions each represented by four images: 300*4 = 1200\n",
      "- 160 distinct melanoma lesions each represented by five images: 160*5 = 800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4    1200\n",
       "5     800\n",
       "Name: lesion_mult, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0025964</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0025964</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0030623</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>HAM_0000040</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0027190</td>\n",
       "      <td>5</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>HAM_0000040</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0027190</td>\n",
       "      <td>5</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7773</th>\n",
       "      <td>HAM_0002552</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0032936</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7774</th>\n",
       "      <td>HAM_0002552</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0032936</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7780</th>\n",
       "      <td>HAM_0002552</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0033232</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>HAM_0003521</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0032258</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>HAM_0003521</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0032258</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id  lesion_mult  num_images      image_id  img_mult   dx  \\\n",
       "1773  HAM_0000871            4           3  ISIC_0025964         2  mel   \n",
       "1774  HAM_0000871            4           3  ISIC_0025964         2  mel   \n",
       "1775  HAM_0000871            4           3  ISIC_0030623         1  mel   \n",
       "1776  HAM_0000040            5           1  ISIC_0027190         5  mel   \n",
       "1777  HAM_0000040            5           1  ISIC_0027190         5  mel   \n",
       "...           ...          ...         ...           ...       ...  ...   \n",
       "7773  HAM_0002552            5           3  ISIC_0032936         2  mel   \n",
       "7774  HAM_0002552            5           3  ISIC_0032936         2  mel   \n",
       "7780  HAM_0002552            5           3  ISIC_0033232         1  mel   \n",
       "9998  HAM_0003521            5           2  ISIC_0032258         2  mel   \n",
       "9999  HAM_0003521            5           2  ISIC_0032258         2  mel   \n",
       "\n",
       "      label dx_type   age     sex     localization set  \n",
       "1773      3   histo  40.0  female            chest  ta  \n",
       "1774      3   histo  40.0  female            chest  ta  \n",
       "1775      3   histo  40.0  female            chest  t1  \n",
       "1776      3   histo  80.0    male  upper extremity  t1  \n",
       "1777      3   histo  80.0    male  upper extremity  t1  \n",
       "...     ...     ...   ...     ...              ...  ..  \n",
       "7773      3   histo  25.0    male  upper extremity  ta  \n",
       "7774      3   histo  25.0    male  upper extremity  ta  \n",
       "7780      3   histo  25.0    male  upper extremity  ta  \n",
       "9998      3   histo  70.0  female             back  ta  \n",
       "9999      3   histo  70.0  female             back  ta  \n",
       "\n",
       "[2000 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "# The specific numbers given in this example assume a certain choice for the attributes, including \n",
    "# sample_size: Union[None, dict] = {\"mel\": 2000,         \n",
    "#                                   \"bcc\": 2000, \n",
    "#                                   \"akiec\": 2000, \n",
    "#                                   \"nv\": 2000,\n",
    "#                                   \"other\" : 2000,}\n",
    "\n",
    "instance = demo\n",
    "df = demo.df_train\n",
    "df = df[df['set'].isin([\"ta\", \"t1\"]) & (df['dx'] == 'mel')]\n",
    "\n",
    "print_header(\"Eg: Melanoma in balanced training set\")\n",
    "\n",
    "to_print = [\"Value counts for \\'lesion_mult\\' column\\n\".upper(),\n",
    "            \"300 distinct melanoma lesions each represented by four images: 300*4 = 1200\",\n",
    "            \"160 distinct melanoma lesions each represented by five images: 160*5 = 800\",]\n",
    "\n",
    "print(\"\\n- \".join(to_print[:3]))\n",
    "display(df['lesion_mult'].value_counts())\n",
    "\n",
    "print(\"\\n- \".join(to_print[3:]))\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3d5ede",
   "metadata": {},
   "source": [
    "<a id='expanding'></a>\n",
    "## Expanding the validation set\n",
    "↑↑ [Contents](#contents) ↑ [Balancing the training set](#balancing) ↓ [Fine-tuning EfficientNet or ResNet18](#fine-tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5f3b8",
   "metadata": {},
   "source": [
    "As mentioned already, we make one prediction per lesion. However, we may have multiple images of a given lesion at our disposal: we could make a prediction for each of them and combine them somehow into a single prediction for the lesion. Even if there is only one image of a lesion, we could make multiple predictions on it: if a random transformation is applied to an image before our model makes a prediction on it, this would yield a different array of probabilities each time. Again, we could combine the results into a single prediction.\n",
    "\n",
    "This is what the attribute ```val_expansion_factor``` of the ```process``` class is concerned with. Similarly to the way we balance the training set, we can replicate one single image per lesion in the validation set as many times as specified by ```val_expansion_factor```, as in ```self.df_val1```, or we can take advantage of other images of the lesion (if available), as in ```self.val_a```.\n",
    "\n",
    "Note that if ```val_expansion_factor``` is set to a positive integer $n$, both validation sets ```self.df_val1``` and ```self.df_val_a``` will have the same number of records ($n$ times the number of lesions in the validation set), because each lesion will be represented by $n$ images. However, if ```val_expansion_factor``` is ```None``` (which is the default), then ```self.df_val_a``` will just contain all images of each lesion in the validation set (and the number of images of a given lesion may vary from one to six)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25bef7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "EG: MELANOMA IN EXPANDED VALIDATION SET (ONLY ONE IMAGE PER LESION USED)\n",
      "========================================================================\n",
      "\n",
      "- Note that 'lesion_mult' is always 3\n",
      "- HAM_0005678 represented by three images\n",
      "- Two distinct images of this lesion: ISIC_0031023 and ISIC_0028086\n",
      "- However, only use ISIC_0031023 (3 times)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>HAM_0006722</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031499</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>HAM_0006722</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031499</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>HAM_0004081</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0031957</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>HAM_0004081</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0031957</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028764</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028764</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028764</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id  lesion_mult  num_images      image_id  img_mult   dx  \\\n",
       "603   HAM_0005678            3           2  ISIC_0031023         3  mel   \n",
       "604   HAM_0005678            3           2  ISIC_0031023         3  mel   \n",
       "605   HAM_0005678            3           2  ISIC_0031023         3  mel   \n",
       "606   HAM_0006722            3           2  ISIC_0031499         3  mel   \n",
       "607   HAM_0006722            3           2  ISIC_0031499         3  mel   \n",
       "...           ...          ...         ...           ...       ...  ...   \n",
       "1060  HAM_0004081            3           1  ISIC_0031957         3  mel   \n",
       "1061  HAM_0004081            3           1  ISIC_0031957         3  mel   \n",
       "1062  HAM_0004746            3           2  ISIC_0028764         3  mel   \n",
       "1063  HAM_0004746            3           2  ISIC_0028764         3  mel   \n",
       "1064  HAM_0004746            3           2  ISIC_0028764         3  mel   \n",
       "\n",
       "      label dx_type   age     sex     localization set  \n",
       "603       3   histo  60.0    male            chest  v1  \n",
       "604       3   histo  60.0    male            chest  v1  \n",
       "605       3   histo  60.0    male            chest  v1  \n",
       "606       3   histo  85.0  female  lower extremity  v1  \n",
       "607       3   histo  85.0  female  lower extremity  v1  \n",
       "...     ...     ...   ...     ...              ...  ..  \n",
       "1060      3   histo  70.0  female  lower extremity  v1  \n",
       "1061      3   histo  70.0  female  lower extremity  v1  \n",
       "1062      3   histo  65.0  female             back  v1  \n",
       "1063      3   histo  65.0  female             back  v1  \n",
       "1064      3   histo  65.0  female             back  v1  \n",
       "\n",
       "[462 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================\n",
      "EG: MELANOMA IN EXPANDED VALIDATION SET (ALL IMAGES USED)\n",
      "=========================================================\n",
      "\n",
      "- Note that 'lesion_mult' is always 3\n",
      "- HAM_0005678 represented by three images\n",
      "- Two distinct images of this lesion to choose from: ISIC_0031023 and ISIC_0028086\n",
      "- Use ISIC_0031023 once, and ISIC_0028086 twice\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028086</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028086</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>HAM_0006722</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0030443</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>HAM_0006722</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031499</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0029021</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>HAM_0002525</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025188</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>HAM_0002525</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025188</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>HAM_0001953</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025611</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>HAM_0001953</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025611</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id  lesion_mult  num_images      image_id  img_mult   dx  \\\n",
       "603   HAM_0005678            3           2  ISIC_0031023         1  mel   \n",
       "604   HAM_0005678            3           2  ISIC_0028086         2  mel   \n",
       "605   HAM_0005678            3           2  ISIC_0028086         2  mel   \n",
       "606   HAM_0006722            3           2  ISIC_0030443         1  mel   \n",
       "607   HAM_0006722            3           2  ISIC_0031499         2  mel   \n",
       "...           ...          ...         ...           ...       ...  ...   \n",
       "1060  HAM_0004746            3           2  ISIC_0029021         1  mel   \n",
       "1061  HAM_0002525            3           2  ISIC_0025188         2  mel   \n",
       "1062  HAM_0002525            3           2  ISIC_0025188         2  mel   \n",
       "1063  HAM_0001953            3           2  ISIC_0025611         2  mel   \n",
       "1064  HAM_0001953            3           2  ISIC_0025611         2  mel   \n",
       "\n",
       "      label dx_type   age     sex     localization set  \n",
       "603       3   histo  60.0    male            chest  v1  \n",
       "604       3   histo  60.0    male            chest  va  \n",
       "605       3   histo  60.0    male            chest  va  \n",
       "606       3   histo  85.0  female  lower extremity  va  \n",
       "607       3   histo  85.0  female  lower extremity  v1  \n",
       "...     ...     ...   ...     ...              ...  ..  \n",
       "1060      3   histo  65.0  female             back  va  \n",
       "1061      3   histo  55.0    male             face  va  \n",
       "1062      3   histo  55.0    male             face  va  \n",
       "1063      3   histo  65.0    male             back  va  \n",
       "1064      3   histo  65.0    male             back  va  \n",
       "\n",
       "[462 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "# The specific numbers given in this example assume a certain choice for the attributes  \n",
    "\n",
    "instance = demo\n",
    "\n",
    "df = demo.df_val1\n",
    "df = df[df['set'].isin([\"va\", \"v1\"]) & (df['dx'] == 'mel')]\n",
    "\n",
    "print_header(\"Eg: Melanoma in expanded validation set (only one image per lesion used)\")\n",
    "\n",
    "to_print = [f\"- Note that \\'lesion_mult\\' is always {instance.val_expansion_factor}\",\n",
    "            \"HAM_0005678 represented by three images\",\n",
    "            \"Two distinct images of this lesion: ISIC_0031023 and ISIC_0028086\",\n",
    "            f\"However, only use ISIC_0031023 ({instance.val_expansion_factor} times)\",]\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "display(df)\n",
    "\n",
    "df = demo.df_val_a\n",
    "df = df[df['set'].isin([\"va\", \"v1\"]) & (df['dx'] == 'mel')]\n",
    "\n",
    "print_header(\"Eg: Melanoma in expanded validation set (all images used)\")\n",
    "\n",
    "to_print = [f\"- Note that \\'lesion_mult\\' is always {instance.val_expansion_factor}\",\n",
    "            \"HAM_0005678 represented by three images\",\n",
    "            \"Two distinct images of this lesion to choose from: ISIC_0031023 and ISIC_0028086\",\n",
    "            \"Use ISIC_0031023 once, and ISIC_0028086 twice\",]\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d46cea",
   "metadata": {},
   "source": [
    "<a id='fine-tuning'></a>\n",
    "## Fine-tuning EfficientNet or ResNet18\n",
    "↑↑ [Contents](#contents) ↑ [Expanding the validation set](#expanding) ↓ [Small sample for testing code](#small_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fee7871",
   "metadata": {},
   "source": [
    "At this point we are ready to train a model on our processed data. We define a class called ```cnn``` in our custom ```multiclass_models``` module. Some of the attributes of the ```cnn``` class are list below. The first attribute is ```source```, which is an instance of the ```process``` class: the processed data gets fed into the model, and the instance of the ```cnn``` class effectively inherits all of the attributes of the ```process``` class. (It's also possible to just specify a dataframe as the source, but we won't discuss this.)\n",
    "\n",
    "The ```model``` attribute specifies whether to use ResNet model archtecture, or EfficientNet architecture. The ```transform``` attribute specifies any transformation we wish to apply to each image before the model is trained on it. If there is a random element to ```transform```, that means the model will 'see' different aspects of a lesion each time an images is passed through it, even if the exact same image is being used multiple times.\n",
    "\n",
    "Other attributes such as ```batch_size``` and ```base_learning_rate``` are self-explanatory. We use Adam optimzation always. Other attributes like ```filename_suffix``` are related to the creation of files to store output of the model (and record-keeping, such as model attributes), but we won't go into this here.\n",
    "\n",
    "```unfreeze_all```, if ```True```, will cause all layers of the model to be unfrozen for fine-tuning; otherwise, if ```unfreeze_last``` is ```True```, only the last block and fully-connected layer willl be unfrozen. Note that if ```unfreeze_all``` is ```True```, then all layers will be unfrozen, regardless of whether or not ```unfreeze_last``` is set as ```True``` (it will be overwritten). If not specified, ```unfreeze_all``` defaults to ```True``` (and ```unfreeze_last``` defaults to ```False```).\n",
    "\n",
    "The ```code_test``` attribute, if ```True```, switches to a mode that uses a small number of images for code-testing purposes, which is precisely what we're doing here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5aa1884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's set values for the attributes of our resnet18 class (the model we will use with out processed data).\n",
    "# One of the attributes has to do with image transformations.\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    \n",
    "transforms.RandomCrop((300, 300)),\n",
    "transforms.Resize((224,224)), # Resize images to fit ResNet input size\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet stats\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17a72b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Union, List, Callable\n",
    "import torchvision.models as models\n",
    "\n",
    "source: Union[process, pd.DataFrame] = demo      # Processed data to be fed into model for training.\n",
    "                                                 # Must either be an instance of the process class, or a dataframe of the same format as source.df if source were an instance of the process class.\n",
    "model_dir: Path = path[\"models\"]                 # Path to directory where models/model info/model results are stored.\n",
    "transform: Union[None, \n",
    "                 transforms.Compose, \n",
    "                 List[Callable]] = transform     # Transform to be applied to images before feeding into neural network.\n",
    "batch_size: Union[None, int] = 32                # Mini-batch size: default 32.\n",
    "epochs: Union[None, int] = 10                    # Number of epochs (all layers unfrozen from the start): default 10.\n",
    "base_learning_rate: Union[None, float] = 1/1000  # Learning rate to start with: default 1/1000. Using Adam optimizer.\n",
    "filename_stem: Union[None, str] = \"rn18\"         # For saving model and related files. Default \"rn18\" (if ResNet model) or \"EffNet\" (if EfficientNet), or \"cnn\".\n",
    "filename_suffix: Union[None, str] = \"demo\"       # Something descriptive and unique for future reference. Default empty string \"\".\n",
    "overwrite: Union[None, bool] = True              # If False, any will generate an unused filename for saving .pth, .csv files etc., but appending a two-digit number.\n",
    "                                                 # If None, will default to False. Only set to True if confident that training done on previous instances with same filename stem and suffix can be over-written.\n",
    "code_test: Union[None, bool] = True\n",
    "# model: Union[None, models.ResNet, models.EfficientNet] = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT) # Pre-trained model. Default: ResNet18.   \n",
    "model: Union[None, models.ResNet, models.EfficientNet] = models.resnet18(weights=\"ResNet18_Weights.DEFAULT\")  \n",
    "unfreeze_all: Union[None, bool] = None,\n",
    "unfreeze_last: Union[None, bool] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da0fe522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============\n",
      "CODE TEST MODE\n",
      "==============\n",
      "\n",
      "- self.epochs set to 1\n",
      "- self.Print set to True\n",
      "- self.filename_suffix set to 'test'\n",
      "- self.overwrite set to True\n",
      "- self.df_train, self.df_val1, self.df_val_a replaced with a small number of records\n",
      "- Change code_test attribute to False and re-create/create new cnn instance after testing is done.\n",
      "\n",
      "Existing files will be overwritten. \n",
      "Base filename: rn18_ta_bal_ufall_1e_demo_test_00\n",
      "Attributes saved to file: D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_ufall_1e_demo_test_00_attributes.json\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the resnet18 class with attribute values as above.\n",
    "from multiclass_models import cnn\n",
    "\n",
    "resnet_demo = cnn(                                   \n",
    "    source=source,                                           \n",
    "    model_dir=model_dir,\n",
    "    transform=transform,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,                                          \n",
    "    base_learning_rate=base_learning_rate,\n",
    "    filename_stem=filename_stem,\n",
    "    filename_suffix=filename_suffix,                         \n",
    "    overwrite=overwrite,\n",
    "    code_test=code_test,    \n",
    "    model=model, \n",
    "    unfreeze_all=unfreeze_all,\n",
    "    unfreeze_last=unfreeze_last,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b087606d",
   "metadata": {},
   "source": [
    "<a id='small_sample'></a>\n",
    "## Small sample for testing code\n",
    "↑↑ [Contents](#contents) ↑ [Fine-tuning EfficientNet or ResNet18](#fine-tuning) ↓ [Model architecture and state dictionary](#model_architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53700e57",
   "metadata": {},
   "source": [
    "We can look at the records in the 'training' and 'validation' sets of our code-testing data. These are created by randomly sampling 10 (respectively, two) records for each lesion class. Note that, therefore, for the code-testing, the two variants of the validation set (one image per lesion versus all images per lesion) will consist of different lesions. Of course, when we're not code-testing, the validation sets represent exactly the same lesions (the only difference lies in the images used to represent them). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7fa41b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================\n",
      "CODE TEST: TRAINING SET\n",
      "=======================\n",
      "\n",
      "169 IMAGES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0003768</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0029929</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0004928</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031424</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>neck</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0004928</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0029770</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>neck</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0004928</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0029770</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>neck</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0003768</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0026634</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  lesion_mult  num_images      image_id  img_mult   dx  label  \\\n",
       "0  HAM_0003768            3           2  ISIC_0029929         1  bkl      0   \n",
       "1  HAM_0004928            3           2  ISIC_0031424         1  bkl      0   \n",
       "2  HAM_0004928            3           2  ISIC_0029770         2  bkl      0   \n",
       "3  HAM_0004928            3           2  ISIC_0029770         2  bkl      0   \n",
       "4  HAM_0003768            3           2  ISIC_0026634         2  bkl      0   \n",
       "\n",
       "  dx_type   age   sex     localization set  \n",
       "0   histo  80.0  male  upper extremity  t1  \n",
       "1   histo  65.0  male             neck  t1  \n",
       "2   histo  65.0  male             neck  ta  \n",
       "3   histo  65.0  male             neck  ta  \n",
       "4   histo  80.0  male  upper extremity  ta  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "CODE TEST: VALIDATION SET (ONE IMAGE PER LESION, REPEATED 3 TIMES)\n",
      "==================================================================\n",
      "\n",
      "42 IMAGES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  lesion_mult  num_images      image_id  img_mult   dx  label  \\\n",
       "0  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "1  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "2  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "3  HAM_0000983            3           1  ISIC_0033490         3  bkl      0   \n",
       "4  HAM_0000983            3           1  ISIC_0033490         3  bkl      0   \n",
       "\n",
       "     dx_type   age      sex localization set  \n",
       "0  consensus  75.0     male         back  v1  \n",
       "1  consensus  75.0     male         back  v1  \n",
       "2  consensus  75.0     male         back  v1  \n",
       "3  consensus   NaN  unknown      unknown  v1  \n",
       "4  consensus   NaN  unknown      unknown  v1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "CODE TEST: VALIDATION SET (3 POSSIBLY DIFFERENT IMAGES PER LESION)\n",
      "==================================================================\n",
      "\n",
      "42 IMAGES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0034125</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0033060</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0033060</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0001200</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0025716</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001200</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0025716</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  lesion_mult  num_images      image_id  img_mult   dx  label  \\\n",
       "0  HAM_0004406            3           2  ISIC_0034125         1  bkl      0   \n",
       "1  HAM_0004406            3           2  ISIC_0033060         2  bkl      0   \n",
       "2  HAM_0004406            3           2  ISIC_0033060         2  bkl      0   \n",
       "3  HAM_0001200            3           1  ISIC_0025716         3  bkl      0   \n",
       "4  HAM_0001200            3           1  ISIC_0025716         3  bkl      0   \n",
       "\n",
       "  dx_type   age   sex localization set  \n",
       "0   histo  80.0  male         back  va  \n",
       "1   histo  80.0  male         back  v1  \n",
       "2   histo  80.0  male         back  v1  \n",
       "3   histo  85.0  male         face  v1  \n",
       "4   histo  85.0  male         face  v1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "print_header(\"Code test: training set\")\n",
    "print(f\"{instance.df_train.shape[0]} images\".upper())\n",
    "display(instance.df_train.head())\n",
    "\n",
    "print_header(f\"Code test: validation set (one image per lesion, repeated {instance.source.val_expansion_factor} times)\")\n",
    "print(f\"{instance.df_val1.shape[0]} images\".upper())\n",
    "display(instance.df_val1.head())\n",
    "\n",
    "print_header(f\"Code test: validation set ({instance.source.val_expansion_factor} possibly different images per lesion)\")\n",
    "print(f\"{instance.df_val_a.shape[0]} images\".upper())\n",
    "display(instance.df_val_a.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6916129",
   "metadata": {},
   "source": [
    "The ```cnn``` class of the ```multiclass_models``` module naturally revolves around the ```train``` method, which feeds our training set into a model for fine-tuning. Below, we do this for the small batch of images in our code-test training set. For a large number of images, a GPU should be used.\n",
    "\n",
    "Note that, as we're testing code, the ```train``` method prints out what is going through the dataloader. We can turn off this feature when training on a large number of images (it's the ```Print``` boolean attribute of the ```cnn``` class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f198de9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================\n",
      "CODE TEST: TRAINING AND VALIDATION\n",
      "==================================\n",
      "\n",
      "image_id, label, ohe-label: ISIC_0029770, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027149, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030230, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032114, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029099, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027598, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031831, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027598, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032652, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032652, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024932, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024997, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029099, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031526, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030142, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031728, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028076, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025302, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033975, 4, tensor([0., 0., 0., 0., 1.])\n",
      "outputs.shape: torch.Size([32, 5])\n",
      "loss: 1.6836050748825073\n",
      "image_id, label, ohe-label: ISIC_0024825, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029099, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028314, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027598, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0034219, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030142, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029929, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026634, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030230, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029891, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024997, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024973, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029514, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031669, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031424, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033860, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025927, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033991, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027149, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0031217, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025599, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027149, 4, tensor([0., 0., 0., 0., 1.])\n",
      "outputs.shape: torch.Size([32, 5])\n",
      "loss: 1.0920720100402832\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028076, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029480, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0031217, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026789, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028076, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033571, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025302, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031831, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031831, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025628, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032438, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031728, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033551, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033679, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024997, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028314, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032715, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031728, 2, tensor([0., 0., 1., 0., 0.])\n",
      "outputs.shape: torch.Size([32, 5])\n",
      "loss: 0.5896570086479187\n",
      "image_id, label, ohe-label: ISIC_0033571, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025628, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027149, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029770, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025345, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030953, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025927, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0025927, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028314, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029480, 4, tensor([0., 0., 0., 0., 1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id, label, ohe-label: ISIC_0024825, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033860, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033571, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033065, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028314, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030953, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033975, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0032652, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028076, 1, tensor([0., 1., 0., 0., 0.])\n",
      "outputs.shape: torch.Size([32, 5])\n",
      "loss: 0.3799683749675751\n",
      "image_id, label, ohe-label: ISIC_0032114, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031526, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025628, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030142, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027560, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033991, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025927, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024932, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0027672, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033679, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030953, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030953, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031526, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033551, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027560, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0025302, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026634, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030142, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033847, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030953, 1, tensor([0., 1., 0., 0., 0.])\n",
      "outputs.shape: torch.Size([32, 5])\n",
      "loss: 0.5710552930831909\n",
      "image_id, label, ohe-label: ISIC_0029278, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025927, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027672, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024973, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027560, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025713, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027560, 4, tensor([0., 0., 0., 0., 1.])\n",
      "outputs.shape: torch.Size([10, 5])\n",
      "loss: 0.474953830242157\n",
      "Validating (one image per lesion)...\n",
      "image_id, label, ohe-label: ISIC_0033305, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033305, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033305, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033490, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033490, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033490, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024991, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024991, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024991, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024937, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024937, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024937, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032410, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032410, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032410, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028735, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028735, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028735, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031498, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0031498, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0031498, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028930, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028930, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028930, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030956, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030956, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030956, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024867, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024867, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024867, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028739, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028739, 2, tensor([0., 0., 1., 0., 0.])\n",
      "outputs.shape: torch.Size([10, 5])\n",
      "val1_loss: 5.563993453979492\n",
      "image_id, label, ohe-label: ISIC_0028739, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029917, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029917, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029917, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026014, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026014, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026014, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027254, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027254, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027254, 1, tensor([0., 1., 0., 0., 0.])\n",
      "outputs.shape: torch.Size([10, 5])\n",
      "val1_loss: 6.8167829513549805\n",
      "Validating (all images per lesion)...\n",
      "image_id, label, ohe-label: ISIC_0034125, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033060, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033060, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025716, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025716, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025716, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027484, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027484, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027484, 3, tensor([0., 0., 0., 1., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id, label, ohe-label: ISIC_0026598, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026598, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026598, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031372, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031372, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026313, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026629, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026629, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026629, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030443, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0031499, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0031499, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0033299, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0033299, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0033299, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0032692, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033608, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033969, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028680, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028680, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028680, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027058, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030114, 2, tensor([0., 0., 1., 0., 0.])\n",
      "outputs.shape: torch.Size([10, 5])\n",
      "val_a_loss: 6.805344581604004\n",
      "image_id, label, ohe-label: ISIC_0030114, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026940, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032429, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029951, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028816, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028816, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028232, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024329, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024329, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024329, 1, tensor([0., 1., 0., 0., 0.])\n",
      "outputs.shape: torch.Size([10, 5])\n",
      "val_a_loss: 10.541035652160645\n",
      "Epoch 1/1, Training Loss: 0.7986, Validation Loss 1: 6.1904, Validation Loss a: 8.6732\n",
      "Saving model.state_dict() as D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_test_1e_test_00.pth.\n",
      "model.state_dict() can now be accessed through state_dict attribute.\n",
      "Train/val losses can now be accessed through epoch_losses attribute.\n",
      "Epoch losses dictionary save as D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_test_1e_test_00_epoch_losses.json\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the specified training data by calling the train method:\n",
    "# from utils import print_header\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "print_header(\"Code test: training and validation\")\n",
    "instance.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ba8946",
   "metadata": {},
   "source": [
    "Epoch losses will be stored in a ```.json``` file, which can be loaded as below (if the ```.json``` file with the exact filename created by the instance of the ```cnn``` class exists: if not, run everything again from the start, including the code-test training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a722d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========\n",
      "CODE TEST\n",
      "=========\n",
      "\n",
      "LOSS DICTIONARY (TRAINING AND VALIDATION LOSS FROM EACH EPOCH)\n",
      "- Key 'val1_loss' refers to validation set in which one image per lesion is used.\n",
      "- Key 'val_a_los' refers to validation set in which more than one image per lesion is potentially used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': array([0.79855193]),\n",
       " 'val1_loss': array([6.1903882]),\n",
       " 'val_a_loss': array([8.67319012])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import load_dict\n",
    "\n",
    "# Let's look at the training and validation loss for each epoch:\n",
    "instance = resnet_demo\n",
    "\n",
    "print_header(\"Code test\")\n",
    "print(\"Loss dictionary (training and validation loss from each epoch)\".upper())\n",
    "to_print = [\"- Key \\'val1_loss\\' refers to validation set in which one image per lesion is used.\",\n",
    "         \"Key \\'val_a_los\\' refers to validation set in which more than one image per lesion is potentially used.\"]\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "try:\n",
    "    if instance.epoch_losses is not None:\n",
    "        display(instance.epoch_losses)\n",
    "    else:\n",
    "        retrieved_epoch_losses = load_dict(instance.model_dir, instance._filename + \"_epoch_losses\")\n",
    "        display(retrieved_epoch_losses)\n",
    "except:\n",
    "    retrieved_epoch_losses = load_dict(instance.model_dir, instance._filename + \"_epoch_losses\")\n",
    "    display(retrieved_epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "573874be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========\n",
      "CODE TEST\n",
      "=========\n",
      "\n",
      "If we didn't just train the model and the epoch losses dictionary is not in memory, we can load it from a file during training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [0.798551931977272],\n",
       " 'val1_loss': [6.190388202667236],\n",
       " 'val_a_loss': [8.673190116882324]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import load_dict\n",
    "\n",
    "# Let's look at the training and validation loss for each epoch:\n",
    "instance = resnet_demo\n",
    "\n",
    "print_header(\"Code test\")\n",
    "print(\"If we didn't just train the model and the epoch losses dictionary is not in memory, we can load it from a file during training.\")\n",
    "\n",
    "display(load_dict(instance.model_dir, instance._filename + \"_epoch_losses\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272687e8",
   "metadata": {},
   "source": [
    "<a id='model_architecture'></a>\n",
    "## Model architecture and state dictionary\n",
    "↑↑ [Contents](#contents) ↑ [Small sample for testing code](#small_sample) ↓ [Inference: getting probabilities](#inference1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6183935d",
   "metadata": {},
   "source": [
    "We can examine our model architecture and parameters before/after training. Our ```cnn``` class of course modifies the fully connected (fc) layer of ResNet-18 or EfficientNetB0 to have the appropriate number of output features based on the number of classes. After training, it saves the model parameters in a ```.pth``` file, with a name given by the ```._filename``` attribute of the instance of the ```cnn``` class. If we want to load the trained model for making inferences or further fine-tuning, we need to call an instance of e.g. resnet18, modify the fc layer, and load our ```.pth``` file, as in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3552fe8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================\n",
      "CODE TEST: MODEL ARCHITECTURE\n",
      "=============================\n",
      "\n",
      "NOTE: 'OUT_FEATURES = 5' AT THE END\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "if instance.state_dict is None:\n",
    "    print(\"Loading model and state dictionary from file\\n\".upper())\n",
    "    file_path_pth = instance.model_dir.joinpath(instance._filename + \".pth\")\n",
    "\n",
    "    # model = models.efficientnet_b0()  \n",
    "    model = models.resnet18()  \n",
    "    if isinstance(model,models.ResNet):\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "    elif isinstance(model,models.EfficientNet):\n",
    "        num_ftrs = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "\n",
    "    # Load the state dictionary into the model\n",
    "    state_dict = torch.load(file_path_pth)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    instance.model = model\n",
    "    instance.state_dict = state_dict\n",
    "    \n",
    "print_header(\"Code test: model architecture\")\n",
    "print(f\"Note: \\'out_features = {len(instance.label_codes)}\\' at the end\".upper())\n",
    "display(instance.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cb6aa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================\n",
      "CODE TEST: MODEL STATE DICTIONARY\n",
      "=================================\n",
      "\n",
      "OrderedDict([('conv1.weight', tensor([[[[-1.1087e-02, -6.7593e-03, -2.4926e-03,  ...,  5.6792e-02,\n",
      "            1.7313e-02, -1.2530e-02],\n",
      "          [ 1.0138e-02,  8.7479e-03, -1.1064e-01,  ..., -2.7141e-01,\n",
      "           -1.2938e-01,  3.3370e-03],\n",
      "          [-7.8421e-03,  5.8271e-02,  2.9468e-01,  ...,  5.1975e-01,\n",
      "            2.5613e-01,  6.3238e-02],\n",
      "          ...,\n",
      "          [-2.8438e-02,  1.5150e-02,  7.1715e-02,  ..., -3.3331e-01,\n",
      "           -4.2086e-01, -2.5812e-01],\n",
      "          [ 2.9627e-02,  4.0148e-02,  6.2112e-02,  ...,  4.1335e-01,\n",
      "            3.9321e-01,  1.6578e-01],\n",
      "          [-1.4571e-02, -4.3363e-03, -2.4791e-02,  ..., -1.5096e-01,\n",
      "           -8.2610e-02, -6.0161e-03]],\n",
      "\n",
      "         [[-1.1167e-02, -2.6290e-02, -3.4528e-02,  ...,  3.2922e-02,\n",
      "            9.4665e-04, -2.5523e-02],\n",
      "          [ 4.5769e-02,  3.4000e-02, -1.0401e-01,  ..., -3.1181e-01,\n",
      "           -1.6012e-01, -1.1553e-03],\n",
      "          [-5.1002e-04,  9.8475e-02,  4.0238e-01,  ...,  7.0869e-01,\n",
      "            3.6958e-01,  1.2 \n",
      " ... LOTS OF PARAMETERS ...\n",
      " 0173, 0.0202, 0.0163, 0.0168, 0.0166, 0.0170,\n",
      "        0.0134, 0.0167, 0.0208, 0.0252, 0.0140, 0.0169, 0.0124, 0.0141, 0.0151,\n",
      "        0.0144, 0.0142, 0.0145, 0.0164, 0.0165, 0.0132, 0.0141, 0.0157, 0.0122,\n",
      "        0.0108, 0.0127, 0.0137, 0.0128, 0.0167, 0.0155, 0.0130, 0.0155, 0.0151,\n",
      "        0.0143, 0.0155, 0.0237, 0.0118, 0.0160, 0.0173, 0.0159, 0.0155, 0.0132,\n",
      "        0.0196, 0.0173, 0.0147, 0.0184, 0.0170, 0.0155, 0.0139, 0.0241, 0.0135,\n",
      "        0.0119, 0.0140, 0.0173, 0.0172, 0.0135, 0.0178, 0.0161, 0.0154])), ('layer4.1.bn2.num_batches_tracked', tensor(6)), ('fc.weight', tensor([[ 0.0311, -0.0172, -0.0200,  ...,  0.0035, -0.0330,  0.0234],\n",
      "        [ 0.0086, -0.0374,  0.0206,  ..., -0.0255, -0.0337,  0.0394],\n",
      "        [ 0.0321,  0.0164, -0.0380,  ...,  0.0080, -0.0353,  0.0335],\n",
      "        [ 0.0375, -0.0362,  0.0376,  ...,  0.0044, -0.0183, -0.0010],\n",
      "        [ 0.0256, -0.0010,  0.0162,  ...,  0.0258, -0.0111, -0.0042]])), ('fc.bias', tensor([0.0082, 0.0188, 0.0184, 0.0204, 0.0156]))])\n"
     ]
    }
   ],
   "source": [
    "print_header(\"Code test: model state dictionary\")\n",
    "print(str(instance.state_dict)[:1000], \"\\n ... LOTS OF PARAMETERS ...\\n\", str(instance.state_dict)[-1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2994197d",
   "metadata": {},
   "source": [
    "<a id='inference1'></a>\n",
    "## Inference: getting probabilities\n",
    "↑↑ [Contents](#contents) ↑ [Model architecture and state dictionary](#model_architecture) ↓ [Inference: combining probabilities](#inference2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d05afdf",
   "metadata": {},
   "source": [
    "Once we have trained a model, we will want to evaluate it by making inferences on lesions/images from our validation set(s), which the model has not been trained on. The ```get_probabilities``` function (in our ```multiclass_models``` module), is the first step towards classifying an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a9a44d31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving probabilities: D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_test_1e_test_00_val1_probabilities.csv\n",
      "Saving probabilities: D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_test_1e_test_00_val_a_probabilities.csv\n",
      "\n",
      "===============================================================\n",
      "CODE TEST: PROBABILITIES, VALIDATION SET (ONE IMAGE PER LESION)\n",
      "===============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_mel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.957200</td>\n",
       "      <td>0.008803</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>3.905761e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.857012</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.138892</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>3.466143e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.939657</td>\n",
       "      <td>0.020345</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>7.660649e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.160004</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.839545</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>8.625674e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.051505</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.948446</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>6.859188e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx  prob_other  prob_akiec  prob_bcc   prob_nv  \\\n",
       "0  HAM_0003218  ISIC_0033305  bkl    0.957200    0.008803  0.024734  0.005357   \n",
       "1  HAM_0003218  ISIC_0033305  bkl    0.857012    0.002237  0.138892  0.001512   \n",
       "2  HAM_0003218  ISIC_0033305  bkl    0.939657    0.020345  0.023048  0.009290   \n",
       "3  HAM_0000983  ISIC_0033490  bkl    0.160004    0.000340  0.839545  0.000103   \n",
       "4  HAM_0000983  ISIC_0033490  bkl    0.051505    0.000033  0.948446  0.000016   \n",
       "\n",
       "       prob_mel  \n",
       "0  3.905761e-03  \n",
       "1  3.466143e-04  \n",
       "2  7.660649e-03  \n",
       "3  8.625674e-06  \n",
       "4  6.859188e-07  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================================\n",
      "CODE TEST: PROBABILITIES, VALIDATION SET (MORE THAN ONE IMAGE PER LESION)\n",
      "=========================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_mel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>ISIC_0034125</td>\n",
       "      <td>bkl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.378271e-11</td>\n",
       "      <td>2.201661e-10</td>\n",
       "      <td>7.232391e-10</td>\n",
       "      <td>7.420231e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>ISIC_0033060</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.866039</td>\n",
       "      <td>5.915513e-04</td>\n",
       "      <td>1.323435e-01</td>\n",
       "      <td>9.058156e-04</td>\n",
       "      <td>1.198957e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>ISIC_0033060</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.997122</td>\n",
       "      <td>1.776210e-04</td>\n",
       "      <td>2.428613e-03</td>\n",
       "      <td>2.323076e-04</td>\n",
       "      <td>3.960762e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0001200</td>\n",
       "      <td>ISIC_0025716</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>3.132195e-03</td>\n",
       "      <td>9.886382e-01</td>\n",
       "      <td>1.502147e-03</td>\n",
       "      <td>4.908901e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001200</td>\n",
       "      <td>ISIC_0025716</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.699566</td>\n",
       "      <td>5.104385e-02</td>\n",
       "      <td>2.367935e-01</td>\n",
       "      <td>1.172803e-02</td>\n",
       "      <td>8.688460e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx  prob_other    prob_akiec      prob_bcc  \\\n",
       "0  HAM_0004406  ISIC_0034125  bkl    1.000000  1.378271e-11  2.201661e-10   \n",
       "1  HAM_0004406  ISIC_0033060  bkl    0.866039  5.915513e-04  1.323435e-01   \n",
       "2  HAM_0004406  ISIC_0033060  bkl    0.997122  1.776210e-04  2.428613e-03   \n",
       "3  HAM_0001200  ISIC_0025716  bkl    0.006237  3.132195e-03  9.886382e-01   \n",
       "4  HAM_0001200  ISIC_0025716  bkl    0.699566  5.104385e-02  2.367935e-01   \n",
       "\n",
       "        prob_nv      prob_mel  \n",
       "0  7.232391e-10  7.420231e-10  \n",
       "1  9.058156e-04  1.198957e-04  \n",
       "2  2.323076e-04  3.960762e-05  \n",
       "3  1.502147e-03  4.908901e-04  \n",
       "4  1.172803e-02  8.688460e-04  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import get_probabilities\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "# model = models.efficientnet_b0()  \n",
    "# model = models.resnet18() \n",
    "# if isinstance(model,models.ResNet):\n",
    "#     num_ftrs = model.fc.in_features\n",
    "#     model.fc = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "# elif isinstance(model,models.EfficientNet):\n",
    "#     num_ftrs = model.classifier[1].in_features\n",
    "#     model.classifier[1] = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "\n",
    "instance.df_probabilities_val1 = get_probabilities(df=instance.df_val1,\n",
    "                                                   data_dir=instance.data_dir,\n",
    "                                                   model_dir=instance.model_dir,\n",
    "                                                   model=instance.model,\n",
    "                                                   filename=instance._filename,\n",
    "                                                   label_codes=instance.label_codes,\n",
    "                                                   transform=instance.transform,\n",
    "                                                   batch_size=instance.batch_size,\n",
    "                                                   Print=False,\n",
    "                                                   save_as=instance._filename + \"_val1\",)\n",
    "\n",
    "instance.df_probabilities_val_a = get_probabilities(df=instance.df_val_a,\n",
    "                                                    data_dir=instance.data_dir,\n",
    "                                                    model_dir=instance.model_dir,\n",
    "                                                    model=instance.model,\n",
    "                                                    filename=instance._filename,\n",
    "                                                    label_codes=instance.label_codes,\n",
    "                                                    transform=instance.transform,\n",
    "                                                    batch_size=instance.batch_size,\n",
    "                                                    Print=False,\n",
    "                                                    save_as=instance._filename + \"_val_a\",)\n",
    "\n",
    "print_header(\"Code test: probabilities, validation set (one image per lesion)\")\n",
    "display_columns = ['lesion_id', 'image_id', 'dx'] + [col for col in instance.df_probabilities_val1.columns if col.startswith('prob')]\n",
    "display(instance.df_probabilities_val1[display_columns].head())\n",
    "\n",
    "print_header(\"Code test: probabilities, validation set (more than one image per lesion)\")\n",
    "display(instance.df_probabilities_val_a[display_columns].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e43511",
   "metadata": {},
   "source": [
    "We can also, naturally, make predictions for any lesion/image from our original dataset, as well as any image from outside our dataset (even, say, a picture of a cat). We explain in the output of the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aa486a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================================\n",
      "CODE TEST: PREDICTION ON INDIVIDUAL IMAGES OR LESIONS\n",
      "=====================================================\n",
      "\n",
      "- We can make predictions for individual images or lesions.\n",
      "- We only require a dataframe with an 'image_id' column.\n",
      "- Given the filename of an image, the df_from_ids function will construct such a dataframe.\n",
      "- We can then feed this dataframe into the get_probabilities function.\n",
      "- Here is the result of passing 'filenames = ['ISIC_0033305','ISIC_0025661']' to df_from_ids:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0033305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0025661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id\n",
       "0  ISIC_0033305\n",
       "1  ISIC_0025661"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- And here are the corresponding probabilities:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_mel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>0.965367</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.034221</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>0.584027</td>\n",
       "      <td>0.408331</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.003799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  prob_other  prob_akiec  prob_bcc   prob_nv  prob_mel\n",
       "0  ISIC_0033305    0.965367    0.000071  0.034221  0.000300  0.000041\n",
       "1  ISIC_0025661    0.584027    0.408331  0.000895  0.002948  0.003799"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- If we have a lesion_id with associated image_ids, we can also construct a small dataframe.\n",
      "- The df_from_ids function also takes arguments for the number of predictions we want to make for a given image/lesion.\n",
      "- Here is the result of passing 'lesion_ids = 'HAM_0000118', 'multiplicity = 3', and 'one_img_per_lesion = False' to df_from_ids:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id\n",
       "0  HAM_0000118  ISIC_0027419\n",
       "1  HAM_0000118  ISIC_0027419\n",
       "2  HAM_0000118  ISIC_0025030"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- We have filtered all columns except for lesion_id and image_id (knowing the diagnosis defeats the purpose).\n",
      "- Here are the associated probabilities:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_mel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>0.889041</td>\n",
       "      <td>0.110740</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>0.750358</td>\n",
       "      <td>0.249013</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>0.372584</td>\n",
       "      <td>0.618265</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.004041</td>\n",
       "      <td>0.001749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id  prob_other  prob_akiec  prob_bcc   prob_nv  \\\n",
       "0  HAM_0000118  ISIC_0027419    0.889041    0.110740  0.000084  0.000076   \n",
       "1  HAM_0000118  ISIC_0027419    0.750358    0.249013  0.000034  0.000402   \n",
       "2  HAM_0000118  ISIC_0025030    0.372584    0.618265  0.003361  0.004041   \n",
       "\n",
       "   prob_mel  \n",
       "0  0.000059  \n",
       "1  0.000192  \n",
       "2  0.001749  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Notice that the probabilities may vary with each execution of a prediction.\n",
      "- This is because a random transformation may be applied to each image before our model makes a prediction on it.\n"
     ]
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import df_from_ids, get_probabilities     \n",
    "\n",
    "instance = resnet_demo\n",
    "df = instance.df\n",
    "\n",
    "print_header(\"Code test: prediction on individual images or lesions\")\n",
    "\n",
    "to_print = [\"- We can make predictions for individual images or lesions.\",\n",
    "            \"We only require a dataframe with an \\'image_id\\' column.\",\n",
    "            \"Given the filename of an image, the df_from_ids function will construct such a dataframe.\",\n",
    "            \"We can then feed this dataframe into the get_probabilities function.\",\n",
    "            \"Here is the result of passing \\'filenames = [\\'ISIC_0033305\\',\\'ISIC_0025661\\']\\' to df_from_ids:\",\n",
    "            \"- And here are the corresponding probabilities:\",\n",
    "            \"- If we have a lesion_id with associated image_ids, we can also construct a small dataframe.\",\n",
    "            \"The df_from_ids function also takes arguments for the number of predictions we want to make for a given image/lesion.\",\n",
    "            \"Here is the result of passing \\'lesion_ids = \\'HAM_0000118\\', \\'multiplicity = 3\\', and \\'one_img_per_lesion = False\\' to df_from_ids:\",\n",
    "            \"- We have filtered all columns except for lesion_id and image_id (knowing the diagnosis defeats the purpose).\",\n",
    "            \"- Here are the associated probabilities:\",\n",
    "            \"- Notice that the probabilities may vary with each execution of a prediction.\",\n",
    "            \"This is because a random transformation may be applied to each image before our model makes a prediction on it.\"]\n",
    "\n",
    "df_2img = df_from_ids(filenames=['ISIC_0033305','ISIC_0025661'], # can be a string or a list of strings\n",
    "                       multiplicity=None,\n",
    "                       lesion_ids=None,\n",
    "                       df=df,\n",
    "                       one_img_per_lesion=None,)\n",
    "\n",
    "print(\"\\n- \".join(to_print[:5]))\n",
    "\n",
    "display(df_2img)\n",
    "\n",
    "df_2img_prob = get_probabilities(df=df_2img,\n",
    "                  data_dir=instance.data_dir,\n",
    "                  model_dir=instance.model_dir,\n",
    "                  model=instance.model,\n",
    "                  filename=instance._filename,\n",
    "                  label_codes=instance.label_codes,\n",
    "                  transform=instance.transform,\n",
    "                  batch_size=instance.batch_size,\n",
    "                  Print=False,\n",
    "                  save_as=None,)   \n",
    "\n",
    "print(to_print[5])\n",
    "display(df_2img_prob)\n",
    "\n",
    "print(\"\\n- \".join(to_print[6:9]))\n",
    "\n",
    "df_1les = df_from_ids(filenames=None,\n",
    "                       multiplicity=3,\n",
    "                       lesion_ids='HAM_0000118', # can be a string or a list of strings\n",
    "                       df=df,\n",
    "                       one_img_per_lesion=False,)\n",
    "\n",
    "display_columns = ['lesion_id', 'image_id'] \n",
    "display(df_1les[display_columns])\n",
    "\n",
    "print(\"\\n- \".join(to_print[9:10]))\n",
    "\n",
    "df_1les_prob = get_probabilities(df=df_1les,\n",
    "                  data_dir=instance.data_dir,\n",
    "                  model_dir=instance.model_dir,\n",
    "                  model=instance.model,\n",
    "                  filename=instance._filename,\n",
    "                  label_codes=instance.label_codes,\n",
    "                  transform=instance.transform,\n",
    "                  batch_size=instance.batch_size,\n",
    "                  Print=False,\n",
    "                  save_as=None,)   \n",
    "\n",
    "print(to_print[10])\n",
    "display_columns = ['lesion_id', 'image_id'] + [col for col in df_1les_prob if col.startswith('prob')]\n",
    "display(df_1les_prob[display_columns])\n",
    "\n",
    "print(\"\\n- \".join(to_print[11:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4d995871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's another example of how we'd use df_from_ids on an arbitrary image from outside our dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_from_somewhere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_from_somewhere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_from_somewhere</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               image_id\n",
       "0  image_from_somewhere\n",
       "1  image_from_somewhere\n",
       "2  image_from_somewhere"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If it were an actual image in the data_dir folder, we could feed this dataframe into the get_probabilities function.\n"
     ]
    }
   ],
   "source": [
    "print(\"Here's another example of how we'd use df_from_ids on an arbitrary image from outside our dataset.\")\n",
    "\n",
    "display(df_from_ids(filenames='image_from_somewhere', multiplicity=3,))\n",
    "\n",
    "print(\"If it were an actual image in the data_dir folder, we could feed this dataframe into the get_probabilities function.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a973eee",
   "metadata": {},
   "source": [
    "<a id='inference2'></a>\n",
    "## Inference: combining probabilities\n",
    "↑↑ [Contents](#contents) ↑ [Inference: getting probabilities](#inference1) ↓ [Inference: combining predictions](#inference3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94d1713",
   "metadata": {},
   "source": [
    "Once we have probabilities corresponding to an image, we can combine them to make a prediction. There are various ways we could combine the probabilities, if we have multiple sets of probabilities for a given image or lesion. This is done by the ```aggregate_probabilities``` function of our ```multiclass_models``` module. Note the ```method``` argument that can be passed to the function: it specifies how we want to combine multiple probabilities for a given image/lesion. See the output of the code cell below for a detailed example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "825133c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================\n",
      "CODE TEST: COMBINING PROBABILITIES\n",
      "==================================\n",
      "\n",
      "- We can combine multiple probabilities for a single lesion, if available, by taking the maximum, minimum, or mean.\n",
      "- Here is the original dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_mel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.889041</td>\n",
       "      <td>0.110740</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.750358</td>\n",
       "      <td>0.249013</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.372584</td>\n",
       "      <td>0.618265</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.004041</td>\n",
       "      <td>0.001749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  num_images      image_id   dx  label dx_type   age   sex  \\\n",
       "0  HAM_0000118           2  ISIC_0027419  bkl      0   histo  80.0  male   \n",
       "1  HAM_0000118           2  ISIC_0027419  bkl      0   histo  80.0  male   \n",
       "2  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "\n",
       "  localization set  prob_other  prob_akiec  prob_bcc   prob_nv  prob_mel  \n",
       "0        scalp  ta    0.889041    0.110740  0.000084  0.000076  0.000059  \n",
       "1        scalp  ta    0.750358    0.249013  0.000034  0.000402  0.000192  \n",
       "2        scalp  t1    0.372584    0.618265  0.003361  0.004041  0.001749  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Here is the dataframe with max mel probability, minimum nv probability, mean akiec and bcc prob's, and 'other' left alone:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_mel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.889041</td>\n",
       "      <td>0.326006</td>\n",
       "      <td>0.00116</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.001749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.750358</td>\n",
       "      <td>0.326006</td>\n",
       "      <td>0.00116</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.001749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.372584</td>\n",
       "      <td>0.326006</td>\n",
       "      <td>0.00116</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.001749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  num_images      image_id   dx  label dx_type   age   sex  \\\n",
       "0  HAM_0000118           2  ISIC_0027419  bkl      0   histo  80.0  male   \n",
       "1  HAM_0000118           2  ISIC_0027419  bkl      0   histo  80.0  male   \n",
       "2  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "\n",
       "  localization set  prob_other  prob_akiec  prob_bcc   prob_nv  prob_mel  \n",
       "0        scalp  ta    0.889041    0.326006   0.00116  0.000076  0.001749  \n",
       "1        scalp  ta    0.750358    0.326006   0.00116  0.000076  0.001749  \n",
       "2        scalp  t1    0.372584    0.326006   0.00116  0.000076  0.001749  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Here's another example (no lesion_id in this case):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_mel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>0.965367</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.034221</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>0.584027</td>\n",
       "      <td>0.408331</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.003799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  prob_other  prob_akiec  prob_bcc   prob_nv  prob_mel\n",
       "0  ISIC_0033305    0.965367    0.000071  0.034221  0.000300  0.000041\n",
       "1  ISIC_0025661    0.584027    0.408331  0.000895  0.002948  0.003799"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_mel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>0.965367</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.034221</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>0.584027</td>\n",
       "      <td>0.408331</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.003799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  prob_other  prob_akiec  prob_bcc   prob_nv  prob_mel\n",
       "0  ISIC_0033305    0.965367    0.000071  0.034221  0.000300  0.000041\n",
       "1  ISIC_0025661    0.584027    0.408331  0.000895  0.002948  0.003799"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import aggregate_probabilities\n",
    "\n",
    "print_header(\"Code test: combining probabilities\")\n",
    "\n",
    "method = { 'max' : ['mel'], 'min' : ['nv'], 'mean' : ['akiec', 'bcc'] }\n",
    "\n",
    "print(\"- We can combine multiple probabilities for a single lesion, if available, by taking the maximum, minimum, or mean.\")\n",
    "print(\"- Here is the original dataframe:\")\n",
    "display(df_1les_prob)\n",
    "print(\"- Here is the dataframe with max mel probability, minimum nv probability, mean akiec and bcc prob\\'s, and \\'other\\' left alone:\")\n",
    "display(aggregate_probabilities(df_1les_prob, method=method))\n",
    "\n",
    "print(\"- Here's another example (no lesion_id in this case):\")\n",
    "display(df_2img_prob)\n",
    "display(aggregate_probabilities(df_2img_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b2594",
   "metadata": {},
   "source": [
    "<a id='inference3'></a>\n",
    "## Inference: combining predictions\n",
    "↑↑ [Contents](#contents) ↑ [Inference: combining probabilities](#inference2) ↓ [Evaluation](#evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f50eb67",
   "metadata": {},
   "source": [
    "Once we have combined possibly multiple probabilities corresponding to a single image/lesion into a single one (via taking the mean, minimum, or maximum), we can make a prediction for the lesion's class. But again, there are options here. By default, the ```final_prediction``` function (```multiclass_models```) below predicts whatever class corresponds to the maximum probability (e.g. if the probability for ```nv``` is 0.8 and this is larger than the probability for the other lesion classes, then ```final_prediction``` will yield ```nv``` (or the encoding for ```nv```). However, we can stipulate that the prediction be given as ```mel``` if the probability for ```mel``` is, say, greater than 0.4. If that's not the case, we can then stipulate that ```bcc``` is predicted if its probability exceeds 0.4, etc. Likewise, we can make it harder to obtain a ```nv``` prediction by setting a threshold of at least 0.6 for that class. This is the purpose of the ordered dictionaries ```threshold_dict_help``` and ```threshold_dict_hinder``` arguments that are passed to ```final_prediction```. \n",
    "\n",
    "And even then, there are still further choices we can make. Once we have a prediction for each image corresponding to a lesion, we can combine the predictions according to various 'voting' methods: we might want to declare ```mel``` as soon as one of the predictions is for that class. The default is whichever class is predicted most often is the final prediction (and if there's a tie, break it by a random selection).\n",
    "\n",
    "Detailed examples are explained in the output of the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a2f14f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================\n",
      "CODE TEST: MAKING PREDICTIONS\n",
      "=============================\n",
      "\n",
      "- There are various ways we can form a prediction based on the combined probabilities.\n",
      "- For instance, we can immediately predict mel if the probability of mel is greater than 0.4.\n",
      "- If that's not the case, we can continue down a list, e.g. predicting bcc if probability of bcc is at least 0.45.\n",
      "- We can also require, e.g., the probability of nv to be at least 0.6 before predicting nv.\n",
      "- Once we have predicted classes for each image of a lesion, we can then combined the predictions in various ways.\n",
      "- For instance, we might want to make a final prediction of mel if that is a prediction for at least one of the images.\n",
      "- If not, we might again go through an ordered list, voting e.g. for bcc if at least one image is predicted as bcc.\n",
      "- It doesn't have to be 'at least one prediction': we could say 'if at least two predictions are for bcc, then...'.\n",
      "- If we reach the end of this list, we'd proceed to select the most popular prediction as the final one for the lesion.\n",
      "- We don't have to specify a priority list at all: in that case we just take the most popular prediction as the final one.\n",
      "- We could do similar if we had no lesion_id but only image_ids repeated a number of times.\n",
      "- Below, by way of illustration, we've stated that we want to predict bcc if the probability for bcc is at least 0.01.\n",
      "- But then, we've stated that we want to make a final prediction of mel if at least one prediction is for mel.\n",
      "- The label codes are as follows: {0: 'other', 1: 'akiec', 2: 'bcc', 3: 'nv', 4: 'mel'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.889041</td>\n",
       "      <td>0.110740</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.750358</td>\n",
       "      <td>0.249013</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.372584</td>\n",
       "      <td>0.618265</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.004041</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  num_images      image_id   dx  label dx_type   age   sex  \\\n",
       "0  HAM_0000118           2  ISIC_0027419  bkl      0   histo  80.0  male   \n",
       "1  HAM_0000118           2  ISIC_0027419  bkl      0   histo  80.0  male   \n",
       "2  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "\n",
       "  localization set  prob_other  prob_akiec  prob_bcc   prob_nv  prob_mel  \\\n",
       "0        scalp  ta    0.889041    0.110740  0.000084  0.000076  0.000059   \n",
       "1        scalp  ta    0.750358    0.249013  0.000034  0.000402  0.000192   \n",
       "2        scalp  t1    0.372584    0.618265  0.003361  0.004041  0.001749   \n",
       "\n",
       "   pred  pred_final  \n",
       "0     0           0  \n",
       "1     0           0  \n",
       "2     1           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List\n",
    "from multiclass_models import final_prediction\n",
    "\n",
    "print_header(\"Code test: making predictions\")\n",
    "\n",
    "raw_probabilities_df: pd.DataFrame = df_1les_prob \n",
    "raw_probabilities_df_a: pd.DataFrame = instance.df_probabilities_val_a\n",
    "aggregate_method: Union[None, Dict[str, List[str]]] = { 'max' : ['mel'], 'min' : ['nv'], 'mean' : ['akiec', 'bcc']}\n",
    "threshold_dict_help: Union[None, OrderedDict[str, float]] = OrderedDict([('bcc',0.01), ('mel',0.4)])\n",
    "threshold_dict_hinder: Union[None, OrderedDict[str, float]] = OrderedDict([('nv',0.6)])    \n",
    "votes_to_win_dict: Union[None, OrderedDict[str, int]] = OrderedDict([('mel',1)])\n",
    "label_codes: Dict[int, str] = instance.label_codes\n",
    "prefix: Union[None, str] = 'prob_'\n",
    "    \n",
    "to_print = [\"- There are various ways we can form a prediction based on the combined probabilities.\",\n",
    "            \"For instance, we can immediately predict mel if the probability of mel is greater than 0.4.\",\n",
    "            \"If that's not the case, we can continue down a list, e.g. predicting bcc if probability of bcc is at least 0.45.\",\n",
    "            \"We can also require, e.g., the probability of nv to be at least 0.6 before predicting nv.\",\n",
    "            \"Once we have predicted classes for each image of a lesion, we can then combined the predictions in various ways.\",\n",
    "            \"For instance, we might want to make a final prediction of mel if that is a prediction for at least one of the images.\",\n",
    "            \"If not, we might again go through an ordered list, voting e.g. for bcc if at least one image is predicted as bcc.\",\n",
    "            \"It doesn't have to be \\'at least one prediction\\': we could say \\'if at least two predictions are for bcc, then...\\'.\",\n",
    "            \"If we reach the end of this list, we'd proceed to select the most popular prediction as the final one for the lesion.\",\n",
    "            \"We don't have to specify a priority list at all: in that case we just take the most popular prediction as the final one.\",\n",
    "            \"We could do similar if we had no lesion_id but only image_ids repeated a number of times.\",\n",
    "            \"Below, by way of illustration, we've stated that we want to predict bcc if the probability for bcc is at least 0.01.\",\n",
    "            \"But then, we've stated that we want to make a final prediction of mel if at least one prediction is for mel.\",\n",
    "            f\"The label codes are as follows: {instance.label_codes}\",            \n",
    "            ]\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "display(final_prediction(raw_probabilities_df=raw_probabilities_df, \n",
    "                 threshold_dict_help=threshold_dict_help,\n",
    "                 threshold_dict_hinder=threshold_dict_hinder,\n",
    "                 votes_to_win_dict=votes_to_win_dict,\n",
    "                 label_codes=label_codes,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa0cc75",
   "metadata": {},
   "source": [
    "We apply the ```final_prediction``` function to the entirely of both variants of our validation set. Both validation sets will contain multiple images for each lesion if ```val_expansion_factor``` is an integer greater than one. Otherwise, the features of ```final_prediction``` concerning combining probabilities and predictions will only be relevant to the all-images-per-lesion version of the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a756c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now apply this to our code test validation sets.\n",
    "# We can reload the probabilities dataframes from csv files saved earlier, if they are not already in memory\n",
    "file_path_val1 = instance.model_dir.joinpath(instance._filename + \"_val1_probabilities.csv\")\n",
    "file_path_val_a = instance.model_dir.joinpath(instance._filename + \"_val_a_probabilities.csv\")\n",
    "instance.df_val1_probabilities = pd.read_csv(file_path_val1,index_col=0)\n",
    "instance.df_val_a_probabilities = pd.read_csv(file_path_val_a,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1e3e87ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================\n",
      "CODE TEST: COMBINING PROBABILITIES AND MAKING PREDICTIONS\n",
      "=========================================================\n",
      "\n",
      "VALIDATION SET: ONE IMAGE PER LESION, REPEATED 3 TIMES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.957200</td>\n",
       "      <td>0.008803</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>3.905761e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.857012</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.138892</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>3.466143e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.939657</td>\n",
       "      <td>0.020345</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>7.660649e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.160004</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.839545</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>8.625674e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.051505</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.948446</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>6.859188e-07</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  lesion_mult  num_images      image_id  img_mult   dx  label  \\\n",
       "0  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "1  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "2  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "3  HAM_0000983            3           1  ISIC_0033490         3  bkl      0   \n",
       "4  HAM_0000983            3           1  ISIC_0033490         3  bkl      0   \n",
       "\n",
       "     dx_type   age      sex localization set  prob_other  prob_akiec  \\\n",
       "0  consensus  75.0     male         back  v1    0.957200    0.008803   \n",
       "1  consensus  75.0     male         back  v1    0.857012    0.002237   \n",
       "2  consensus  75.0     male         back  v1    0.939657    0.020345   \n",
       "3  consensus   NaN  unknown      unknown  v1    0.160004    0.000340   \n",
       "4  consensus   NaN  unknown      unknown  v1    0.051505    0.000033   \n",
       "\n",
       "   prob_bcc   prob_nv      prob_mel  pred  pred_final  \n",
       "0  0.024734  0.005357  3.905761e-03     0           0  \n",
       "1  0.138892  0.001512  3.466143e-04     0           0  \n",
       "2  0.023048  0.009290  7.660649e-03     0           0  \n",
       "3  0.839545  0.000103  8.625674e-06     2           2  \n",
       "4  0.948446  0.000016  6.859188e-07     2           2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALIDATION SET: 3 IMAGES PER LESION, USING ALL IMAGES BEFORE REPEATING\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0034125</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>va</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.378271e-11</td>\n",
       "      <td>2.201661e-10</td>\n",
       "      <td>7.232391e-10</td>\n",
       "      <td>7.420231e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0033060</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.866039</td>\n",
       "      <td>5.915513e-04</td>\n",
       "      <td>1.323435e-01</td>\n",
       "      <td>9.058156e-04</td>\n",
       "      <td>1.198957e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0033060</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.997122</td>\n",
       "      <td>1.776210e-04</td>\n",
       "      <td>2.428613e-03</td>\n",
       "      <td>2.323076e-04</td>\n",
       "      <td>3.960762e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0001200</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0025716</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>3.132195e-03</td>\n",
       "      <td>9.886382e-01</td>\n",
       "      <td>1.502147e-03</td>\n",
       "      <td>4.908901e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001200</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0025716</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.699566</td>\n",
       "      <td>5.104385e-02</td>\n",
       "      <td>2.367935e-01</td>\n",
       "      <td>1.172803e-02</td>\n",
       "      <td>8.688460e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  lesion_mult  num_images      image_id  img_mult   dx  label  \\\n",
       "0  HAM_0004406            3           2  ISIC_0034125         1  bkl      0   \n",
       "1  HAM_0004406            3           2  ISIC_0033060         2  bkl      0   \n",
       "2  HAM_0004406            3           2  ISIC_0033060         2  bkl      0   \n",
       "3  HAM_0001200            3           1  ISIC_0025716         3  bkl      0   \n",
       "4  HAM_0001200            3           1  ISIC_0025716         3  bkl      0   \n",
       "\n",
       "  dx_type   age   sex localization set  prob_other    prob_akiec  \\\n",
       "0   histo  80.0  male         back  va    1.000000  1.378271e-11   \n",
       "1   histo  80.0  male         back  v1    0.866039  5.915513e-04   \n",
       "2   histo  80.0  male         back  v1    0.997122  1.776210e-04   \n",
       "3   histo  85.0  male         face  v1    0.006237  3.132195e-03   \n",
       "4   histo  85.0  male         face  v1    0.699566  5.104385e-02   \n",
       "\n",
       "       prob_bcc       prob_nv      prob_mel  pred  pred_final  \n",
       "0  2.201661e-10  7.232391e-10  7.420231e-10     0           0  \n",
       "1  1.323435e-01  9.058156e-04  1.198957e-04     0           0  \n",
       "2  2.428613e-03  2.323076e-04  3.960762e-05     0           0  \n",
       "3  9.886382e-01  1.502147e-03  4.908901e-04     2           2  \n",
       "4  2.367935e-01  1.172803e-02  8.688460e-04     0           2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NOW WE SIMPLY DROP DUPLICATES (LESION_ID)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>label</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HAM_0003267</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HAM_0006318</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HAM_0005518</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HAM_0005663</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HAM_0001953</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HAM_0002591</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HAM_0005713</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>HAM_0007568</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HAM_0007313</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>HAM_0007364</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>HAM_0002882</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>HAM_0003949</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lesion_id  label  pred_final\n",
       "0   HAM_0003218      0           0\n",
       "3   HAM_0000983      0           2\n",
       "6   HAM_0003267      3           0\n",
       "9   HAM_0006318      3           0\n",
       "12  HAM_0005518      0           2\n",
       "15  HAM_0005663      0           0\n",
       "18  HAM_0001953      4           0\n",
       "21  HAM_0002591      4           2\n",
       "24  HAM_0005713      0           0\n",
       "27  HAM_0007568      0           0\n",
       "30  HAM_0007313      2           0\n",
       "33  HAM_0007364      2           0\n",
       "36  HAM_0002882      1           0\n",
       "39  HAM_0003949      1           2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>label</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0001200</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HAM_0001756</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HAM_0006602</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HAM_0007418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HAM_0004065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HAM_0006722</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HAM_0000107</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HAM_0000940</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>HAM_0007150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HAM_0005998</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>HAM_0005973</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>HAM_0003123</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>HAM_0002954</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lesion_id  label  pred_final\n",
       "0   HAM_0004406      0           0\n",
       "3   HAM_0001200      0           2\n",
       "6   HAM_0001756      3           0\n",
       "9   HAM_0006602      3           0\n",
       "12  HAM_0007418      0           0\n",
       "15  HAM_0004065      0           0\n",
       "18  HAM_0006722      4           0\n",
       "21  HAM_0000107      4           0\n",
       "24  HAM_0000940      0           0\n",
       "27  HAM_0007150      0           0\n",
       "30  HAM_0005998      2           0\n",
       "33  HAM_0005973      2           0\n",
       "36  HAM_0003123      1           0\n",
       "39  HAM_0002954      1           0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import final_prediction\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "raw_probabilities_df1: pd.DataFrame = instance.df_probabilities_val1 \n",
    "raw_probabilities_df_a: pd.DataFrame = instance.df_probabilities_val_a\n",
    "aggregate_method: Union[None, Dict[str, List[str]]] = { 'max' : ['mel'], 'min' : ['nv'], 'mean' : ['bcc']}\n",
    "threshold_dict_help: Union[None, OrderedDict[str, float]] = OrderedDict([('mel',0.4), ('bcc',0.45)])\n",
    "threshold_dict_hinder: Union[None, OrderedDict[str, float]] = OrderedDict([('nv',0.6)])    \n",
    "votes_to_win_dict: Union[None, OrderedDict[str, int]] = OrderedDict([('mel',1)])\n",
    "label_codes: Dict[int, str] = instance.label_codes\n",
    "prefix: Union[None, str] = 'prob_'\n",
    "\n",
    "print_header(\"Code test: combining probabilities and making predictions\")\n",
    "\n",
    "print(f\"Validation set: one image per lesion, repeated {instance.source.val_expansion_factor} times\".upper())\n",
    "\n",
    "instance.df_pred_val1 = final_prediction(raw_probabilities_df=raw_probabilities_df1, \n",
    "                                         threshold_dict_help=threshold_dict_help,\n",
    "                                         threshold_dict_hinder=threshold_dict_hinder,\n",
    "                                         votes_to_win_dict=votes_to_win_dict,\n",
    "                                         label_codes=label_codes,)\n",
    "\n",
    "display(instance.df_pred_val1.head())\n",
    "\n",
    "print(f\"\\nValidation set: {instance.source.val_expansion_factor} images per lesion, using all images before repeating\".upper())\n",
    "\n",
    "instance.df_pred_val_a = final_prediction(raw_probabilities_df=raw_probabilities_df_a, \n",
    "                                         threshold_dict_help=threshold_dict_help,\n",
    "                                         threshold_dict_hinder=threshold_dict_hinder,\n",
    "                                         votes_to_win_dict=votes_to_win_dict,\n",
    "                                         label_codes=label_codes,)\n",
    "\n",
    "display(instance.df_pred_val_a.head())\n",
    "\n",
    "print(\"\\nNow we simply drop duplicates (lesion_id)...\".upper())\n",
    "\n",
    "display(instance.df_pred_val1.drop_duplicates(subset='lesion_id')[['lesion_id','label','pred_final']])\n",
    "\n",
    "display(instance.df_pred_val_a.drop_duplicates(subset='lesion_id')[['lesion_id','label','pred_final']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4162850",
   "metadata": {},
   "source": [
    "<a id='evaluation'></a>\n",
    "## Evaluation\n",
    "↑↑ [Contents](#contents) ↑ [Inference: combining predictions](#inference3) ↓ [Trivial models](#trivial_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8cc048",
   "metadata": {},
   "source": [
    "Having a single final prediction for each lesion in our validation set, we can evaluate our model. We have some custom functions to display confusion matrices with class-wise precision and recall: such functions and other metric-related functions are to be found in our custom ```evaluation``` module. Details are explained, with examples, in the output of the code cell below. \n",
    "\n",
    "We have chosen balanced accuracy as our overall metric for evaluating model performance. However, we also display several other metrics, such as the Matthews correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3b8844a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================\n",
      "CODE TEST: CONFUSION MATRIX (VALIDATION SET)\n",
      "============================================\n",
      "\n",
      "- The overall evaluation metric would appear at the bottom right, if it were defined (this code test set is too small).\n",
      "- It would be a class-wise weighted average fbeta score, beta and weights as specified (default values 1).\n",
      "- One could also pass None, a float, or a different function to the func parameter in confusion_matrix_with_metric.\n",
      "\n",
      "ONE IMAGE PER LESION, REPEATED 3 TIMES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>akiec</th>\n",
       "      <th>bcc</th>\n",
       "      <th>nv</th>\n",
       "      <th>mel</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.4</td>\n",
       "      <td>_</td>\n",
       "      <td>0.0</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted other akiec  bcc nv mel All    recall\n",
       "actual                                         \n",
       "other         4     0    2  0   0   6  0.666667\n",
       "akiec         1     0    1  0   0   2       0.0\n",
       "bcc           2     0    0  0   0   2       0.0\n",
       "nv            2     0    0  0   0   2       0.0\n",
       "mel           1     0    1  0   0   2       0.0\n",
       "All          10     0    4  0   0  14         _\n",
       "precision   0.4     _  0.0  _   _   _         _"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 IMAGES PER LESION, USING ALL AVAILABLE IMAGES BEFORE REPEATING\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>akiec</th>\n",
       "      <th>bcc</th>\n",
       "      <th>nv</th>\n",
       "      <th>mel</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>_</td>\n",
       "      <td>0.0</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted     other akiec  bcc nv mel All    recall\n",
       "actual                                             \n",
       "other             5     0    1  0   0   6  0.833333\n",
       "akiec             2     0    0  0   0   2       0.0\n",
       "bcc               2     0    0  0   0   2       0.0\n",
       "nv                2     0    0  0   0   2       0.0\n",
       "mel               2     0    0  0   0   2       0.0\n",
       "All              13     0    1  0   0  14         _\n",
       "precision  0.384615     _  0.0  _   _   _         _"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from evaluation import weighted_average_f, confusion_matrix_with_metric\n",
    "\n",
    "instance = resnet_demo\n",
    "map_labels = instance.label_codes\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label'] \n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final'] \n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']  \n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']  \n",
    "\n",
    "txp1 = pd.crosstab(target1,prediction1,margins=True,dropna=False)\n",
    "txp_a = pd.crosstab(target_a,prediction_a,margins=True,dropna=False)\n",
    "\n",
    "beta = 1\n",
    "# Weights inversely proportional to relative class size in the training set, giving more importance to smaller classes.\n",
    "weights = 1/instance.df_train['label'].value_counts(normalize=True).sort_index().values # None\n",
    "\n",
    "instance.cm1 = confusion_matrix_with_metric(AxB=txp1,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "instance.cm_a = confusion_matrix_with_metric(AxB=txp_a,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "print_header(\"Code test: confusion matrix (validation set)\")\n",
    "\n",
    "to_print = [\"- The overall evaluation metric would appear at the bottom right, if it were defined (this code test set is too small).\",\n",
    "            \"It would be a class-wise weighted average fbeta score, beta and weights as specified (default values 1).\",\n",
    "            \"One could also pass None, a float, or a different function to the func parameter in confusion_matrix_with_metric.\"]\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "print(f\"\\nOne image per lesion, repeated {instance.source.val_expansion_factor} times\".upper())\n",
    "display(instance.cm1.fillna('_'))\n",
    "\n",
    "print(f\"\\n{instance.source.val_expansion_factor} images per lesion, using all available images before repeating\".upper())\n",
    "display(instance.cm_a.fillna('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b0a5ae88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "CODE TEST: OTHER METRICS\n",
      "========================\n",
      "\n",
      "- ACC: accuracy\n",
      "- BACC: balanced accuracy\n",
      "- precision: macro-averaged precision (equal weight to each class)\n",
      "- recal: macro-averaged recall (equal weight to each class)\n",
      "- Fbeta: macro-averaged F_beta score (equal weight to each class)\n",
      "- MCC: Matthews correlation coefficient\n",
      "- ROC-AUC mac: macro-averaged ROC-AUC (equal weight to each class)\n",
      "- ROC-AUC wt: weighted-average ROC-AUC (larger class -> more weight)\n",
      "- ROC-AUC wt*: weighted-average ROC-AUC (larger class -> *less weight)\n",
      "\n",
      " ONE IMAGE PER LESION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>-0.111803</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.505952</td>\n",
       "      <td>0.508333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC      BACC  precision    recall      F1/2   F1        F2       MCC  \\\n",
       "0  0.285714  0.133333        0.2  0.133333  0.086957  0.1  0.117647 -0.111803   \n",
       "\n",
       "   ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0        0.525    0.505952     0.508333  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " POSSIBLY MORE THAN ONE IMAGE PER LESION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>-0.16343</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.491071</td>\n",
       "      <td>0.508333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC      BACC  precision    recall      F1/2        F1        F2  \\\n",
       "0  0.357143  0.166667   0.192308  0.166667  0.086207  0.105263  0.135135   \n",
       "\n",
       "       MCC  ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0 -0.16343       0.5125    0.491071     0.508333  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from evaluation import metric_dictionary\n",
    "# import pandas as pd\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label'] \n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final'] \n",
    "probabilities1 = instance.df_probabilities_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_') \n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']  \n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']  \n",
    "probabilities_a = instance.df_probabilities_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_') \n",
    "\n",
    "beta = 1\n",
    "# Weights inversely proportional to relative class size, giving more importance to smaller classes.\n",
    "weights = 1/instance.df_train['label'].value_counts(normalize=True).sort_index().values # None\n",
    "\n",
    "print_header(\"Code test: other metrics\")\n",
    "\n",
    "to_print = [\"- ACC: accuracy\",\n",
    "            \"BACC: balanced accuracy\",\n",
    "            \"precision: macro-averaged precision (equal weight to each class)\",\n",
    "            \"recal: macro-averaged recall (equal weight to each class)\",\n",
    "            \"Fbeta: macro-averaged F_beta score (equal weight to each class)\",\n",
    "            \"MCC: Matthews correlation coefficient\",\n",
    "            \"ROC-AUC mac: macro-averaged ROC-AUC (equal weight to each class)\",\n",
    "            \"ROC-AUC wt: weighted-average ROC-AUC (larger class -> more weight)\",\n",
    "            \"ROC-AUC wt*: weighted-average ROC-AUC (larger class -> *less weight)\",            \n",
    "            ]\n",
    "\n",
    "instance.metric_dict1 = metric_dictionary(target=target1, \n",
    "                                          prediction=prediction1, \n",
    "                                          probabilities=probabilities1)\n",
    "\n",
    "instance.metric_dict_a = metric_dictionary(target=target_a, \n",
    "                                          prediction=prediction_a, \n",
    "                                          probabilities=probabilities_a)\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "print(\"\\n One image per lesion\".upper())\n",
    "display(pd.DataFrame(instance.metric_dict1))\n",
    "\n",
    "print(\"\\n Possibly more than one image per lesion\".upper())\n",
    "display(pd.DataFrame(instance.metric_dict_a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
