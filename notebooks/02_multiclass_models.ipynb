{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f32ebf",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c92e86b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path['project'] : D:\\projects\\skin-lesion-classification\n",
      "path['images'] : D:\\projects\\skin-lesion-classification\\images\n",
      "path['models'] : D:\\projects\\skin-lesion-classification\\models\n",
      "path['expository'] : D:\\projects\\skin-lesion-classification\\expository\n",
      "path['literature'] : D:\\projects\\skin-lesion-classification\\literature\n",
      "path['notebooks'] : D:\\projects\\skin-lesion-classification\\notebooks\n",
      "path['presentation'] : D:\\projects\\skin-lesion-classification\\presentation\n",
      "path['scripts'] : D:\\projects\\skin-lesion-classification\\scripts\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# If we're using Google Colab, we set the environment variable to point to the relevant folder in our Google Drive:\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.environ['SKIN_LESION_CLASSIFICATION'] = '/content/drive/MyDrive/Colab Notebooks/skin-lesion-classification'\n",
    "\n",
    "# Otherwise, we use the environment variable on our local system:\n",
    "project_environment_variable = \"SKIN_LESION_CLASSIFICATION\"\n",
    "\n",
    "# Path to the root directory of the project:\n",
    "project_path = Path(os.environ.get(project_environment_variable))\n",
    "\n",
    "# Relative path to /scripts (from where custom modules will be imported):\n",
    "scripts_path = project_path.joinpath(\"scripts\")\n",
    "\n",
    "# Add this path to sys.path so that Python will look there for modules:\n",
    "sys.path.append(str(scripts_path))\n",
    "\n",
    "# Now import path_step from our custom utils module to create a dictionary to all subdirectories in our root directory:\n",
    "from utils import path_setup\n",
    "path = path_setup.subfolders(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16849006",
   "metadata": {},
   "source": [
    "## Loading and preprocessing metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1200a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type, Union      # For type hints\n",
    "from processing import process      # Custom module for processing metadata\n",
    "\n",
    "data_dir: Path = path[\"images\"]     # Path to directory containing metadata.csv file\n",
    "csv_filename: str = \"metadata.csv\"  # The filename\n",
    "    \n",
    "restrict_to: Union[dict, None] = None                   # Remove all records *unless* column k lies in list v, for k : v in restrict_to dictionary.    \n",
    "remove_if: Union[dict, None] = None                     # Remove all records if column k lies in list v, for k : v in remove_if dictionary.    \n",
    "drop_row_if_missing_value_in: Union[list, None] = None  # We drop all rows for which there is a missing value in a column from this list.   \n",
    "                                    \n",
    "tvr: int = 3              # Ratio of training set to validation set. See discussion below for explanation.\n",
    "seed: int = 0             # Random seed for parts of the process where randomness is called for.\n",
    "keep_first: bool = False  # If False, then, for each lesion, we choose a random image to assign to our training set. \n",
    "stratified: bool = True   # If True, we stratify classes so that the proportions remain as stable as possible after train/val split. \n",
    "                          # If False, the proportions will be roughly similar.\n",
    "\n",
    "to_classify: Union[list, dict] = [\"mel\",   # These are the lesion types we are interested in classifying. \n",
    "                                  \"bcc\",   # Any missing ones will be grouped together as the 0-label class: no need to write \"other\" here.\n",
    "                                  \"akiec\", # If 'other' is not desired, use restrict_to attribute above\n",
    "                                  \"nv\",]\n",
    "\n",
    "train_one_img_per_lesion: Union[bool, None] = False # If False, we take advantage of the (in some cases) multiple images of a lesion in our dataset\n",
    "val_one_img_per_lesion: Union[bool, None] = False   # If False, we will validate our model by combining multiple predictions for a lesion (for multiple images of it) into a single prediction\n",
    "val_expansion_factor: Union[int, None] = 3          # A random transformation may be applied to an image before making a prediction.\n",
    "                                                    # For a given lesion, we may make multiple predictions (as specified here), and combine them into a single prediction.\n",
    "    \n",
    "sample_size: Union[None, dict] = {\"mel\": 2000,     # Handling class imbalance by upsampling minority classes/downsampling majority classes     \n",
    "                                  \"bcc\": 2000,     # Specify how many images of each lesion diagnosis we want in our training set.\n",
    "                                  \"akiec\": 2000, \n",
    "                                  \"nv\": 2000,\n",
    "                                  \"other\" : 2000,} # Could also leave out \"other\" here, and include e.g. \"df: 2000\" if we wanted to.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbcb4935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded file 'D:\\projects\\skin-lesion-classification\\images\\metadata.csv'.\n",
      "- Inserted 'num_images' column in dataframe, to the right of 'lesion_id' column.\n",
      "- Inserted 'label' column in dataframe, to the right of 'dx' column: \n",
      "  {'bkl': 0, 'df': 0, 'vasc': 0, 'akiec': 1, 'nv': 2, 'mel': 3, 'bcc': 4}\n",
      "- Added 'set' column to dataframe, with values 't1', 'v1', 'ta', and 'va', to the right of 'localization' column.\n",
      "- Basic, overall dataframe (pre-train/test split): self.df\n",
      "- Balancing classes in training set.\n",
      "- Balanced training set (uses as many different images per lesion as possible): self.df_train\n",
      "- Expanding validation set: will combine 3 predictions into one, for each lesion in val set.\n",
      "- Expanded validation set (one image per lesion, repeated 3 times): self.df_val1\n",
      "- Expanded validation set (use up to 3 different images per lesion, if available): self.df_val_a\n",
      "- Small sample dataframes for code testing: self._df_train_code_test, self._df_val1_code_test, self._df_val_a_code_test\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the process class with attribute values as above.\n",
    "demo = process(data_dir=data_dir,\n",
    "               csv_filename=csv_filename,\n",
    "               restrict_to=restrict_to,\n",
    "               remove_if=remove_if,\n",
    "               drop_row_if_missing_value_in=drop_row_if_missing_value_in,\n",
    "               tvr=tvr,\n",
    "               seed=seed,\n",
    "               keep_first=keep_first,\n",
    "               stratified=stratified,\n",
    "               to_classify=to_classify,\n",
    "               train_one_img_per_lesion=train_one_img_per_lesion,\n",
    "               val_expansion_factor=val_expansion_factor,\n",
    "               sample_size=sample_size,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0205ff",
   "metadata": {},
   "source": [
    "## Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b841851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "DISTRIBUTION OF LESIONS BY DIAGNOSIS: OVERALL\n",
      "=============================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5403.00</td>\n",
       "      <td>898.00</td>\n",
       "      <td>614.00</td>\n",
       "      <td>327.00</td>\n",
       "      <td>228.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>72.33</td>\n",
       "      <td>12.02</td>\n",
       "      <td>8.22</td>\n",
       "      <td>4.38</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv   other     mel     bcc   akiec\n",
       "freq  5403.00  898.00  614.00  327.00  228.00\n",
       "%       72.33   12.02    8.22    4.38    3.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lesions: 7470.\n",
      "\n",
      "\n",
      "===========================================\n",
      "DISTRIBUTION OF LESIONS BY DIAGNOSIS: TRAIN\n",
      "===========================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4052.00</td>\n",
       "      <td>673.00</td>\n",
       "      <td>460.00</td>\n",
       "      <td>245.00</td>\n",
       "      <td>171.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>72.34</td>\n",
       "      <td>12.02</td>\n",
       "      <td>8.21</td>\n",
       "      <td>4.37</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv   other     mel     bcc   akiec\n",
       "freq  4052.00  673.00  460.00  245.00  171.00\n",
       "%       72.34   12.02    8.21    4.37    3.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lesions: 5601 (74.98% of all lesions).\n",
      "\n",
      "\n",
      "=========================================\n",
      "DISTRIBUTION OF LESIONS BY DIAGNOSIS: VAL\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1351.00</td>\n",
       "      <td>225.00</td>\n",
       "      <td>154.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>57.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>72.28</td>\n",
       "      <td>12.04</td>\n",
       "      <td>8.24</td>\n",
       "      <td>4.39</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv   other     mel    bcc  akiec\n",
       "freq  1351.00  225.00  154.00  82.00  57.00\n",
       "%       72.28   12.04    8.24   4.39   3.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lesions: 1869 (25.02% of all lesions).\n",
      "\n",
      "\n",
      "============================================\n",
      "DISTRIBUTION OF IMAGES BY DIAGNOSIS: OVERALL\n",
      "============================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6705.00</td>\n",
       "      <td>1356.00</td>\n",
       "      <td>1113.00</td>\n",
       "      <td>514.00</td>\n",
       "      <td>327.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>66.95</td>\n",
       "      <td>13.54</td>\n",
       "      <td>11.11</td>\n",
       "      <td>5.13</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv    other      mel     bcc   akiec\n",
       "freq  6705.00  1356.00  1113.00  514.00  327.00\n",
       "%       66.95    13.54    11.11    5.13    3.27"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 10015.\n",
      "\n",
      "\n",
      "==========================================\n",
      "DISTRIBUTION OF IMAGES BY DIAGNOSIS: TRAIN\n",
      "==========================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5007.00</td>\n",
       "      <td>1008.00</td>\n",
       "      <td>831.00</td>\n",
       "      <td>384.00</td>\n",
       "      <td>250.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>66.94</td>\n",
       "      <td>13.48</td>\n",
       "      <td>11.11</td>\n",
       "      <td>5.13</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv    other     mel     bcc   akiec\n",
       "freq  5007.00  1008.00  831.00  384.00  250.00\n",
       "%       66.94    13.48   11.11    5.13    3.34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 7480 (74.69% of all images).\n",
      "\n",
      "\n",
      "========================================\n",
      "DISTRIBUTION OF IMAGES BY DIAGNOSIS: VAL\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1698.00</td>\n",
       "      <td>348.00</td>\n",
       "      <td>282.00</td>\n",
       "      <td>130.00</td>\n",
       "      <td>77.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>66.98</td>\n",
       "      <td>13.73</td>\n",
       "      <td>11.12</td>\n",
       "      <td>5.13</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv   other     mel     bcc  akiec\n",
       "freq  1698.00  348.00  282.00  130.00  77.00\n",
       "%       66.98   13.73   11.12    5.13   3.04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 2535 (25.31% of all images).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for across in [\"lesions\", \"images\"]:\n",
    "    for subset in [\"all\", \"train\", \"val\"]:\n",
    "        process.dx_dist(demo, subset = subset, across = across)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86793889",
   "metadata": {},
   "source": [
    "## Train/val split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efbbd9e",
   "metadata": {},
   "source": [
    "<!-- <details>\n",
    "    <summary><b><i>Train test split explanation: click here to expand/collapse</i></b></summary> -->\n",
    "    \n",
    "We partition our dataset based on ```lesion_id```, **not** on ```image_id```: that way, every lesion will be represented in training or in validation, but not both.\n",
    "\n",
    "For each classification task, we will train a model by making use of\n",
    "* **exactly one** image for every lesion in our training set;\n",
    "* **all** images of every lesion in our training set.\n",
    "\n",
    "In both cases, we will vaildate our model by making use of \n",
    "* **exactly one** image for every lesion in our validation set;\n",
    "* **all** images of every lesion in our validation set (at least, _potentially_ all of them). \n",
    "\n",
    "**However**, we will make only one prediction per lesion (```lesion_id```) in our validation set: if there are multiple images of a lesion in the validation set, we will combine the predictions for the multiple images into a single prediction for the lesion.\n",
    "\n",
    "Accordingly, we proceed as follows. We'll explain by example, assuming the dataset is not filtered before splitting (if it is, the number of distinct lesions will be less than $7470$, and the proportions will be different).\n",
    "1. Randomly select (without replacement) a proportion of our $7470$ distinct ```lesion_id```s and label them with ```t``` (train). \n",
    "2. Label the remaining ```lesion_id```s with ```v``` (validate).\n",
    "3. For each ```lesion_id``` labeled with a ```t```:\n",
    "    * Select an ```image_id``` and label it ```t1```.\n",
    "    * Label all (if any) remaining ```image_id```s corresponding to this ```lesion_id``` with ```ta```.\n",
    "4.  For each ```lesion_id``` labeled with a ```v```:\n",
    "    * Select an ```image_id``` and label it ```v1```.\n",
    "    * Label all (if any) remaining ```image_id```s corresponding to this ```lesion_id``` with ```va```.\n",
    "\n",
    "In Step 1, the number of ```lesion_id```s randomly selected to be labeled ```t``` will be such that the ratio of ```t```s to ```v```s is as close as possible to a specified ratio ```tvr``` (we default to $3$, i.e. $\\approx75\\%$ of lesions are represented in training). In Steps 3 and 4, the first substep can be done randomly (our default choice), or we can simply choose the \"first\" image in our table that corresponds to the lesion (see ```keep_first``` attribute of the ```process``` class). \n",
    "\n",
    "The four train/val scenarios we could consider are:\n",
    "* ```t1v1```: train on precisely those images labeled ```t1``` and validate on precisely those labeled ```v1```.\n",
    "* ```t1va```: train on precisely those images labeled ```t1``` and validate on precisely those labeled ```v1``` **or** ```va```.\n",
    "* ```tav1```: train on precisely those images labeled ```t1``` **or** ```ta``` and validate on precisely those labeled ```v1```.\n",
    "* ```tava```: train on precisely those images labeled ```t1``` **or** ```ta``` and validate on precisely those labeled ```v1``` ***or*** ```va```.\n",
    "\n",
    "The mnemonic is ```t``` for training, ```v``` for validation, ```1``` for one-image-per-lesion, and ```a``` for all images.\n",
    "<!-- </details> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5f71744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================\n",
      "FIRST FIVE ROWS OF METADATA TABLE\n",
      "=================================\n",
      "\n",
      "ADDED COLUMNS\n",
      "\n",
      "- 'num_images': number of images of lesion in dataset\n",
      "- 'label': class to which lesion belongs\n",
      "- 'set': train/val assignment\n",
      "- 't*': lesion is in the training set\n",
      "- 'v*': lesion is in the validation set\n",
      "- 't1': we would train on this image if training a model on exactly one, or on all, image(s) per lesion in the training set\n",
      "- If training set is balanced using one image per lesion, this one image would be re-used as many times as necessary.\n",
      "- 'ta': we would train on this image if training a model on all images of each lesion in the training set\n",
      "- If training set is balanced using all images per lesion, images labeled ta would all be used before any image is repeated.\n",
      "- 'v1': we'd use this image if validating a model on exactly one, or on all, image(s) per lesion in the validation set\n",
      "- If a validation expansion factor is given, this one image would be re-used that many times\n",
      "- 'va': we'd use this image if validating on all images of each lesion in the validation set\n",
      "- If a validation expansion factor is given, iamges labeled va would all be used before any image is repeated.\n",
      "- NB: if more than one image is used for any lesion in validation, the predictions will be combined into a single prediction\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  num_images      image_id   dx  label dx_type   age   sex  \\\n",
       "0  HAM_0000118           2  ISIC_0027419  bkl      0   histo  80.0  male   \n",
       "1  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "2  HAM_0002730           2  ISIC_0026769  bkl      0   histo  80.0  male   \n",
       "3  HAM_0002730           2  ISIC_0025661  bkl      0   histo  80.0  male   \n",
       "4  HAM_0001466           2  ISIC_0031633  bkl      0   histo  75.0  male   \n",
       "\n",
       "  localization set  \n",
       "0        scalp  ta  \n",
       "1        scalp  t1  \n",
       "2        scalp  va  \n",
       "3        scalp  v1  \n",
       "4          ear  va  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's have a look at our metadata dataframe, which is now just an attribute of the metadata instance of the process class.\n",
    "from utils import print_header\n",
    "\n",
    "instance = demo\n",
    "df = instance.df\n",
    "\n",
    "print_header(\"First five rows of metadata table\")\n",
    "\n",
    "to_print = [\"Added columns\\n\".upper(), \n",
    "            \"\\'num_images\\': number of images of lesion in dataset\", \n",
    "            \"\\'label\\': class to which lesion belongs\",\n",
    "            \"\\'set\\': train/val assignment\",\n",
    "            \"\\'t*\\': lesion is in the training set\",\n",
    "            \"\\'v*\\': lesion is in the validation set\",\n",
    "            \"\\'t1\\': we would train on this image if training a model on exactly one, or on all, image(s) per lesion in the training set\",\n",
    "            \"If training set is balanced using one image per lesion, this one image would be re-used as many times as necessary.\",\n",
    "            \"\\'ta\\': we would train on this image if training a model on all images of each lesion in the training set\",\n",
    "            \"If training set is balanced using all images per lesion, images labeled ta would all be used before any image is repeated.\",\n",
    "            \"\\'v1': we\\'d use this image if validating a model on exactly one, or on all, image(s) per lesion in the validation set\",\n",
    "            \"If a validation expansion factor is given, this one image would be re-used that many times\",\n",
    "            \"\\'va': we\\'d use this image if validating on all images of each lesion in the validation set\" ,\n",
    "            \"If a validation expansion factor is given, iamges labeled va would all be used before any image is repeated.\",\n",
    "            \"NB: if more than one image is used for any lesion in validation, the predictions will be combined into a single prediction\"\n",
    "           ]\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb0736c",
   "metadata": {},
   "source": [
    "## Balancing the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f4cb43",
   "metadata": {},
   "source": [
    "<!-- <details>\n",
    "    <summary><b><i>Balancing/upsampling explanation: click here to expand/collapse</i></b></summary> -->\n",
    "\n",
    "We explain the balancing procedure by way of example. (This is performed by the ```balance``` method of the ```process``` class in our ```processing``` module.) We assume the dataset has not been filtered, training to validation ratio is $3$, etc. There are $460$ distinct melanoma lesions represented in our training set. As most melanoma are represented by multiple distinct images, there are a total of $831$ distinct images of melanoma lesions in our training set. Suppose we want our training set to contain $2000$ melanoma images: each of the $460$ distinct melanoma lesions will be represented by $2000/460 \\approx 4.35$ images on average. We do not merely sample with replacement.\n",
    "\n",
    "The goal is to (a) have as little variance as possible in the number of times a lesion is represented, and (b) use as many distinct images as possible (taking advantage of the fact that there are multiple _distinct_ images of most melanoma). Thus, we note that $2000 = 4\\times 460 + 160$, so we will use each of the $460$ distinct melanoma lesions four times, and make the remainder up by randomly sample $160$ distinct lesions from the $160$. In other words, exactly $300$ distinct lesions will each be represented by exactly four images, and exactly $160$ distinct lesions will each be represented by exactly five images: $2000 = 300 \\times 4 + 160 \\times 5$. \n",
    "\n",
    "How do we select the four images of each distinct melanoma lesion (plus another one image for $160$ of them)? Consider lesion id ```HAM_0000871``` for example: there are three distinct images of this lesion in our data set. Thus, if ```train_one_img_per_lesion``` is ```False```, we will use all three of them, and then randomly select one more (or two more if this particular lesion were to be one of the $160$ that are represented five times). See below. On the other hand, if ```train_one_img_per_lesion``` is ```True```, we have no choice but to use the one image (label ```t1```) four times.\n",
    "    \n",
    "<!-- </details> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c4a51e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "EG: REPRESENTATIONS OF LESION HAM_0000871 IN BALANCED TRAINING SET\n",
      "==================================================================\n",
      "\n",
      "HAM_0000871 REPRESENTED BY FOUR IMAGES\n",
      "\n",
      "- Three distinct images of this lesion to choose from: ISIC_0025964, ISIC_0030623, and ISIC_0025964\n",
      "- Use ISIC_0025964 once, ISIC_0030623 twice, and ISIC_0025964 once\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0025964</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0025964</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0030623</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0026506</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>trunk</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id  lesion_mult  num_images      image_id  img_mult   dx  \\\n",
       "1773  HAM_0000871            4           3  ISIC_0025964         2  mel   \n",
       "1774  HAM_0000871            4           3  ISIC_0025964         2  mel   \n",
       "1775  HAM_0000871            4           3  ISIC_0030623         1  mel   \n",
       "3087  HAM_0000871            4           3  ISIC_0026506         1  mel   \n",
       "\n",
       "      label dx_type   age     sex localization set  \n",
       "1773      3   histo  40.0  female        chest  ta  \n",
       "1774      3   histo  40.0  female        chest  ta  \n",
       "1775      3   histo  40.0  female        chest  t1  \n",
       "3087      3   histo  40.0  female        trunk  ta  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "\n",
    "# The specific numbers in this example assume a certain choice for the attributes, including \n",
    "# sample_size: Union[None, dict] = {\"mel\": 2000,         \n",
    "#                                   \"bcc\": 2000, \n",
    "#                                   \"akiec\": 2000, \n",
    "#                                   \"nv\": 2000,\n",
    "#                                   \"other\" : 2000,}\n",
    "\n",
    "instance = demo\n",
    "df = demo.df_train\n",
    "\n",
    "print_header(\"Eg: Representations of lesion HAM_0000871 in balanced training set\")\n",
    "\n",
    "to_print = [\"HAM_0000871 represented by four images\\n\".upper(),\n",
    "            \"Three distinct images of this lesion to choose from: ISIC_0025964, ISIC_0030623, and ISIC_0025964\",\n",
    "            \"Use ISIC_0025964 once, ISIC_0030623 twice, and ISIC_0025964 once\",]\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "display(df[df['lesion_id'] == 'HAM_0000871'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a797a173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================\n",
      "EG: MELANOMA IN BALANCED TRAINING SET\n",
      "=====================================\n",
      "\n",
      "VALUE COUNTS FOR 'LESION_MULT' COLUMN\n",
      "\n",
      "- 300 distinct melanoma lesions each represented by four images: 300*4 = 1200\n",
      "- 160 distinct melanoma lesions each represented by five images: 160*5 = 800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4    1200\n",
       "5     800\n",
       "Name: lesion_mult, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0025964</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0030623</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>HAM_0000040</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0027190</td>\n",
       "      <td>5</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>HAM_0000040</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0027190</td>\n",
       "      <td>5</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>HAM_0000040</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0027190</td>\n",
       "      <td>5</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7773</th>\n",
       "      <td>HAM_0002552</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0032936</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7781</th>\n",
       "      <td>HAM_0002552</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0033232</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7782</th>\n",
       "      <td>HAM_0002552</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0033232</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>HAM_0003521</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0032258</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>HAM_0003521</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0032258</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id  lesion_mult  num_images      image_id  img_mult   dx  \\\n",
       "1773  HAM_0000871            4           3  ISIC_0025964         1  mel   \n",
       "1774  HAM_0000871            4           3  ISIC_0030623         1  mel   \n",
       "1775  HAM_0000040            5           1  ISIC_0027190         5  mel   \n",
       "1776  HAM_0000040            5           1  ISIC_0027190         5  mel   \n",
       "1777  HAM_0000040            5           1  ISIC_0027190         5  mel   \n",
       "...           ...          ...         ...           ...       ...  ...   \n",
       "7773  HAM_0002552            5           3  ISIC_0032936         2  mel   \n",
       "7781  HAM_0002552            5           3  ISIC_0033232         2  mel   \n",
       "7782  HAM_0002552            5           3  ISIC_0033232         2  mel   \n",
       "9998  HAM_0003521            5           2  ISIC_0032258         2  mel   \n",
       "9999  HAM_0003521            5           2  ISIC_0032258         2  mel   \n",
       "\n",
       "      label dx_type   age     sex     localization set  \n",
       "1773      1   histo  40.0  female            chest  ta  \n",
       "1774      1   histo  40.0  female            chest  t1  \n",
       "1775      1   histo  80.0    male  upper extremity  t1  \n",
       "1776      1   histo  80.0    male  upper extremity  t1  \n",
       "1777      1   histo  80.0    male  upper extremity  t1  \n",
       "...     ...     ...   ...     ...              ...  ..  \n",
       "7773      1   histo  25.0    male  upper extremity  ta  \n",
       "7781      1   histo  25.0    male  upper extremity  ta  \n",
       "7782      1   histo  25.0    male  upper extremity  ta  \n",
       "9998      1   histo  70.0  female             back  ta  \n",
       "9999      1   histo  70.0  female             back  ta  \n",
       "\n",
       "[2000 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "# The specific numbers given in this example assume a certain choice for the attributes, including \n",
    "# sample_size: Union[None, dict] = {\"mel\": 2000,         \n",
    "#                                   \"bcc\": 2000, \n",
    "#                                   \"akiec\": 2000, \n",
    "#                                   \"nv\": 2000,\n",
    "#                                   \"other\" : 2000,}\n",
    "\n",
    "instance = demo\n",
    "df = demo.df_train\n",
    "df = df[df['set'].isin([\"ta\", \"t1\"]) & (df['dx'] == 'mel')]\n",
    "\n",
    "print_header(\"Eg: Melanoma in balanced training set\")\n",
    "\n",
    "to_print = [\"Value counts for \\'lesion_mult\\' column\\n\".upper(),\n",
    "            \"300 distinct melanoma lesions each represented by four images: 300*4 = 1200\",\n",
    "            \"160 distinct melanoma lesions each represented by five images: 160*5 = 800\",]\n",
    "\n",
    "print(\"\\n- \".join(to_print[:3]))\n",
    "display(df['lesion_mult'].value_counts())\n",
    "\n",
    "print(\"\\n- \".join(to_print[3:]))\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3d5ede",
   "metadata": {},
   "source": [
    "## Expanding the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5f3b8",
   "metadata": {},
   "source": [
    "As mentioned already, we make one prediction per lesion. However, we may have multiple images of a given lesion at our disposal: we could make a prediction for each of them and combine them somehow into a single prediction for the lesion. Even if there is only one image of a lesion, we could make multiple predictions on it: if a random transformation is applied to an image before our model makes a prediction on it, this would yield a different array of probabilities each time. Again, we could combine the results into a single prediction.\n",
    "\n",
    "This is what the attribute ```val_expansion_factor``` of the ```process``` class is concerned with. Similarly to the way we balance the training set, we can replicate one single image per lesion in the validation set as many times as specified by ```val_expansion_factor```, as in ```self.df_val1```, or we can take advantage of other images of the lesion (if available), as in ```self.val_a```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25bef7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "EG: MELANOMA IN EXPANDED VALIDATION SET (ONLY ONE IMAGE PER LESION USED)\n",
      "========================================================================\n",
      "\n",
      "- Note that 'lesion_mult' is always 3\n",
      "- HAM_0005678 represented by three images\n",
      "- Two distinct images of this lesion: ISIC_0031023 and ISIC_0028086\n",
      "- However, only use ISIC_0031023 (3 times)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>HAM_0006722</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031499</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>HAM_0006722</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031499</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>HAM_0004081</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0031957</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>HAM_0004081</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0031957</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028764</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028764</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028764</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id  lesion_mult  num_images      image_id  img_mult   dx  \\\n",
       "603   HAM_0005678            3           2  ISIC_0031023         3  mel   \n",
       "604   HAM_0005678            3           2  ISIC_0031023         3  mel   \n",
       "605   HAM_0005678            3           2  ISIC_0031023         3  mel   \n",
       "606   HAM_0006722            3           2  ISIC_0031499         3  mel   \n",
       "607   HAM_0006722            3           2  ISIC_0031499         3  mel   \n",
       "...           ...          ...         ...           ...       ...  ...   \n",
       "1060  HAM_0004081            3           1  ISIC_0031957         3  mel   \n",
       "1061  HAM_0004081            3           1  ISIC_0031957         3  mel   \n",
       "1062  HAM_0004746            3           2  ISIC_0028764         3  mel   \n",
       "1063  HAM_0004746            3           2  ISIC_0028764         3  mel   \n",
       "1064  HAM_0004746            3           2  ISIC_0028764         3  mel   \n",
       "\n",
       "      label dx_type   age     sex     localization set  \n",
       "603       3   histo  60.0    male            chest  v1  \n",
       "604       3   histo  60.0    male            chest  v1  \n",
       "605       3   histo  60.0    male            chest  v1  \n",
       "606       3   histo  85.0  female  lower extremity  v1  \n",
       "607       3   histo  85.0  female  lower extremity  v1  \n",
       "...     ...     ...   ...     ...              ...  ..  \n",
       "1060      3   histo  70.0  female  lower extremity  v1  \n",
       "1061      3   histo  70.0  female  lower extremity  v1  \n",
       "1062      3   histo  65.0  female             back  v1  \n",
       "1063      3   histo  65.0  female             back  v1  \n",
       "1064      3   histo  65.0  female             back  v1  \n",
       "\n",
       "[462 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================\n",
      "EG: MELANOMA IN EXPANDED VALIDATION SET (ALL IMAGES USED)\n",
      "=========================================================\n",
      "\n",
      "- Note that 'lesion_mult' is always 3\n",
      "- HAM_0005678 represented by three images\n",
      "- Two distinct images of this lesion to choose from: ISIC_0031023 and ISIC_0028086\n",
      "- Use ISIC_0031023 once, and ISIC_0028086 twice\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028086</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028086</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>HAM_0006722</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0030443</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>HAM_0006722</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031499</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028764</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028764</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0029021</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>HAM_0002525</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025188</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>HAM_0001953</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025611</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id  lesion_mult  num_images      image_id  img_mult   dx  \\\n",
       "603   HAM_0005678            3           2  ISIC_0031023         1  mel   \n",
       "604   HAM_0005678            3           2  ISIC_0028086         2  mel   \n",
       "605   HAM_0005678            3           2  ISIC_0028086         2  mel   \n",
       "606   HAM_0006722            3           2  ISIC_0030443         1  mel   \n",
       "607   HAM_0006722            3           2  ISIC_0031499         2  mel   \n",
       "...           ...          ...         ...           ...       ...  ...   \n",
       "1060  HAM_0004746            3           2  ISIC_0028764         2  mel   \n",
       "1061  HAM_0004746            3           2  ISIC_0028764         2  mel   \n",
       "1062  HAM_0004746            3           2  ISIC_0029021         1  mel   \n",
       "1063  HAM_0002525            3           2  ISIC_0025188         1  mel   \n",
       "1064  HAM_0001953            3           2  ISIC_0025611         1  mel   \n",
       "\n",
       "      label dx_type   age     sex     localization set  \n",
       "603       3   histo  60.0    male            chest  v1  \n",
       "604       3   histo  60.0    male            chest  va  \n",
       "605       3   histo  60.0    male            chest  va  \n",
       "606       3   histo  85.0  female  lower extremity  va  \n",
       "607       3   histo  85.0  female  lower extremity  v1  \n",
       "...     ...     ...   ...     ...              ...  ..  \n",
       "1060      3   histo  65.0  female             back  v1  \n",
       "1061      3   histo  65.0  female             back  v1  \n",
       "1062      3   histo  65.0  female             back  va  \n",
       "1063      3   histo  55.0    male             face  va  \n",
       "1064      3   histo  65.0    male             back  va  \n",
       "\n",
       "[462 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "# The specific numbers given in this example assume a certain choice for the attributes  \n",
    "\n",
    "instance = demo\n",
    "\n",
    "df = demo.df_val1\n",
    "df = df[df['set'].isin([\"va\", \"v1\"]) & (df['dx'] == 'mel')]\n",
    "\n",
    "print_header(\"Eg: Melanoma in expanded validation set (only one image per lesion used)\")\n",
    "\n",
    "to_print = [f\"- Note that \\'lesion_mult\\' is always {instance.val_expansion_factor}\",\n",
    "            \"HAM_0005678 represented by three images\",\n",
    "            \"Two distinct images of this lesion: ISIC_0031023 and ISIC_0028086\",\n",
    "            f\"However, only use ISIC_0031023 ({instance.val_expansion_factor} times)\",]\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "display(df)\n",
    "\n",
    "df = demo.df_val_a\n",
    "df = df[df['set'].isin([\"va\", \"v1\"]) & (df['dx'] == 'mel')]\n",
    "\n",
    "print_header(\"Eg: Melanoma in expanded validation set (all images used)\")\n",
    "\n",
    "to_print = [f\"- Note that \\'lesion_mult\\' is always {instance.val_expansion_factor}\",\n",
    "            \"HAM_0005678 represented by three images\",\n",
    "            \"Two distinct images of this lesion to choose from: ISIC_0031023 and ISIC_0028086\",\n",
    "            \"Use ISIC_0031023 once, and ISIC_0028086 twice\",]\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d46cea",
   "metadata": {},
   "source": [
    "## Fine-tuning EfficientNet or ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de51e9f",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aa1884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's set values for the attributes of our resnet18 class (the model we will use with out processed data).\n",
    "# One of the attributes has to do with image transformations.\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    \n",
    "transforms.RandomCrop((300, 300)),\n",
    "transforms.Resize((224,224)), # Resize images to fit ResNet input size\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet stats\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17a72b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Union, List, Callable\n",
    "import torchvision.models as models\n",
    "\n",
    "source: Union[process, pd.DataFrame] = demo      # Processed data to be fed into model for training.\n",
    "                                                 # Must either be an instance of the process class, or a dataframe of the same format as source.df if source were an instance of the process class.\n",
    "model_dir: Path = path[\"models\"]                 # Path to directory where models/model info/model results are stored.\n",
    "transform: Union[None, \n",
    "                 transforms.Compose, \n",
    "                 List[Callable]] = transform     # Transform to be applied to images before feeding into neural network.\n",
    "batch_size: Union[None, int] = 32                # Mini-batch size: default 32.\n",
    "epochs: Union[None, int] = 10                    # Number of epochs (all layers unfrozen from the start): default 10.\n",
    "base_learning_rate: Union[None, float] = 1/1000  # Learning rate to start with: default 1/1000. Using Adam optimizer.\n",
    "filename_stem: Union[None, str] = \"rn18\"         # For saving model and related files. Default \"rn18\" (if ResNet model) or \"EffNet\" (if EfficientNet), or \"cnn\".\n",
    "filename_suffix: Union[None, str] = \"demo\"       # Something descriptive and unique for future reference. Default empty string \"\".\n",
    "overwrite: Union[None, bool] = True              # If False, any will generate an unused filename for saving .pth, .csv files etc., but appending a two-digit number.\n",
    "                                                 # If None, will default to False. Only set to True if confident that training done on previous instances with same filename stem and suffix can be over-written.\n",
    "code_test: Union[None, bool] = True\n",
    "# model: Union[None, models.ResNet, models.EfficientNet] = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT) # Pre-trained model. Default: ResNet18.   \n",
    "model: Union[None, models.ResNet, models.EfficientNet] = models.resnet18(weights=\"ResNet18_Weights.DEFAULT\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da0fe522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============\n",
      "CODE TEST MODE\n",
      "==============\n",
      "\n",
      "- self.epochs set to 1\n",
      "- self.Print set to True\n",
      "- self.filename_suffix set to 'test'\n",
      "- self.overwrite set to True\n",
      "- self.df_train, self.df_val1, self.df_val_a replaced with a small number of records\n",
      "- Change code_test attribute to False and re-create/create new cnn instance after testing is done.\n",
      "\n",
      "Existing files will be overwritten. \n",
      "Base filename: rn18_ta_bal_test_1e_test_00\n",
      "Attributes saved to file: D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_test_1e_test_00_attributes.json\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the resnet18 class with attribute values as above.\n",
    "from multiclass_models import cnn\n",
    "\n",
    "resnet_demo = cnn(                                   \n",
    "    source=source,                                           \n",
    "    model_dir=model_dir,\n",
    "    transform=transform,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,                                          \n",
    "    base_learning_rate=base_learning_rate,\n",
    "    filename_stem=filename_stem,\n",
    "    filename_suffix=filename_suffix,                         \n",
    "    overwrite=overwrite,\n",
    "    code_test=code_test,    \n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b087606d",
   "metadata": {},
   "source": [
    "### Code test with small batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7fa41b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================\n",
      "CODE TEST: TRAINING SET\n",
      "=======================\n",
      "\n",
      "170 IMAGES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0003768</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0029929</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0004928</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031424</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>neck</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0004928</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0029770</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>neck</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0004928</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0029770</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>neck</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0003768</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0026634</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  lesion_mult  num_images      image_id  img_mult   dx  label  \\\n",
       "0  HAM_0003768            3           2  ISIC_0029929         1  bkl      0   \n",
       "1  HAM_0004928            3           2  ISIC_0031424         1  bkl      0   \n",
       "2  HAM_0004928            3           2  ISIC_0029770         2  bkl      0   \n",
       "3  HAM_0004928            3           2  ISIC_0029770         2  bkl      0   \n",
       "4  HAM_0003768            3           2  ISIC_0026634         2  bkl      0   \n",
       "\n",
       "  dx_type   age   sex     localization set  \n",
       "0   histo  80.0  male  upper extremity  t1  \n",
       "1   histo  65.0  male             neck  t1  \n",
       "2   histo  65.0  male             neck  ta  \n",
       "3   histo  65.0  male             neck  ta  \n",
       "4   histo  80.0  male  upper extremity  ta  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "CODE TEST: VALIDATION SET (ONE IMAGE PER LESION, REPEATED 3 TIMES)\n",
      "==================================================================\n",
      "\n",
      "42 IMAGES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  lesion_mult  num_images      image_id  img_mult   dx  label  \\\n",
       "0  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "1  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "2  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "3  HAM_0000983            3           1  ISIC_0033490         3  bkl      0   \n",
       "4  HAM_0000983            3           1  ISIC_0033490         3  bkl      0   \n",
       "\n",
       "     dx_type   age      sex localization set  \n",
       "0  consensus  75.0     male         back  v1  \n",
       "1  consensus  75.0     male         back  v1  \n",
       "2  consensus  75.0     male         back  v1  \n",
       "3  consensus   NaN  unknown      unknown  v1  \n",
       "4  consensus   NaN  unknown      unknown  v1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "CODE TEST: VALIDATION SET (3 POSSIBLY DIFFERENT IMAGES PER LESION)\n",
      "==================================================================\n",
      "\n",
      "42 IMAGES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0034125</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0033060</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0033060</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0003943</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0031078</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0003943</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0031464</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  lesion_mult  num_images      image_id  img_mult   dx  label  \\\n",
       "0  HAM_0004406            3           2  ISIC_0034125         1  bkl      0   \n",
       "1  HAM_0004406            3           2  ISIC_0033060         2  bkl      0   \n",
       "2  HAM_0004406            3           2  ISIC_0033060         2  bkl      0   \n",
       "3  HAM_0003943            3           3  ISIC_0031078         1  bkl      0   \n",
       "4  HAM_0003943            3           3  ISIC_0031464         1  bkl      0   \n",
       "\n",
       "  dx_type   age     sex     localization set  \n",
       "0   histo  80.0    male             back  va  \n",
       "1   histo  80.0    male             back  v1  \n",
       "2   histo  80.0    male             back  v1  \n",
       "3   histo  80.0  female  lower extremity  va  \n",
       "4   histo  80.0  female  lower extremity  v1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "print_header(\"Code test: training set\")\n",
    "print(f\"{instance.df_train.shape[0]} images\".upper())\n",
    "display(instance.df_train.head())\n",
    "\n",
    "print_header(f\"Code test: validation set (one image per lesion, repeated {instance.source.val_expansion_factor} times)\")\n",
    "print(f\"{instance.df_val1.shape[0]} images\".upper())\n",
    "display(instance.df_val1.head())\n",
    "\n",
    "print_header(f\"Code test: validation set ({instance.source.val_expansion_factor} possibly different images per lesion)\")\n",
    "print(f\"{instance.df_val_a.shape[0]} images\".upper())\n",
    "display(instance.df_val_a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f198de9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================\n",
      "CODE TEST: TRAINING AND VALIDATION\n",
      "==================================\n",
      "\n",
      "image_id, label, ohe-label: ISIC_0031831, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029891, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033278, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033065, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025927, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028314, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033860, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031526, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0032652, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0026634, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031526, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029099, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029770, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024825, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027149, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030953, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029770, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025302, 0, tensor([1., 0., 0., 0., 0.])\n",
      "outputs.shape: torch.Size([32, 5])\n",
      "loss: 1.7418774366378784\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028314, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031526, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0032652, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0027560, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030953, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028076, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030953, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031424, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031831, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033278, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032715, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028076, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027598, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025302, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0026789, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030142, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032114, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0027560, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033551, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0033571, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "outputs.shape: torch.Size([32, 5])\n",
      "loss: 1.1016082763671875\n",
      "image_id, label, ohe-label: ISIC_0024997, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025302, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024825, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026634, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033571, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030230, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0034219, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025628, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033571, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029514, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0032438, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0033847, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0033975, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027560, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0025927, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0027672, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033991, 0, tensor([1., 0., 0., 0., 0.])\n",
      "outputs.shape: torch.Size([32, 5])\n",
      "loss: 0.5090758204460144\n",
      "image_id, label, ohe-label: ISIC_0029099, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030953, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031728, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028076, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0031217, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030953, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027149, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033551, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030142, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0024932, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025599, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032652, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024997, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025628, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029099, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031669, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025927, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029929, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032114, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030230, 4, tensor([0., 0., 0., 0., 1.])\n",
      "outputs.shape: torch.Size([32, 5])\n",
      "loss: 0.26072683930397034\n",
      "image_id, label, ohe-label: ISIC_0028314, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033991, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024932, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025927, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028314, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033679, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033860, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029480, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0027598, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027560, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031728, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028076, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031217, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027672, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0027149, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031728, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0024997, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030142, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024973, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033278, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030142, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027149, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025345, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "outputs.shape: torch.Size([32, 5])\n",
      "loss: 0.3454873859882355\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0031831, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025927, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029480, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0027598, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025628, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024973, 0, tensor([1., 0., 0., 0., 0.])\n",
      "outputs.shape: torch.Size([10, 5])\n",
      "loss: 0.3341825604438782\n",
      "Validating (one image per lesion)...\n",
      "image_id, label, ohe-label: ISIC_0033305, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033305, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033305, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033490, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033490, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033490, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024991, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024991, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024991, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024937, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024937, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024937, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032410, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032410, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032410, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028735, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028735, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028735, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031498, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031498, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031498, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028930, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028930, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028930, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030956, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030956, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030956, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024867, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024867, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024867, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028739, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028739, 4, tensor([0., 0., 0., 0., 1.])\n",
      "outputs.shape: torch.Size([10, 5])\n",
      "val1_loss: 4.740045070648193\n",
      "image_id, label, ohe-label: ISIC_0028739, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029917, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029917, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029917, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0026014, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026014, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026014, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027254, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027254, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027254, 1, tensor([0., 1., 0., 0., 0.])\n",
      "outputs.shape: torch.Size([10, 5])\n",
      "val1_loss: 5.295468330383301\n",
      "Validating (all images per lesion)...\n",
      "image_id, label, ohe-label: ISIC_0034125, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033060, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033060, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031078, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031464, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025973, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027484, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027484, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027484, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026598, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026598, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026598, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031372, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031372, 0, tensor([1., 0., 0., 0., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id, label, ohe-label: ISIC_0026313, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026629, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026629, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026629, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030443, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031499, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031499, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033299, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033299, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033299, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032692, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033608, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033969, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028680, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028680, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028680, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027058, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030114, 4, tensor([0., 0., 0., 0., 1.])\n",
      "outputs.shape: torch.Size([10, 5])\n",
      "val_a_loss: 4.924468994140625\n",
      "image_id, label, ohe-label: ISIC_0030114, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0026940, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0032429, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029951, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028816, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028816, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028232, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024329, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024329, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024329, 1, tensor([0., 1., 0., 0., 0.])\n",
      "outputs.shape: torch.Size([10, 5])\n",
      "val_a_loss: 2.817688465118408\n",
      "Epoch 1/1, Training Loss: 0.7155, Validation Loss 1: 5.0178, Validation Loss a: 3.8711\n",
      "Saving model.state_dict() as D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_test_1e_test_00.pth.\n",
      "model.state_dict() can now be accessed through state_dict attribute.\n",
      "Train/val losses can now be accessed through epoch_losses attribute.\n",
      "Epoch losses dictionary save as D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_test_1e_test_00_epoch_losses.json\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the specified training data by calling the train method:\n",
    "# from utils import print_header\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "print_header(\"Code test: training and validation\")\n",
    "instance.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a722d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========\n",
      "CODE TEST\n",
      "=========\n",
      "\n",
      "LOSS DICTIONARY (TRAINING AND VALIDATION LOSS FROM EACH EPOCH)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': array([0.71549305]),\n",
       " 'val1_loss': array([5.0177567]),\n",
       " 'val_a_loss': array([3.87107873])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import load_dict\n",
    "\n",
    "# Let's look at the training and validation loss for each epoch:\n",
    "instance = resnet_demo\n",
    "\n",
    "print_header(\"Code test\")\n",
    "print(f\"Loss dictionary (TRAINING AND VALIDATION LOSS FROM EACH EPOCH)\".upper())\n",
    "\n",
    "try:\n",
    "    if instance.epoch_losses is not None:\n",
    "        display(instance.epoch_losses)\n",
    "    else:\n",
    "        retrieved_epoch_losses = load_dict(instance.model_dir, instance._filename + \"_epoch_losses\")\n",
    "        display(retrieved_epoch_losses)\n",
    "except:\n",
    "    retrieved_epoch_losses = load_dict(instance.model_dir, instance._filename + \"_epoch_losses\")\n",
    "    display(retrieved_epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3552fe8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "CODE TEST: MODEL ARCHITECTURE AND STATE DICTIONARY\n",
      "==================================================\n",
      "\n",
      "\n",
      "==============================\n",
      "CODE TEST:  MODEL ARCHITECTURE\n",
      "==============================\n",
      "\n",
      "NOTE: 'OUT_FEATURES=5' AT THE END\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "print_header(\"Code test: model architecture and state dictionary\")\n",
    "\n",
    "if instance.state_dict is None:\n",
    "    print(\"Loading model and state dictionary from file\\n\".upper())\n",
    "    file_path_pth = instance.model_dir.joinpath(instance._filename + \".pth\")\n",
    "\n",
    "    # model = models.efficientnet_b0()  \n",
    "    model = models.resnet18()  \n",
    "    if isinstance(model,models.ResNet):\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "    elif isinstance(model,models.EfficientNet):\n",
    "        num_ftrs = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "\n",
    "    # Load the state dictionary into the model\n",
    "    state_dict = torch.load(file_path_pth)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    instance.model = model\n",
    "    instance.state_dict = state_dict\n",
    "    \n",
    "print_header(\"Code test:  model architecture\")\n",
    "print(f\"Note: \\'out_features={len(instance.label_codes)}\\' at the end\".upper())\n",
    "display(instance.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cb6aa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================\n",
      "CODE TEST: MODEL STATE DICTIONARY\n",
      "=================================\n",
      "\n",
      "OrderedDict([('conv1.weight', tensor([[[[-1.2006e-02, -5.9770e-03, -1.8481e-03,  ...,  5.5908e-02,\n",
      "            1.6073e-02, -1.4027e-02],\n",
      "          [ 9.5711e-03,  9.5411e-03, -1.1017e-01,  ..., -2.7173e-01,\n",
      "           -1.2985e-01,  2.4616e-03],\n",
      "          [-8.6098e-03,  5.9050e-02,  2.9509e-01,  ...,  5.1917e-01,\n",
      "            2.5565e-01,  6.2269e-02],\n",
      "          ...,\n",
      "          [-2.8976e-02,  1.5986e-02,  7.2161e-02,  ..., -3.3399e-01,\n",
      "           -4.2163e-01, -2.5939e-01],\n",
      "          [ 2.8915e-02,  4.0837e-02,  6.2291e-02,  ...,  4.1259e-01,\n",
      "            3.9243e-01,  1.6449e-01],\n",
      "          [-1.5208e-02, -3.4787e-03, -2.4442e-02,  ..., -1.5184e-01,\n",
      "           -8.3447e-02, -7.1686e-03]],\n",
      "\n",
      "         [[-1.0895e-02, -2.5281e-02, -3.3266e-02,  ...,  3.1528e-02,\n",
      "           -3.0424e-03, -2.9929e-02],\n",
      "          [ 4.6378e-02,  3.5028e-02, -1.0307e-01,  ..., -3.1316e-01,\n",
      "           -1.6438e-01, -5.5776e-03],\n",
      "          [-3.2989e-03,  9.9680e-02,  4.0311e-01,  ...,  7.0678e-01,\n",
      "            3.6481e-01,  1.2 \n",
      " ... LOTS OF PARAMETERS ...\n",
      " 18, 0.0158, 0.0155, 0.0148, 0.0150,\n",
      "        0.0150, 0.0135, 0.0142, 0.0130, 0.0150, 0.0132, 0.0126, 0.0143, 0.0151,\n",
      "        0.0163, 0.0168, 0.0201, 0.0141, 0.0189, 0.0226, 0.0169, 0.0149, 0.0117,\n",
      "        0.0169, 0.0149, 0.0140, 0.0150, 0.0162, 0.0193, 0.0153, 0.0191, 0.0138,\n",
      "        0.0124, 0.0168, 0.0178, 0.0138, 0.0224, 0.0161, 0.0182, 0.0146])), ('layer4.1.bn2.num_batches_tracked', tensor(6)), ('fc.weight', tensor([[-3.9295e-02, -3.9114e-02,  3.6763e-02,  ..., -4.2130e-02,\n",
      "         -2.4361e-02, -2.0849e-02],\n",
      "        [-2.2168e-04, -1.2359e-02, -2.9131e-02,  ...,  3.5991e-02,\n",
      "         -1.0843e-02, -3.7493e-02],\n",
      "        [ 3.1506e-02,  6.3725e-03,  6.8541e-03,  ..., -3.2469e-03,\n",
      "          2.0672e-05,  1.7937e-02],\n",
      "        [ 2.2938e-02, -8.3793e-03, -2.9423e-02,  ...,  3.8011e-02,\n",
      "         -4.3971e-02, -2.5574e-02],\n",
      "        [-2.9116e-02,  9.3925e-03,  3.8854e-02,  ...,  1.4246e-02,\n",
      "          1.4247e-02,  2.6793e-02]])), ('fc.bias', tensor([ 0.0284, -0.0297, -0.0311,  0.0361, -0.0323]))])\n"
     ]
    }
   ],
   "source": [
    "print_header(\"Code test: model state dictionary\")\n",
    "print(str(instance.state_dict)[:1000], \"\\n ... LOTS OF PARAMETERS ...\\n\", str(instance.state_dict)[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9a44d31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving probabilities: D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_test_1e_test_00_probabilities.csv\n",
      "Saving probabilities: D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_test_1e_test_00_probabilities.csv\n",
      "\n",
      "===============================================================\n",
      "CODE TEST: PROBABILITIES, VALIDATION SET (ONE IMAGE PER LESION)\n",
      "===============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>bkl</td>\n",
       "      <td>7.460868e-04</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.122082</td>\n",
       "      <td>0.875233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>bkl</td>\n",
       "      <td>1.372970e-04</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.139352</td>\n",
       "      <td>0.859480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>bkl</td>\n",
       "      <td>3.386477e-03</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.278105</td>\n",
       "      <td>0.706586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>bkl</td>\n",
       "      <td>2.949595e-07</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.999971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>bkl</td>\n",
       "      <td>2.715284e-06</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.999931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx    prob_other  prob_akiec   prob_nv  \\\n",
       "0  HAM_0003218  ISIC_0033305  bkl  7.460868e-04    0.001333  0.000606   \n",
       "1  HAM_0003218  ISIC_0033305  bkl  1.372970e-04    0.000913  0.000118   \n",
       "2  HAM_0003218  ISIC_0033305  bkl  3.386477e-03    0.005549  0.006373   \n",
       "3  HAM_0000983  ISIC_0033490  bkl  2.949595e-07    0.000010  0.000002   \n",
       "4  HAM_0000983  ISIC_0033490  bkl  2.715284e-06    0.000006  0.000003   \n",
       "\n",
       "   prob_mel  prob_bcc  \n",
       "0  0.122082  0.875233  \n",
       "1  0.139352  0.859480  \n",
       "2  0.278105  0.706586  \n",
       "3  0.000018  0.999971  \n",
       "4  0.000057  0.999931  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================================\n",
      "CODE TEST: PROBABILITIES, VALIDATION SET (MORE THAN ONE IMAGE PER LESION)\n",
      "=========================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>ISIC_0034125</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.170367</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.186573</td>\n",
       "      <td>0.075787</td>\n",
       "      <td>0.564936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>ISIC_0033060</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.010129</td>\n",
       "      <td>0.989082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>ISIC_0033060</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.996028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0003943</td>\n",
       "      <td>ISIC_0031078</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.012329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0003943</td>\n",
       "      <td>ISIC_0031464</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.978615</td>\n",
       "      <td>0.021300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx  prob_other  prob_akiec   prob_nv  prob_mel  \\\n",
       "0  HAM_0004406  ISIC_0034125  bkl    0.170367    0.002337  0.186573  0.075787   \n",
       "1  HAM_0004406  ISIC_0033060  bkl    0.000015    0.000763  0.000012  0.010129   \n",
       "2  HAM_0004406  ISIC_0033060  bkl    0.000021    0.000561  0.000011  0.003380   \n",
       "3  HAM_0003943  ISIC_0031078  bkl    0.000010    0.000002  0.000005  0.987654   \n",
       "4  HAM_0003943  ISIC_0031464  bkl    0.000020    0.000007  0.000058  0.978615   \n",
       "\n",
       "   prob_bcc  \n",
       "0  0.564936  \n",
       "1  0.989082  \n",
       "2  0.996028  \n",
       "3  0.012329  \n",
       "4  0.021300  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import get_probabilities\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "# model = models.efficientnet_b0()  \n",
    "# model = models.resnet18() \n",
    "# if isinstance(model,models.ResNet):\n",
    "#     num_ftrs = model.fc.in_features\n",
    "#     model.fc = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "# elif isinstance(model,models.EfficientNet):\n",
    "#     num_ftrs = model.classifier[1].in_features\n",
    "#     model.classifier[1] = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "\n",
    "instance.df_probabilities_val1 = get_probabilities(df=instance.df_val1,\n",
    "                                                   data_dir=instance.data_dir,\n",
    "                                                   model_dir=instance.model_dir,\n",
    "                                                   model=instance.model,\n",
    "                                                   filename=instance._filename,\n",
    "                                                   label_codes=instance.label_codes,\n",
    "                                                   transform=instance.transform,\n",
    "                                                   batch_size=instance.batch_size,\n",
    "                                                   Print=False,\n",
    "                                                   save_as=instance._filename,)\n",
    "\n",
    "instance.df_probabilities_val_a = get_probabilities(df=instance.df_val_a,\n",
    "                                                    data_dir=instance.data_dir,\n",
    "                                                    model_dir=instance.model_dir,\n",
    "                                                    model=instance.model,\n",
    "                                                    filename=instance._filename,\n",
    "                                                    label_codes=instance.label_codes,\n",
    "                                                    transform=instance.transform,\n",
    "                                                    batch_size=instance.batch_size,\n",
    "                                                    Print=False,\n",
    "                                                    save_as=instance._filename,)\n",
    "\n",
    "print_header(\"Code test: probabilities, validation set (one image per lesion)\")\n",
    "display_columns = ['lesion_id', 'image_id', 'dx'] + [col for col in instance.df_probabilities_val1.columns if col.startswith('prob')]\n",
    "display(instance.df_probabilities_val1[display_columns].head())\n",
    "\n",
    "print_header(\"Code test: probabilities, validation set (more than one image per lesion)\")\n",
    "display(instance.df_probabilities_val_a[display_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa486a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================================\n",
      "CODE TEST: PREDICTION ON INDIVIDUAL IMAGES OR LESIONS\n",
      "=====================================================\n",
      "\n",
      "- We can make predictions for individual images or lesions.\n",
      "- We only require a dataframe with an 'image_id' column.\n",
      "- Given the filename of an image, the df_from_ids function will construct such a dataframe.\n",
      "- We can then feed this dataframe into the get_probabilities function.\n",
      "- Here is the result of passing 'filenames=['ISIC_0033305','ISIC_0025661']' to df_from_ids:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0033305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0025661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id\n",
       "0  ISIC_0033305\n",
       "1  ISIC_0025661"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- And here are the corresponding probabilities:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>1.133565e-03</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>1.143219e-03</td>\n",
       "      <td>0.083207</td>\n",
       "      <td>0.911576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>3.843240e-08</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>7.986385e-08</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.999793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id    prob_other  prob_akiec       prob_nv  prob_mel  prob_bcc\n",
       "0  ISIC_0033305  1.133565e-03    0.002940  1.143219e-03  0.083207  0.911576\n",
       "1  ISIC_0025661  3.843240e-08    0.000205  7.986385e-08  0.000002  0.999793"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- If we have a lesion_id with associated image_ids, we can also construct a small dataframe.\n",
      "- The df_from_ids function also takes arguments for the number of predictions we want to make for a given image/lesion.\n",
      "- Here is the result of passing 'lesion_ids='HAM_0000118'', 'multiplicity=3', and 'one_img_per_lesion=False' to df_from_ids:\n",
      "- However, here we have filtered all columns except for lesion_id and image_id (knowing the diagnosis defeats the purpose).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id\n",
       "0  HAM_0000118  ISIC_0027419\n",
       "1  HAM_0000118  ISIC_0027419\n",
       "2  HAM_0000118  ISIC_0025030"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Here are the associated probabilities:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>0.055993</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.472147</td>\n",
       "      <td>0.466352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.026197</td>\n",
       "      <td>0.003501</td>\n",
       "      <td>0.696560</td>\n",
       "      <td>0.270767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.008122</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.004272</td>\n",
       "      <td>0.987568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id  prob_other  prob_akiec   prob_nv  prob_mel  \\\n",
       "0  HAM_0000118  ISIC_0027419    0.003104    0.055993  0.002405  0.472147   \n",
       "1  HAM_0000118  ISIC_0027419    0.002975    0.026197  0.003501  0.696560   \n",
       "2  HAM_0000118  ISIC_0025030    0.000016    0.008122  0.000022  0.004272   \n",
       "\n",
       "   prob_bcc  \n",
       "0  0.466352  \n",
       "1  0.270767  \n",
       "2  0.987568  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Notice that the probabilities may vary with each execution of a prediction.\n",
      "- This is because a random transformation may be applied to each image before our model makes a prediction on it.\n"
     ]
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import df_from_ids, get_probabilities     \n",
    "\n",
    "instance = resnet_demo\n",
    "df = instance.df\n",
    "\n",
    "print_header(\"Code test: prediction on individual images or lesions\")\n",
    "\n",
    "to_print = [\"- We can make predictions for individual images or lesions.\",\n",
    "            \"We only require a dataframe with an \\'image_id\\' column.\",\n",
    "            \"Given the filename of an image, the df_from_ids function will construct such a dataframe.\",\n",
    "            \"We can then feed this dataframe into the get_probabilities function.\",\n",
    "            \"Here is the result of passing \\'filenames=[\\'ISIC_0033305\\',\\'ISIC_0025661\\']\\' to df_from_ids:\",\n",
    "            \"- And here are the corresponding probabilities:\",\n",
    "            \"- If we have a lesion_id with associated image_ids, we can also construct a small dataframe.\",\n",
    "            \"The df_from_ids function also takes arguments for the number of predictions we want to make for a given image/lesion.\",\n",
    "            \"- Here is the result of passing \\'lesion_ids=\\'HAM_0000118'\\', \\'multiplicity=3\\', and \\'one_img_per_lesion=False\\' to df_from_ids:\",\n",
    "            \"However, here we have filtered all columns except for lesion_id and image_id (knowing the diagnosis defeats the purpose).\",\n",
    "            \"- Here are the associated probabilities:\",\n",
    "            \"- Notice that the probabilities may vary with each execution of a prediction.\",\n",
    "            \"This is because a random transformation may be applied to each image before our model makes a prediction on it.\"]\n",
    "\n",
    "df_2img = df_from_ids(filenames=['ISIC_0033305','ISIC_0025661'], # can be a string or a list of strings\n",
    "                       multiplicity=None,\n",
    "                       lesion_ids=None,\n",
    "                       df=df,\n",
    "                       one_img_per_lesion=None,)\n",
    "\n",
    "print(\"\\n- \".join(to_print[:5]))\n",
    "\n",
    "display(df_2img)\n",
    "\n",
    "df_2img_prob = get_probabilities(df=df_2img,\n",
    "                  data_dir=instance.data_dir,\n",
    "                  model_dir=instance.model_dir,\n",
    "                  model=instance.model,\n",
    "                  filename=instance._filename,\n",
    "                  label_codes=instance.label_codes,\n",
    "                  transform=instance.transform,\n",
    "                  batch_size=instance.batch_size,\n",
    "                  Print=False,\n",
    "                  save_as=None,)   \n",
    "\n",
    "print(to_print[5])\n",
    "display(df_2img_prob)\n",
    "\n",
    "print(\"\\n- \".join(to_print[6:8]))\n",
    "\n",
    "df_1les = df_from_ids(filenames=None,\n",
    "                       multiplicity=3,\n",
    "                       lesion_ids='HAM_0000118', # can be a string or a list of strings\n",
    "                       df=df,\n",
    "                       one_img_per_lesion=False,)\n",
    "\n",
    "print(\"\\n- \".join(to_print[8:10]))\n",
    "display_columns = ['lesion_id', 'image_id'] \n",
    "display(df_1les[display_columns])\n",
    "\n",
    "df_1les_prob = get_probabilities(df=df_1les,\n",
    "                  data_dir=instance.data_dir,\n",
    "                  model_dir=instance.model_dir,\n",
    "                  model=instance.model,\n",
    "                  filename=instance._filename,\n",
    "                  label_codes=instance.label_codes,\n",
    "                  transform=instance.transform,\n",
    "                  batch_size=instance.batch_size,\n",
    "                  Print=False,\n",
    "                  save_as=None,)   \n",
    "\n",
    "print(to_print[10])\n",
    "display_columns = ['lesion_id', 'image_id'] + [col for col in df_1les_prob if col.startswith('prob')]\n",
    "display(df_1les_prob[display_columns])\n",
    "\n",
    "print(\"\\n- \".join(to_print[11:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f8fcd34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'multiclass_models' from 'D:\\\\projects\\\\skin-lesion-classification\\\\scripts\\\\multiclass_models.py'>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import multiclass_models\n",
    "\n",
    "importlib.reload(multiclass_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "65449f97",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================\n",
      "CODE TEST: PROBABILITIES FOR ALL IMAGES\n",
      "=======================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>0.488154</td>\n",
       "      <td>0.320958</td>\n",
       "      <td>0.112851</td>\n",
       "      <td>0.075228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>0.546590</td>\n",
       "      <td>0.207624</td>\n",
       "      <td>0.160286</td>\n",
       "      <td>0.079096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0006663</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0033482</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.126734</td>\n",
       "      <td>0.534769</td>\n",
       "      <td>0.037566</td>\n",
       "      <td>0.299172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0006663</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0033201</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>0.150670</td>\n",
       "      <td>0.624709</td>\n",
       "      <td>0.059166</td>\n",
       "      <td>0.159651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0003162</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0032997</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.058898</td>\n",
       "      <td>0.161691</td>\n",
       "      <td>0.408894</td>\n",
       "      <td>0.197394</td>\n",
       "      <td>0.173124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>HAM_0000967</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0025539</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.109885</td>\n",
       "      <td>0.118041</td>\n",
       "      <td>0.390637</td>\n",
       "      <td>0.202687</td>\n",
       "      <td>0.178750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>HAM_0005480</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0026149</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>va</td>\n",
       "      <td>0.013788</td>\n",
       "      <td>0.298523</td>\n",
       "      <td>0.205440</td>\n",
       "      <td>0.246306</td>\n",
       "      <td>0.235942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>HAM_0005480</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025992</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.167860</td>\n",
       "      <td>0.157719</td>\n",
       "      <td>0.106153</td>\n",
       "      <td>0.566874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>HAM_0004592</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0030730</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.006594</td>\n",
       "      <td>0.468394</td>\n",
       "      <td>0.284184</td>\n",
       "      <td>0.187424</td>\n",
       "      <td>0.053403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>HAM_0004592</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0029141</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>va</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.174940</td>\n",
       "      <td>0.325974</td>\n",
       "      <td>0.258017</td>\n",
       "      <td>0.240804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lesion_id  num_images      image_id     dx  label dx_type   age  \\\n",
       "0    HAM_0000118           2  ISIC_0027419    bkl      0   histo  80.0   \n",
       "1    HAM_0000118           2  ISIC_0025030    bkl      0   histo  80.0   \n",
       "2    HAM_0006663           2  ISIC_0033482    bkl      0   histo  85.0   \n",
       "3    HAM_0006663           2  ISIC_0033201    bkl      0   histo  85.0   \n",
       "4    HAM_0003162           2  ISIC_0032997    bkl      0   histo  75.0   \n",
       "..           ...         ...           ...    ...    ...     ...   ...   \n",
       "139  HAM_0000967           1  ISIC_0025539  akiec      4   histo  75.0   \n",
       "140  HAM_0005480           2  ISIC_0026149  akiec      4   histo  65.0   \n",
       "141  HAM_0005480           2  ISIC_0025992  akiec      4   histo  65.0   \n",
       "142  HAM_0004592           2  ISIC_0030730  akiec      4   histo  60.0   \n",
       "143  HAM_0004592           2  ISIC_0029141  akiec      4   histo  60.0   \n",
       "\n",
       "        sex     localization set  prob_other  prob_mel  prob_bcc   prob_nv  \\\n",
       "0      male            scalp  ta    0.002810  0.488154  0.320958  0.112851   \n",
       "1      male            scalp  t1    0.006403  0.546590  0.207624  0.160286   \n",
       "2    female  lower extremity  t1    0.001759  0.126734  0.534769  0.037566   \n",
       "3    female  lower extremity  ta    0.005804  0.150670  0.624709  0.059166   \n",
       "4      male             back  t1    0.058898  0.161691  0.408894  0.197394   \n",
       "..      ...              ...  ..         ...       ...       ...       ...   \n",
       "139    male  lower extremity  v1    0.109885  0.118041  0.390637  0.202687   \n",
       "140    male             face  va    0.013788  0.298523  0.205440  0.246306   \n",
       "141    male             face  v1    0.001394  0.167860  0.157719  0.106153   \n",
       "142  female             face  v1    0.006594  0.468394  0.284184  0.187424   \n",
       "143  female             face  va    0.000264  0.174940  0.325974  0.258017   \n",
       "\n",
       "     prob_akiec  \n",
       "0      0.075228  \n",
       "1      0.079096  \n",
       "2      0.299172  \n",
       "3      0.159651  \n",
       "4      0.173124  \n",
       "..          ...  \n",
       "139    0.178750  \n",
       "140    0.235942  \n",
       "141    0.566874  \n",
       "142    0.053403  \n",
       "143    0.240804  \n",
       "\n",
       "[144 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "CODE TEST: PROBABILITIES AND PREDICTIONS FOR ALL IMAGES\n",
      "=======================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>0.488154</td>\n",
       "      <td>0.320958</td>\n",
       "      <td>0.112851</td>\n",
       "      <td>0.075228</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>0.546590</td>\n",
       "      <td>0.207624</td>\n",
       "      <td>0.160286</td>\n",
       "      <td>0.079096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0006663</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0033482</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.126734</td>\n",
       "      <td>0.534769</td>\n",
       "      <td>0.037566</td>\n",
       "      <td>0.299172</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0006663</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0033201</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>0.150670</td>\n",
       "      <td>0.624709</td>\n",
       "      <td>0.059166</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0003162</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0032997</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.058898</td>\n",
       "      <td>0.161691</td>\n",
       "      <td>0.408894</td>\n",
       "      <td>0.197394</td>\n",
       "      <td>0.173124</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>HAM_0000967</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0025539</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.109885</td>\n",
       "      <td>0.118041</td>\n",
       "      <td>0.390637</td>\n",
       "      <td>0.202687</td>\n",
       "      <td>0.178750</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>HAM_0005480</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0026149</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>va</td>\n",
       "      <td>0.013788</td>\n",
       "      <td>0.298523</td>\n",
       "      <td>0.205440</td>\n",
       "      <td>0.246306</td>\n",
       "      <td>0.235942</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>HAM_0005480</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025992</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.167860</td>\n",
       "      <td>0.157719</td>\n",
       "      <td>0.106153</td>\n",
       "      <td>0.566874</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>HAM_0004592</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0030730</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.006594</td>\n",
       "      <td>0.468394</td>\n",
       "      <td>0.284184</td>\n",
       "      <td>0.187424</td>\n",
       "      <td>0.053403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>HAM_0004592</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0029141</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>va</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.174940</td>\n",
       "      <td>0.325974</td>\n",
       "      <td>0.258017</td>\n",
       "      <td>0.240804</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lesion_id  num_images      image_id     dx  label dx_type   age  \\\n",
       "0    HAM_0000118           2  ISIC_0027419    bkl      0   histo  80.0   \n",
       "1    HAM_0000118           2  ISIC_0025030    bkl      0   histo  80.0   \n",
       "2    HAM_0006663           2  ISIC_0033482    bkl      0   histo  85.0   \n",
       "3    HAM_0006663           2  ISIC_0033201    bkl      0   histo  85.0   \n",
       "4    HAM_0003162           2  ISIC_0032997    bkl      0   histo  75.0   \n",
       "..           ...         ...           ...    ...    ...     ...   ...   \n",
       "139  HAM_0000967           1  ISIC_0025539  akiec      4   histo  75.0   \n",
       "140  HAM_0005480           2  ISIC_0026149  akiec      4   histo  65.0   \n",
       "141  HAM_0005480           2  ISIC_0025992  akiec      4   histo  65.0   \n",
       "142  HAM_0004592           2  ISIC_0030730  akiec      4   histo  60.0   \n",
       "143  HAM_0004592           2  ISIC_0029141  akiec      4   histo  60.0   \n",
       "\n",
       "        sex     localization set  prob_other  prob_mel  prob_bcc   prob_nv  \\\n",
       "0      male            scalp  ta    0.002810  0.488154  0.320958  0.112851   \n",
       "1      male            scalp  t1    0.006403  0.546590  0.207624  0.160286   \n",
       "2    female  lower extremity  t1    0.001759  0.126734  0.534769  0.037566   \n",
       "3    female  lower extremity  ta    0.005804  0.150670  0.624709  0.059166   \n",
       "4      male             back  t1    0.058898  0.161691  0.408894  0.197394   \n",
       "..      ...              ...  ..         ...       ...       ...       ...   \n",
       "139    male  lower extremity  v1    0.109885  0.118041  0.390637  0.202687   \n",
       "140    male             face  va    0.013788  0.298523  0.205440  0.246306   \n",
       "141    male             face  v1    0.001394  0.167860  0.157719  0.106153   \n",
       "142  female             face  v1    0.006594  0.468394  0.284184  0.187424   \n",
       "143  female             face  va    0.000264  0.174940  0.325974  0.258017   \n",
       "\n",
       "     prob_akiec  pred  \n",
       "0      0.075228     1  \n",
       "1      0.079096     1  \n",
       "2      0.299172     2  \n",
       "3      0.159651     2  \n",
       "4      0.173124     2  \n",
       "..          ...   ...  \n",
       "139    0.178750     2  \n",
       "140    0.235942     1  \n",
       "141    0.566874     4  \n",
       "142    0.053403     1  \n",
       "143    0.240804     2  \n",
       "\n",
       "[144 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================================================\n",
      "CODE TEST: PROBABILITIES AND PREDICTIONS FOR IMAGES IN VALIDATION SET\n",
      "=====================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>HAM_0006801</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0032570</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.046393</td>\n",
       "      <td>0.083066</td>\n",
       "      <td>0.102322</td>\n",
       "      <td>0.734325</td>\n",
       "      <td>0.033894</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>HAM_0002335</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031812</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.043069</td>\n",
       "      <td>0.150440</td>\n",
       "      <td>0.688703</td>\n",
       "      <td>0.109991</td>\n",
       "      <td>0.007796</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>HAM_0006988</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0024943</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>0.116960</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.878939</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>HAM_0005586</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0024415</td>\n",
       "      <td>nv</td>\n",
       "      <td>3</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>45.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.102728</td>\n",
       "      <td>0.366121</td>\n",
       "      <td>0.024346</td>\n",
       "      <td>0.502185</td>\n",
       "      <td>0.004621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>HAM_0001076</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0033627</td>\n",
       "      <td>nv</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.423836</td>\n",
       "      <td>0.146423</td>\n",
       "      <td>0.157589</td>\n",
       "      <td>0.152320</td>\n",
       "      <td>0.119832</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>HAM_0006855</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0030842</td>\n",
       "      <td>nv</td>\n",
       "      <td>3</td>\n",
       "      <td>histo</td>\n",
       "      <td>50.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>0.209552</td>\n",
       "      <td>0.454396</td>\n",
       "      <td>0.091031</td>\n",
       "      <td>0.241185</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>HAM_0004330</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0030555</td>\n",
       "      <td>df</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.435236</td>\n",
       "      <td>0.063799</td>\n",
       "      <td>0.146160</td>\n",
       "      <td>0.350733</td>\n",
       "      <td>0.004073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>HAM_0007418</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0026313</td>\n",
       "      <td>df</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>50.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.014638</td>\n",
       "      <td>0.335821</td>\n",
       "      <td>0.276991</td>\n",
       "      <td>0.305636</td>\n",
       "      <td>0.066914</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>HAM_0006371</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0034135</td>\n",
       "      <td>df</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.018797</td>\n",
       "      <td>0.126853</td>\n",
       "      <td>0.207847</td>\n",
       "      <td>0.636889</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>HAM_0004126</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0030060</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.236065</td>\n",
       "      <td>0.137967</td>\n",
       "      <td>0.447473</td>\n",
       "      <td>0.084833</td>\n",
       "      <td>0.093662</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>HAM_0000042</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0033905</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>45.0</td>\n",
       "      <td>female</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>0.164309</td>\n",
       "      <td>0.332060</td>\n",
       "      <td>0.182941</td>\n",
       "      <td>0.316116</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>HAM_0001113</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0031900</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.091109</td>\n",
       "      <td>0.227575</td>\n",
       "      <td>0.016306</td>\n",
       "      <td>0.664617</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>HAM_0001719</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0031090</td>\n",
       "      <td>vasc</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>female</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.526077</td>\n",
       "      <td>0.095319</td>\n",
       "      <td>0.188934</td>\n",
       "      <td>0.155346</td>\n",
       "      <td>0.034324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>HAM_0004877</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027159</td>\n",
       "      <td>vasc</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.869906</td>\n",
       "      <td>0.031418</td>\n",
       "      <td>0.053604</td>\n",
       "      <td>0.031890</td>\n",
       "      <td>0.013182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>HAM_0005245</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0024375</td>\n",
       "      <td>vasc</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.137608</td>\n",
       "      <td>0.200343</td>\n",
       "      <td>0.217249</td>\n",
       "      <td>0.430879</td>\n",
       "      <td>0.013921</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>HAM_0000393</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027865</td>\n",
       "      <td>bcc</td>\n",
       "      <td>2</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.002556</td>\n",
       "      <td>0.256503</td>\n",
       "      <td>0.485825</td>\n",
       "      <td>0.231674</td>\n",
       "      <td>0.023442</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>HAM_0003851</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0031643</td>\n",
       "      <td>bcc</td>\n",
       "      <td>2</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.077194</td>\n",
       "      <td>0.844768</td>\n",
       "      <td>0.052705</td>\n",
       "      <td>0.024447</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>HAM_0004940</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0026970</td>\n",
       "      <td>bcc</td>\n",
       "      <td>2</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.026466</td>\n",
       "      <td>0.239001</td>\n",
       "      <td>0.300750</td>\n",
       "      <td>0.414656</td>\n",
       "      <td>0.019127</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>HAM_0000967</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0025539</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.109885</td>\n",
       "      <td>0.118041</td>\n",
       "      <td>0.390637</td>\n",
       "      <td>0.202687</td>\n",
       "      <td>0.178750</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>HAM_0005480</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025992</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.167860</td>\n",
       "      <td>0.157719</td>\n",
       "      <td>0.106153</td>\n",
       "      <td>0.566874</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>HAM_0004592</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0030730</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.006594</td>\n",
       "      <td>0.468394</td>\n",
       "      <td>0.284184</td>\n",
       "      <td>0.187424</td>\n",
       "      <td>0.053403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lesion_id  num_images      image_id     dx  label    dx_type   age  \\\n",
       "109  HAM_0006801           3  ISIC_0032570    bkl      0      histo  60.0   \n",
       "110  HAM_0002335           2  ISIC_0031812    bkl      0      histo  85.0   \n",
       "112  HAM_0006988           1  ISIC_0024943    bkl      0  consensus  75.0   \n",
       "113  HAM_0005586           1  ISIC_0024415     nv      3  follow_up  45.0   \n",
       "115  HAM_0001076           2  ISIC_0033627     nv      3      histo  65.0   \n",
       "116  HAM_0006855           1  ISIC_0030842     nv      3      histo  50.0   \n",
       "118  HAM_0004330           2  ISIC_0030555     df      0      histo  70.0   \n",
       "120  HAM_0007418           2  ISIC_0026313     df      0  consensus  50.0   \n",
       "121  HAM_0006371           3  ISIC_0034135     df      0  consensus  35.0   \n",
       "124  HAM_0004126           2  ISIC_0030060    mel      1      histo  80.0   \n",
       "127  HAM_0000042           3  ISIC_0033905    mel      1      histo  45.0   \n",
       "129  HAM_0001113           1  ISIC_0031900    mel      1      histo  55.0   \n",
       "130  HAM_0001719           1  ISIC_0031090   vasc      0      histo  55.0   \n",
       "131  HAM_0004877           2  ISIC_0027159   vasc      0      histo  85.0   \n",
       "133  HAM_0005245           1  ISIC_0024375   vasc      0  consensus  70.0   \n",
       "135  HAM_0000393           2  ISIC_0027865    bcc      2      histo  40.0   \n",
       "136  HAM_0003851           1  ISIC_0031643    bcc      2      histo  70.0   \n",
       "138  HAM_0004940           2  ISIC_0026970    bcc      2      histo  80.0   \n",
       "139  HAM_0000967           1  ISIC_0025539  akiec      4      histo  75.0   \n",
       "141  HAM_0005480           2  ISIC_0025992  akiec      4      histo  65.0   \n",
       "142  HAM_0004592           2  ISIC_0030730  akiec      4      histo  60.0   \n",
       "\n",
       "        sex     localization set  prob_other  prob_mel  prob_bcc   prob_nv  \\\n",
       "109  female  lower extremity  v1    0.046393  0.083066  0.102322  0.734325   \n",
       "110    male  upper extremity  v1    0.043069  0.150440  0.688703  0.109991   \n",
       "112  female             face  v1    0.000012  0.003398  0.116960  0.000692   \n",
       "113  female             back  v1    0.102728  0.366121  0.024346  0.502185   \n",
       "115    male             back  v1    0.423836  0.146423  0.157589  0.152320   \n",
       "116    male             back  v1    0.003835  0.209552  0.454396  0.091031   \n",
       "118    male  lower extremity  v1    0.435236  0.063799  0.146160  0.350733   \n",
       "120    male  lower extremity  v1    0.014638  0.335821  0.276991  0.305636   \n",
       "121  female  lower extremity  v1    0.018797  0.126853  0.207847  0.636889   \n",
       "124  female             back  v1    0.236065  0.137967  0.447473  0.084833   \n",
       "127  female  upper extremity  v1    0.004573  0.164309  0.332060  0.182941   \n",
       "129    male             back  v1    0.000392  0.091109  0.227575  0.016306   \n",
       "130  female  upper extremity  v1    0.526077  0.095319  0.188934  0.155346   \n",
       "131  female  upper extremity  v1    0.869906  0.031418  0.053604  0.031890   \n",
       "133  female          abdomen  v1    0.137608  0.200343  0.217249  0.430879   \n",
       "135  female          abdomen  v1    0.002556  0.256503  0.485825  0.231674   \n",
       "136    male             back  v1    0.000886  0.077194  0.844768  0.052705   \n",
       "138    male             back  v1    0.026466  0.239001  0.300750  0.414656   \n",
       "139    male  lower extremity  v1    0.109885  0.118041  0.390637  0.202687   \n",
       "141    male             face  v1    0.001394  0.167860  0.157719  0.106153   \n",
       "142  female             face  v1    0.006594  0.468394  0.284184  0.187424   \n",
       "\n",
       "     prob_akiec  pred  \n",
       "109    0.033894     3  \n",
       "110    0.007796     2  \n",
       "112    0.878939     4  \n",
       "113    0.004621     1  \n",
       "115    0.119832     0  \n",
       "116    0.241185     2  \n",
       "118    0.004073     0  \n",
       "120    0.066914     1  \n",
       "121    0.009614     3  \n",
       "124    0.093662     2  \n",
       "127    0.316116     2  \n",
       "129    0.664617     4  \n",
       "130    0.034324     0  \n",
       "131    0.013182     0  \n",
       "133    0.013921     2  \n",
       "135    0.023442     2  \n",
       "136    0.024447     2  \n",
       "138    0.019127     2  \n",
       "139    0.178750     2  \n",
       "141    0.566874     4  \n",
       "142    0.053403     1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================================\n",
      "CODE TEST: PROBABILITIES AND AGGREGATED [...] PREDICTIONS FOR IMAGES IN VALIDATION SET\n",
      "======================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>pred_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>0.488154</td>\n",
       "      <td>0.320958</td>\n",
       "      <td>0.112851</td>\n",
       "      <td>0.075228</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>0.546590</td>\n",
       "      <td>0.207624</td>\n",
       "      <td>0.160286</td>\n",
       "      <td>0.079096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0006663</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0033482</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.126734</td>\n",
       "      <td>0.534769</td>\n",
       "      <td>0.037566</td>\n",
       "      <td>0.299172</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0006663</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0033201</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>0.150670</td>\n",
       "      <td>0.624709</td>\n",
       "      <td>0.059166</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0003162</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0032997</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.058898</td>\n",
       "      <td>0.161691</td>\n",
       "      <td>0.408894</td>\n",
       "      <td>0.197394</td>\n",
       "      <td>0.173124</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>HAM_0000967</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0025539</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.109885</td>\n",
       "      <td>0.118041</td>\n",
       "      <td>0.390637</td>\n",
       "      <td>0.202687</td>\n",
       "      <td>0.178750</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>HAM_0005480</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0026149</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>va</td>\n",
       "      <td>0.013788</td>\n",
       "      <td>0.298523</td>\n",
       "      <td>0.205440</td>\n",
       "      <td>0.246306</td>\n",
       "      <td>0.235942</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>HAM_0005480</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025992</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.167860</td>\n",
       "      <td>0.157719</td>\n",
       "      <td>0.106153</td>\n",
       "      <td>0.566874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>HAM_0004592</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0030730</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.006594</td>\n",
       "      <td>0.468394</td>\n",
       "      <td>0.284184</td>\n",
       "      <td>0.187424</td>\n",
       "      <td>0.053403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>HAM_0004592</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0029141</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>va</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.174940</td>\n",
       "      <td>0.325974</td>\n",
       "      <td>0.258017</td>\n",
       "      <td>0.240804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lesion_id  num_images      image_id     dx  label dx_type   age  \\\n",
       "0    HAM_0000118           2  ISIC_0027419    bkl      0   histo  80.0   \n",
       "1    HAM_0000118           2  ISIC_0025030    bkl      0   histo  80.0   \n",
       "2    HAM_0006663           2  ISIC_0033482    bkl      0   histo  85.0   \n",
       "3    HAM_0006663           2  ISIC_0033201    bkl      0   histo  85.0   \n",
       "4    HAM_0003162           2  ISIC_0032997    bkl      0   histo  75.0   \n",
       "..           ...         ...           ...    ...    ...     ...   ...   \n",
       "139  HAM_0000967           1  ISIC_0025539  akiec      4   histo  75.0   \n",
       "140  HAM_0005480           2  ISIC_0026149  akiec      4   histo  65.0   \n",
       "141  HAM_0005480           2  ISIC_0025992  akiec      4   histo  65.0   \n",
       "142  HAM_0004592           2  ISIC_0030730  akiec      4   histo  60.0   \n",
       "143  HAM_0004592           2  ISIC_0029141  akiec      4   histo  60.0   \n",
       "\n",
       "        sex     localization set  prob_other  prob_mel  prob_bcc   prob_nv  \\\n",
       "0      male            scalp  ta    0.002810  0.488154  0.320958  0.112851   \n",
       "1      male            scalp  t1    0.006403  0.546590  0.207624  0.160286   \n",
       "2    female  lower extremity  t1    0.001759  0.126734  0.534769  0.037566   \n",
       "3    female  lower extremity  ta    0.005804  0.150670  0.624709  0.059166   \n",
       "4      male             back  t1    0.058898  0.161691  0.408894  0.197394   \n",
       "..      ...              ...  ..         ...       ...       ...       ...   \n",
       "139    male  lower extremity  v1    0.109885  0.118041  0.390637  0.202687   \n",
       "140    male             face  va    0.013788  0.298523  0.205440  0.246306   \n",
       "141    male             face  v1    0.001394  0.167860  0.157719  0.106153   \n",
       "142  female             face  v1    0.006594  0.468394  0.284184  0.187424   \n",
       "143  female             face  va    0.000264  0.174940  0.325974  0.258017   \n",
       "\n",
       "     prob_akiec  pred_mode  \n",
       "0      0.075228          1  \n",
       "1      0.079096          1  \n",
       "2      0.299172          2  \n",
       "3      0.159651          2  \n",
       "4      0.173124          2  \n",
       "..          ...        ...  \n",
       "139    0.178750          2  \n",
       "140    0.235942          1  \n",
       "141    0.566874          1  \n",
       "142    0.053403          1  \n",
       "143    0.240804          1  \n",
       "\n",
       "[144 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from multiclass_models import threshold, get_argmax, append_prediction, df_with_probabilities, mode_with_random, predictions_mode\n",
    "\n",
    "instance = resnet18mc_test\n",
    "\n",
    "# try:\n",
    "#     instance._inference_df = df_with_probabilities(instance)\n",
    "# except:\n",
    "filename = instance._filename + \"_infer.csv\" # or whatever it might be\n",
    "file_path_csv = instance.model_dir.joinpath(filename)\n",
    "file_path_csv\n",
    "instance._inference_df = df_with_probabilities(file_path_csv)\n",
    "\n",
    "print_header(\"Code test: probabilities for all images\".upper())\n",
    "\n",
    "display(instance._inference_df)\n",
    "\n",
    "threshold_dict_help = OrderedDict([('mel',0.4)])\n",
    "threshold_dict_hinder = OrderedDict([('nv',0.6)])\n",
    "\n",
    "inverse_label_codes = {value: key for key, value in instance.label_codes.items()}\n",
    "\n",
    "print_header(\"Code test: probabilities and predictions for all images\".upper())\n",
    "instance._predictions_df = append_prediction(original_df=instance._inference_df, \n",
    "                                             probabilities_df=instance._inference_df, \n",
    "                                             threshold_dict_help=threshold_dict_help,\n",
    "                                             threshold_dict_hinder=threshold_dict_hinder,\n",
    "                                             inverse_label_codes=inverse_label_codes,)\n",
    "\n",
    "display(instance._predictions_df)\n",
    "\n",
    "print_header(\"Code test: probabilities and predictions for images in validation set\".upper())\n",
    "instance._predictions_df_val = instance._predictions_df[instance._predictions_df[\"set\"] == \"v1\"]\n",
    "\n",
    "display(instance._predictions_df_val)\n",
    "\n",
    "print_header(\"Code test: probabilities and aggregated [...] predictions for images in validation set\".upper())\n",
    "display(predictions_mode(instance._predictions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f1e2ca86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>pred_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>0.488154</td>\n",
       "      <td>0.320958</td>\n",
       "      <td>0.112851</td>\n",
       "      <td>0.075228</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>0.546590</td>\n",
       "      <td>0.207624</td>\n",
       "      <td>0.160286</td>\n",
       "      <td>0.079096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0006663</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0033482</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.126734</td>\n",
       "      <td>0.534769</td>\n",
       "      <td>0.037566</td>\n",
       "      <td>0.299172</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0006663</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0033201</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>0.150670</td>\n",
       "      <td>0.624709</td>\n",
       "      <td>0.059166</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0003162</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0032997</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.058898</td>\n",
       "      <td>0.161691</td>\n",
       "      <td>0.408894</td>\n",
       "      <td>0.197394</td>\n",
       "      <td>0.173124</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>HAM_0000967</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0025539</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.109885</td>\n",
       "      <td>0.118041</td>\n",
       "      <td>0.390637</td>\n",
       "      <td>0.202687</td>\n",
       "      <td>0.178750</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>HAM_0005480</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0026149</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>va</td>\n",
       "      <td>0.013788</td>\n",
       "      <td>0.298523</td>\n",
       "      <td>0.205440</td>\n",
       "      <td>0.246306</td>\n",
       "      <td>0.235942</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>HAM_0005480</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025992</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.167860</td>\n",
       "      <td>0.157719</td>\n",
       "      <td>0.106153</td>\n",
       "      <td>0.566874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>HAM_0004592</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0030730</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.006594</td>\n",
       "      <td>0.468394</td>\n",
       "      <td>0.284184</td>\n",
       "      <td>0.187424</td>\n",
       "      <td>0.053403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>HAM_0004592</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0029141</td>\n",
       "      <td>akiec</td>\n",
       "      <td>4</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>va</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.174940</td>\n",
       "      <td>0.325974</td>\n",
       "      <td>0.258017</td>\n",
       "      <td>0.240804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lesion_id  num_images      image_id     dx  label dx_type   age  \\\n",
       "0    HAM_0000118           2  ISIC_0027419    bkl      0   histo  80.0   \n",
       "1    HAM_0000118           2  ISIC_0025030    bkl      0   histo  80.0   \n",
       "2    HAM_0006663           2  ISIC_0033482    bkl      0   histo  85.0   \n",
       "3    HAM_0006663           2  ISIC_0033201    bkl      0   histo  85.0   \n",
       "4    HAM_0003162           2  ISIC_0032997    bkl      0   histo  75.0   \n",
       "..           ...         ...           ...    ...    ...     ...   ...   \n",
       "139  HAM_0000967           1  ISIC_0025539  akiec      4   histo  75.0   \n",
       "140  HAM_0005480           2  ISIC_0026149  akiec      4   histo  65.0   \n",
       "141  HAM_0005480           2  ISIC_0025992  akiec      4   histo  65.0   \n",
       "142  HAM_0004592           2  ISIC_0030730  akiec      4   histo  60.0   \n",
       "143  HAM_0004592           2  ISIC_0029141  akiec      4   histo  60.0   \n",
       "\n",
       "        sex     localization set  prob_other  prob_mel  prob_bcc   prob_nv  \\\n",
       "0      male            scalp  ta    0.002810  0.488154  0.320958  0.112851   \n",
       "1      male            scalp  t1    0.006403  0.546590  0.207624  0.160286   \n",
       "2    female  lower extremity  t1    0.001759  0.126734  0.534769  0.037566   \n",
       "3    female  lower extremity  ta    0.005804  0.150670  0.624709  0.059166   \n",
       "4      male             back  t1    0.058898  0.161691  0.408894  0.197394   \n",
       "..      ...              ...  ..         ...       ...       ...       ...   \n",
       "139    male  lower extremity  v1    0.109885  0.118041  0.390637  0.202687   \n",
       "140    male             face  va    0.013788  0.298523  0.205440  0.246306   \n",
       "141    male             face  v1    0.001394  0.167860  0.157719  0.106153   \n",
       "142  female             face  v1    0.006594  0.468394  0.284184  0.187424   \n",
       "143  female             face  va    0.000264  0.174940  0.325974  0.258017   \n",
       "\n",
       "     prob_akiec  pred_mode  \n",
       "0      0.075228          1  \n",
       "1      0.079096          1  \n",
       "2      0.299172          2  \n",
       "3      0.159651          2  \n",
       "4      0.173124          2  \n",
       "..          ...        ...  \n",
       "139    0.178750          2  \n",
       "140    0.235942          1  \n",
       "141    0.566874          1  \n",
       "142    0.053403          1  \n",
       "143    0.240804          1  \n",
       "\n",
       "[144 rows x 16 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_mode(instance._predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3b8844a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================\n",
      "CODE TEST: CONFUSION MATRIX (VALIDATION SET)\n",
      "============================================\n",
      "\n",
      "- The overall evaluation metric would appear at the bottom right, if it were defined (this code test set is too small).\n",
      "- It would be a class-wise weighted average fbeta score, beta and weights as specified (default values 1).\n",
      "- One could also pass None, a float, or a function other than weighted_average_f to the func parameter in confusion_matrix_with_metric.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>nv</th>\n",
       "      <th>akiec</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted other  mel       bcc   nv     akiec All    recall\n",
       "actual                                                     \n",
       "other         3    1         2    2         1   9  0.333333\n",
       "mel           0    0         2    0         1   3       0.0\n",
       "bcc           0    0         3    0         0   3       1.0\n",
       "nv            1    1         1    0         0   3       0.0\n",
       "akiec         0    1         1    0         1   3  0.333333\n",
       "All           4    3         9    2         3  21         _\n",
       "precision  0.75  0.0  0.333333  0.0  0.333333   _         _"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from evaluation import weighted_average_f, confusion_matrix_with_metric\n",
    "\n",
    "instance = resnet18mc_test\n",
    "map_labels = instance.label_codes\n",
    "\n",
    "A = instance._predictions_df_val['label']\n",
    "B = instance._predictions_df_val['pred']\n",
    "AxB = pd.crosstab(A,B,margins=True,dropna=False)\n",
    "\n",
    "beta = 1\n",
    "weights = None\n",
    "\n",
    "instance._cm = confusion_matrix_with_metric(AxB=AxB,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "print_header(\"Code test: confusion matrix (validation set)\")\n",
    "\n",
    "to_print = [\"- The overall evaluation metric would appear at the bottom right, if it were defined (this code test set is too small).\",\n",
    "            \"It would be a class-wise weighted average fbeta score, beta and weights as specified (default values 1).\",\n",
    "            \"One could also pass None, a float, or a function other than weighted_average_f to the func parameter in confusion_matrix_with_metric.\"]\n",
    "print(\"\\n- \".join(to_print))\n",
    "display(instance._cm.fillna('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b0a5ae88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "CODE TEST: OTHER METRICS\n",
      "========================\n",
      "\n",
      "- ACC: accuracy\n",
      "- BACC: balanced accuracy\n",
      "- precision: macro-averaged precision (equal weight to each class)\n",
      "- recal: macro-averaged recall (equal weight to each class)\n",
      "- Fbeta: macro-averaged F_beta score (equal weight to each class)\n",
      "- MCC: Matthews correlation coefficient\n",
      "- ROC-AUC mac: macro-averaged ROC-AUC (equal weight to each class)\n",
      "- ROC-AUC wt: weighted-average ROC-AUC (larger class -> more weight)\n",
      "- ROC-AUC wt*: weighted-average ROC-AUC (larger class -> *less weight)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.350072</td>\n",
       "      <td>0.346472</td>\n",
       "      <td>0.350072</td>\n",
       "      <td>0.283516</td>\n",
       "      <td>0.271494</td>\n",
       "      <td>0.298296</td>\n",
       "      <td>0.158465</td>\n",
       "      <td>0.722044</td>\n",
       "      <td>0.72177</td>\n",
       "      <td>0.726919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC      BACC  precision    recall      F1/2        F1        F2  \\\n",
       "0  0.277778  0.350072   0.346472  0.350072  0.283516  0.271494  0.298296   \n",
       "\n",
       "        MCC  ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0  0.158465     0.722044     0.72177     0.726919  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from evaluation import metric_dictionary\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "instance = resnet18mc_test\n",
    "\n",
    "target = instance._predictions_df['label'] \n",
    "prediction = instance._predictions_df['pred'] \n",
    "probabilities = instance._predictions_df.filter(regex=r'^prob_')\n",
    "\n",
    "# target = pd.concat([target_, pd.Series([1,2])])\n",
    "# target = target.reset_index(drop=True)\n",
    "# prediction = pd.concat([prediction_, pd.Series([0,2])]) \n",
    "# prediction = prediction.reset_index(drop=True)\n",
    "# probabilities = probabilities_.copy()\n",
    "# probabilities.loc[16] = 0.2\n",
    "# probabilities.loc[17] = 0.2\n",
    "# probabilities = probabilities.values\n",
    "\n",
    "print_header(\"Code test: other metrics\")\n",
    "to_print = [\"- ACC: accuracy\",\n",
    "            \"BACC: balanced accuracy\",\n",
    "            \"precision: macro-averaged precision (equal weight to each class)\",\n",
    "            \"recal: macro-averaged recall (equal weight to each class)\",\n",
    "            \"Fbeta: macro-averaged F_beta score (equal weight to each class)\",\n",
    "            \"MCC: Matthews correlation coefficient\",\n",
    "            \"ROC-AUC mac: macro-averaged ROC-AUC (equal weight to each class)\",\n",
    "            \"ROC-AUC wt: weighted-average ROC-AUC (larger class -> more weight)\",\n",
    "            \"ROC-AUC wt*: weighted-average ROC-AUC (larger class -> *less weight)\",            \n",
    "            ]\n",
    "\n",
    "instance._metric_dict = metric_dictionary(target=target, \n",
    "                                          prediction=prediction, \n",
    "                                          probabilities=probabilities)\n",
    "print(\"\\n- \".join(to_print))\n",
    "display(pd.DataFrame(instance._metric_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104706f1",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "343159ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    \n",
    "transforms.RandomCrop((300, 300)),\n",
    "transforms.Resize((224,224)), # Resize images to fit ResNet input size\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet stats\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98981d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from typing import List, Callable\n",
    "\n",
    "df: pd.DataFrame = metadata.df                   # Background dataset for the model. metadata._df_sample_batch is a random selection of 64 rows of metadata.df. We use it for testing our code.\n",
    "train_set: Union[pd.DataFrame, list, str] = \"t1\" # \"t1\" (one image per lesion in training set); [\"t1\", \"ta\"] (all images for each lesion in training set); can also specify another sub-dataframe of self.df.\n",
    "val_set: Union[pd.DataFrame, list, str] = \"v1\"   # Similar to train_set above.\n",
    "label_codes: dict = metadata._label_codes        # Correspondence between label codes like 0 and label words like 'other'.\n",
    "data_dir: Path = path[\"images\"]                  # Path to directory where images are stored.\n",
    "model_dir: Path = path[\"models\"]                 # Path to directory where models/model info/model results are stored.\n",
    "transform: List[Callable] = transform            # Transform to be applied to images before feeding to ResNet-18\n",
    "batch_size: int = 32                             # Mini-batch size: default 32.\n",
    "epochs: int = 10                                 # Number of epochs (all layers unfrozen from the start): default 10.\n",
    "base_learning_rate: float = 0.001                # Learning rate to start with: default 0.001. Using Adam optimizer.\n",
    "filename_stem: str = \"rn18mc\"                    # For saving model and related files. train set and num epochs will be appended automatically. Default \"rn18mc\".\n",
    "filename_suffix: str = \"base\"                    # Something descriptive and unique for future reference and to avoid over-writing other files. Default empty string \"\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f407e3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18mc_base = resnet18(                                  \n",
    "    df=df, \n",
    "    train_set=train_set,\n",
    "    val_set=val_set,\n",
    "    label_codes=label_codes,\n",
    "    data_dir=data_dir,\n",
    "    model_dir=model_dir,\n",
    "    transform=transform,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,                                                \n",
    "    base_learning_rate=base_learning_rate,\n",
    "    filename_stem=filename_stem,\n",
    "    filename_suffix=filename_suffix,                                  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd97d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only need to do this once...\n",
    "# resnet18mc_base.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "913c5953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'evaluation' from 'D:\\\\projects\\\\skin-lesion-classification\\\\scripts\\\\evaluation.py'>"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "del instance._inference_df\n",
    "import evaluation\n",
    "\n",
    "importlib.reload(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "ca805556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================\n",
      "BASELINE MODEL: PROBABILITIES FOR ALL IMAGES\n",
      "============================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.190499</td>\n",
       "      <td>0.589043</td>\n",
       "      <td>0.070307</td>\n",
       "      <td>0.127727</td>\n",
       "      <td>0.022423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.325244</td>\n",
       "      <td>0.116826</td>\n",
       "      <td>0.034226</td>\n",
       "      <td>0.438181</td>\n",
       "      <td>0.085523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>va</td>\n",
       "      <td>0.025946</td>\n",
       "      <td>0.010540</td>\n",
       "      <td>0.299041</td>\n",
       "      <td>0.045798</td>\n",
       "      <td>0.618675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.039586</td>\n",
       "      <td>0.041373</td>\n",
       "      <td>0.251411</td>\n",
       "      <td>0.027629</td>\n",
       "      <td>0.640001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>va</td>\n",
       "      <td>0.110923</td>\n",
       "      <td>0.402103</td>\n",
       "      <td>0.215037</td>\n",
       "      <td>0.059775</td>\n",
       "      <td>0.212162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  num_images      image_id   dx  label dx_type   age   sex  \\\n",
       "0  HAM_0000118           2  ISIC_0027419  bkl      0   histo  80.0  male   \n",
       "1  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "2  HAM_0002730           2  ISIC_0026769  bkl      0   histo  80.0  male   \n",
       "3  HAM_0002730           2  ISIC_0025661  bkl      0   histo  80.0  male   \n",
       "4  HAM_0001466           2  ISIC_0031633  bkl      0   histo  75.0  male   \n",
       "\n",
       "  localization set  prob_other  prob_mel  prob_akiec   prob_nv  prob_bcc  \n",
       "0        scalp  ta    0.190499  0.589043    0.070307  0.127727  0.022423  \n",
       "1        scalp  t1    0.325244  0.116826    0.034226  0.438181  0.085523  \n",
       "2        scalp  va    0.025946  0.010540    0.299041  0.045798  0.618675  \n",
       "3        scalp  v1    0.039586  0.041373    0.251411  0.027629  0.640001  \n",
       "4          ear  va    0.110923  0.402103    0.215037  0.059775  0.212162  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BASELINE MODEL: PROBABILITIES AND PREDICTIONS FOR ALL IMAGES\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.190499</td>\n",
       "      <td>0.589043</td>\n",
       "      <td>0.070307</td>\n",
       "      <td>0.127727</td>\n",
       "      <td>0.022423</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.325244</td>\n",
       "      <td>0.116826</td>\n",
       "      <td>0.034226</td>\n",
       "      <td>0.438181</td>\n",
       "      <td>0.085523</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>va</td>\n",
       "      <td>0.025946</td>\n",
       "      <td>0.010540</td>\n",
       "      <td>0.299041</td>\n",
       "      <td>0.045798</td>\n",
       "      <td>0.618675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.039586</td>\n",
       "      <td>0.041373</td>\n",
       "      <td>0.251411</td>\n",
       "      <td>0.027629</td>\n",
       "      <td>0.640001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>va</td>\n",
       "      <td>0.110923</td>\n",
       "      <td>0.402103</td>\n",
       "      <td>0.215037</td>\n",
       "      <td>0.059775</td>\n",
       "      <td>0.212162</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  num_images      image_id   dx  label dx_type   age   sex  \\\n",
       "0  HAM_0000118           2  ISIC_0027419  bkl      0   histo  80.0  male   \n",
       "1  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "2  HAM_0002730           2  ISIC_0026769  bkl      0   histo  80.0  male   \n",
       "3  HAM_0002730           2  ISIC_0025661  bkl      0   histo  80.0  male   \n",
       "4  HAM_0001466           2  ISIC_0031633  bkl      0   histo  75.0  male   \n",
       "\n",
       "  localization set  prob_other  prob_mel  prob_akiec   prob_nv  prob_bcc  pred  \n",
       "0        scalp  ta    0.190499  0.589043    0.070307  0.127727  0.022423     2  \n",
       "1        scalp  t1    0.325244  0.116826    0.034226  0.438181  0.085523     4  \n",
       "2        scalp  va    0.025946  0.010540    0.299041  0.045798  0.618675     1  \n",
       "3        scalp  v1    0.039586  0.041373    0.251411  0.027629  0.640001     1  \n",
       "4          ear  va    0.110923  0.402103    0.215037  0.059775  0.212162     2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================\n",
      "BASELINE MODEL: PROBABILITIES AND PREDICTIONS FOR IMAGES IN VALIDATION SET\n",
      "==========================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.039586</td>\n",
       "      <td>0.041373</td>\n",
       "      <td>0.251411</td>\n",
       "      <td>0.027629</td>\n",
       "      <td>0.640001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027850</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.118692</td>\n",
       "      <td>0.143967</td>\n",
       "      <td>0.113587</td>\n",
       "      <td>0.164686</td>\n",
       "      <td>0.459067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HAM_0002761</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0029068</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.041351</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.025426</td>\n",
       "      <td>0.131957</td>\n",
       "      <td>0.798437</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HAM_0004234</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0029396</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.045510</td>\n",
       "      <td>0.151270</td>\n",
       "      <td>0.007371</td>\n",
       "      <td>0.789996</td>\n",
       "      <td>0.005853</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HAM_0001949</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025767</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>trunk</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.712821</td>\n",
       "      <td>0.006769</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.272685</td>\n",
       "      <td>0.006774</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lesion_id  num_images      image_id   dx  label dx_type   age     sex  \\\n",
       "3   HAM_0002730           2  ISIC_0025661  bkl      0   histo  80.0    male   \n",
       "5   HAM_0001466           2  ISIC_0027850  bkl      0   histo  75.0    male   \n",
       "7   HAM_0002761           2  ISIC_0029068  bkl      0   histo  60.0    male   \n",
       "11  HAM_0004234           2  ISIC_0029396  bkl      0   histo  85.0  female   \n",
       "13  HAM_0001949           2  ISIC_0025767  bkl      0   histo  70.0    male   \n",
       "\n",
       "   localization set  prob_other  prob_mel  prob_akiec   prob_nv  prob_bcc  \\\n",
       "3         scalp  v1    0.039586  0.041373    0.251411  0.027629  0.640001   \n",
       "5           ear  v1    0.118692  0.143967    0.113587  0.164686  0.459067   \n",
       "7          face  v1    0.041351  0.002828    0.025426  0.131957  0.798437   \n",
       "11        chest  v1    0.045510  0.151270    0.007371  0.789996  0.005853   \n",
       "13        trunk  v1    0.712821  0.006769    0.000950  0.272685  0.006774   \n",
       "\n",
       "    pred  \n",
       "3      1  \n",
       "5      1  \n",
       "7      1  \n",
       "11     4  \n",
       "13     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from evaluation import get_argmax, append_prediction, get_probabilities_df\n",
    "\n",
    "instance = resnet18mc_base\n",
    "\n",
    "# try:\n",
    "#     instance._inference_df = df_with_probabilities(instance)\n",
    "# except:\n",
    "filename = \"rn18mc_t1_10e_base_inference.csv\" #instance._filename + \"_infer.csv\" # \"rn18mc_t1_10e_base_inference.csv\"\n",
    "file_path_csv = instance.model_dir.joinpath(filename)\n",
    "instance._inference_df = df_with_probabilities(file_path_csv)\n",
    "instance._inference_df = pd.merge(instance.df, instance._inference_df, on='image_id', how='inner')\n",
    "\n",
    "print_header(\"Baseline model: probabilities for all images\".upper())\n",
    "\n",
    "display(instance._inference_df.head())\n",
    "\n",
    "inverse_label_codes = {value: key for key, value in instance.label_codes.items()}\n",
    "\n",
    "print_header(\"Baseline model: probabilities and predictions for all images\".upper())\n",
    "instance._predictions_df = append_prediction(original_df=instance._inference_df, \n",
    "                                        probabilities_df=instance._inference_df, \n",
    "                                        inverse_label_codes=inverse_label_codes,)\n",
    "\n",
    "display(instance._predictions_df.head())\n",
    "\n",
    "print_header(\"Baseline model: probabilities and predictions for images in validation set\".upper())\n",
    "instance._predictions_df_val = instance._predictions_df[instance._predictions_df[\"set\"] == \"v1\"]\n",
    "\n",
    "display(instance._predictions_df_val.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "8cc27bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "BASELINE MODEL: CONFUSION MATRIX (VALIDATION SET)\n",
      "=================================================\n",
      "\n",
      "OVERALL EVALUATION METRIC AT BOTTOM RIGHT: AVERAGE CLASS-WISE F2 SCORE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>bcc</th>\n",
       "      <th>mel</th>\n",
       "      <th>akiec</th>\n",
       "      <th>nv</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>78</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>71</td>\n",
       "      <td>225</td>\n",
       "      <td>0.346667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>82</td>\n",
       "      <td>0.560976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>69</td>\n",
       "      <td>154</td>\n",
       "      <td>0.422078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>0.350877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>1,259</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0.931902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>134</td>\n",
       "      <td>96</td>\n",
       "      <td>164</td>\n",
       "      <td>54</td>\n",
       "      <td>1,421</td>\n",
       "      <td>1,869</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.58209</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.396341</td>\n",
       "      <td>0.37037</td>\n",
       "      <td>0.885996</td>\n",
       "      <td>_</td>\n",
       "      <td>0.52265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted    other       bcc       mel    akiec        nv    All    recall\n",
       "actual                                                                    \n",
       "other           78        19        46       11        71    225  0.346667\n",
       "bcc              5        46         4        9        18     82  0.560976\n",
       "mel              9         2        65        9        69    154  0.422078\n",
       "akiec            7        20         6       20         4     57  0.350877\n",
       "nv              35         9        43        5     1,259  1,351  0.931902\n",
       "All            134        96       164       54     1,421  1,869         _\n",
       "precision  0.58209  0.479167  0.396341  0.37037  0.885996      _   0.52265"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>bcc</th>\n",
       "      <th>mel</th>\n",
       "      <th>akiec</th>\n",
       "      <th>nv</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>612</td>\n",
       "      <td>86</td>\n",
       "      <td>312</td>\n",
       "      <td>53</td>\n",
       "      <td>293</td>\n",
       "      <td>1,356</td>\n",
       "      <td>0.451327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>14</td>\n",
       "      <td>367</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>86</td>\n",
       "      <td>514</td>\n",
       "      <td>0.714008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>587</td>\n",
       "      <td>36</td>\n",
       "      <td>438</td>\n",
       "      <td>1,113</td>\n",
       "      <td>0.527403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>19</td>\n",
       "      <td>70</td>\n",
       "      <td>14</td>\n",
       "      <td>200</td>\n",
       "      <td>24</td>\n",
       "      <td>327</td>\n",
       "      <td>0.611621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>184</td>\n",
       "      <td>54</td>\n",
       "      <td>278</td>\n",
       "      <td>19</td>\n",
       "      <td>6,170</td>\n",
       "      <td>6,705</td>\n",
       "      <td>0.920209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>874</td>\n",
       "      <td>584</td>\n",
       "      <td>1,217</td>\n",
       "      <td>329</td>\n",
       "      <td>7,011</td>\n",
       "      <td>10,015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.700229</td>\n",
       "      <td>0.628425</td>\n",
       "      <td>0.482334</td>\n",
       "      <td>0.607903</td>\n",
       "      <td>0.880046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.644286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted     other       bcc       mel     akiec        nv     All    recall\n",
       "actual                                                                       \n",
       "other           612        86       312        53       293   1,356  0.451327\n",
       "bcc              14       367        26        21        86     514  0.714008\n",
       "mel              45         7       587        36       438   1,113  0.527403\n",
       "akiec            19        70        14       200        24     327  0.611621\n",
       "nv              184        54       278        19     6,170   6,705  0.920209\n",
       "All             874       584     1,217       329     7,011  10,015       NaN\n",
       "precision  0.700229  0.628425  0.482334  0.607903  0.880046     NaN  0.644286"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from evaluation import weighted_average_f, confusion_matrix_with_metric\n",
    "\n",
    "instance = resnet18mc_base\n",
    "map_labels = instance.label_codes\n",
    "\n",
    "A = instance._predictions_df_val['label']\n",
    "B = instance._predictions_df_val['pred']\n",
    "AxB = pd.crosstab(A,B,margins=True,dropna=False)\n",
    "\n",
    "beta = 2\n",
    "\n",
    "instance._cm = confusion_matrix_with_metric(AxB=AxB,\n",
    "                                                lst=None,\n",
    "                                                full_pad=True,\n",
    "                                                func=weighted_average_f,\n",
    "                                                beta=beta,\n",
    "                                                weights=None,\n",
    "                                                percentage=False,\n",
    "                                                map_labels=map_labels)\n",
    "\n",
    "print_header(\"BASELINE MODEL: confusion matrix (validation set)\")\n",
    "\n",
    "print(f\"Overall evaluation metric at bottom right: average class-wise F{beta} score\".upper())\n",
    "display(instance._cm.fillna('_'))\n",
    "\n",
    "C = instance._predictions_df['label']\n",
    "D = instance._predictions_df['pred']\n",
    "CxD = pd.crosstab(C,D,margins=True,dropna=False)\n",
    "\n",
    "confusion_matrix_with_metric(AxB=CxD,\n",
    "                                                lst=None,\n",
    "                                                full_pad=True,\n",
    "                                                func=weighted_average_f,\n",
    "                                                beta=beta,\n",
    "                                                weights=None,\n",
    "                                                percentage=False,\n",
    "                                                map_labels=map_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9043467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
