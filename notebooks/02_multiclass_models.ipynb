{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f32ebf",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c92e86b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path['project'] : D:\\projects\\skin-lesion-classification\n",
      "path['images'] : D:\\projects\\skin-lesion-classification\\images\n",
      "path['models'] : D:\\projects\\skin-lesion-classification\\models\n",
      "path['expository'] : D:\\projects\\skin-lesion-classification\\expository\n",
      "path['literature'] : D:\\projects\\skin-lesion-classification\\literature\n",
      "path['notebooks'] : D:\\projects\\skin-lesion-classification\\notebooks\n",
      "path['presentation'] : D:\\projects\\skin-lesion-classification\\presentation\n",
      "path['scripts'] : D:\\projects\\skin-lesion-classification\\scripts\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# If we're using Google Colab, we set the environment variable to point to the relevant folder in our Google Drive:\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.environ['SKIN_LESION_CLASSIFICATION'] = '/content/drive/MyDrive/Colab Notebooks/skin-lesion-classification'\n",
    "\n",
    "# Otherwise, we use the environment variable on our local system:\n",
    "project_environment_variable = \"SKIN_LESION_CLASSIFICATION\"\n",
    "\n",
    "# Path to the root directory of the project:\n",
    "project_path = Path(os.environ.get(project_environment_variable))\n",
    "\n",
    "# Relative path to /scripts (from where custom modules will be imported):\n",
    "scripts_path = project_path.joinpath(\"scripts\")\n",
    "\n",
    "# Add this path to sys.path so that Python will look there for modules:\n",
    "sys.path.append(str(scripts_path))\n",
    "\n",
    "# Now import path_step from our custom utils module to create a dictionary to all subdirectories in our root directory:\n",
    "from utils import path_setup\n",
    "path = path_setup.subfolders(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef79028",
   "metadata": {},
   "source": [
    "<a id='contents'></a>\n",
    "# Contents\n",
    "\n",
    "* [Pipeline walk-through with explanations and examples](#pipeline_walk-through)\n",
    "    * [Loading and processing metadata](#loading_and)\n",
    "    * [Class distribution](#class_distribution)\n",
    "    * [Train/val split](#trainval_split)\n",
    "    * [Balancing the training set](#balancing)\n",
    "    * [Expanding the validation set](#expanding)\n",
    "    * [Fine-tuning EfficientNet or ResNet18](#fine-tuning)\n",
    "    * [Small sample for testing code](#small_sample)\n",
    "    * [Model architecture and state dictionary](#model_architecture)\n",
    "    * [Inference: getting probabilities](#inference1)\n",
    "    * [Inference: combining probabilities](#inference2)\n",
    "    * [Inference: combining predictions](#inference3)\n",
    "    * [Evaluation](#evaluation)\n",
    "* [Trivial models](#trivial_models)\n",
    "* [Baseline models](#baseline_models)\n",
    "* [Models with balancing](#models_with)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb138682",
   "metadata": {},
   "source": [
    "<a id='pipeline_walk-through'></a>\n",
    "# Pipeline walk-through with explanations and examples\n",
    "↑↑ [Contents](#contents) ↓ [Loading and processing metadata](#loading_and)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16849006",
   "metadata": {},
   "source": [
    "<a id='loading_and'></a>\n",
    "## Loading and processing metadata\n",
    "↑↑ [Contents](#contents) ↑ [Pipeline walk-through with explanations and examples](#pipeline_walk-through) ↓ [Class distribution](#class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1200a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type, Union      # For type hints\n",
    "from processing import process      # Custom module for processing metadata\n",
    "\n",
    "data_dir: Path = path[\"images\"]     # Path to directory containing metadata.csv file\n",
    "csv_filename: str = \"metadata.csv\"  # The filename\n",
    "    \n",
    "restrict_to: Union[dict, None] = None                   # Remove all records *unless* column k lies in list v, for k : v in restrict_to dictionary.    \n",
    "remove_if: Union[dict, None] = None                     # Remove all records if column k lies in list v, for k : v in remove_if dictionary.    \n",
    "drop_row_if_missing_value_in: Union[list, None] = None  # We drop all rows for which there is a missing value in a column from this list.   \n",
    "                                    \n",
    "tvr: int = 3              # Ratio of training set to validation set. See discussion below for explanation.\n",
    "seed: int = 0             # Random seed for parts of the process where randomness is called for.\n",
    "keep_first: bool = False  # If False, then, for each lesion, we choose a random image to assign to our training set. \n",
    "stratified: bool = True   # If True, we stratify classes so that the proportions remain as stable as possible after train/val split. \n",
    "                          # If False, the proportions will be roughly similar.\n",
    "\n",
    "to_classify: Union[list, dict] = [\"mel\",   # These are the lesion types we are interested in classifying. \n",
    "                                  \"bcc\",   # Any missing ones will be grouped together as the 0-label class: no need to write \"other\" here.\n",
    "                                  \"akiec\", # If 'other' is not desired, use restrict_to attribute above\n",
    "                                  \"nv\",]   # Can also be a dictionary, like { 'malignant' : ['mel', 'bcc'], 'benign' : ['nv', 'bkl']}\n",
    "\n",
    "train_one_img_per_lesion: Union[bool, None] = False # If False, we take advantage of the (in some cases) multiple images of a lesion in our dataset\n",
    "val_one_img_per_lesion: Union[bool, None] = False   # If False, we will validate our model by combining multiple predictions for a lesion (for multiple images of it) into a single prediction\n",
    "val_expansion_factor: Union[int, None] = 3          # A random transformation may be applied to an image before making a prediction.\n",
    "                                                    # For a given lesion, we may make multiple predictions (as specified here), and combine them into a single prediction.\n",
    "    \n",
    "sample_size: Union[None, dict] = {\"mel\": 2000,     # Handling class imbalance by upsampling minority classes/downsampling majority classes     \n",
    "                                  \"bcc\": 2000,     # Specify how many images of each lesion diagnosis we want in our training set.\n",
    "                                  \"akiec\": 2000, \n",
    "                                  \"nv\": 2000,\n",
    "                                  \"other\" : 2000,} # Could also leave out \"other\" here, and include e.g. \"df: 2000\" if we wanted to.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbcb4935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded file 'D:\\projects\\skin-lesion-classification\\images\\metadata.csv'.\n",
      "- Inserted 'num_images' column in dataframe, to the right of 'lesion_id' column.\n",
      "- Inserted 'label' column in dataframe, to the right of 'dx' column: \n",
      "  {'bkl': 0, 'df': 0, 'vasc': 0, 'mel': 1, 'akiec': 2, 'nv': 3, 'bcc': 4}\n",
      "- Added 'set' column to dataframe, with values 't1', 'v1', 'ta', and 'va', to the right of 'localization' column.\n",
      "- Basic, overall dataframe (pre-train/test split): self.df\n",
      "- Balancing classes in training set.\n",
      "- Balanced training set (uses as many different images per lesion as possible): self.df_train\n",
      "- Expanding validation set: will combine 3 predictions into one, for each lesion in val set.\n",
      "- Expanded validation set (one image per lesion, repeated 3 times): self.df_val1\n",
      "- Expanded validation set (use up to 3 different images per lesion, if available): self.df_val_a\n",
      "- Small sample dataframes for code testing: self._df_train_code_test, self._df_val1_code_test, self._df_val_a_code_test\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the process class with attribute values as above.\n",
    "demo = process(data_dir=data_dir,\n",
    "               csv_filename=csv_filename,\n",
    "               restrict_to=restrict_to,\n",
    "               remove_if=remove_if,\n",
    "               drop_row_if_missing_value_in=drop_row_if_missing_value_in,\n",
    "               tvr=tvr,\n",
    "               seed=seed,\n",
    "               keep_first=keep_first,\n",
    "               stratified=stratified,\n",
    "               to_classify=to_classify,\n",
    "               train_one_img_per_lesion=train_one_img_per_lesion,\n",
    "               val_expansion_factor=val_expansion_factor,\n",
    "               sample_size=sample_size,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0205ff",
   "metadata": {},
   "source": [
    "<a id='class_distribution'></a>\n",
    "## Class distribution\n",
    "↑↑ [Contents](#contents) ↑ [Loading and processing metadata](#loading_and) ↓ [Train/val split](#trainval_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b841851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "DISTRIBUTION OF LESIONS BY DIAGNOSIS: OVERALL\n",
      "=============================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5403.00</td>\n",
       "      <td>898.00</td>\n",
       "      <td>614.00</td>\n",
       "      <td>327.00</td>\n",
       "      <td>228.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>72.33</td>\n",
       "      <td>12.02</td>\n",
       "      <td>8.22</td>\n",
       "      <td>4.38</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv   other     mel     bcc   akiec\n",
       "freq  5403.00  898.00  614.00  327.00  228.00\n",
       "%       72.33   12.02    8.22    4.38    3.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lesions: 7470.\n",
      "\n",
      "\n",
      "===========================================\n",
      "DISTRIBUTION OF LESIONS BY DIAGNOSIS: TRAIN\n",
      "===========================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4052.00</td>\n",
       "      <td>673.00</td>\n",
       "      <td>460.00</td>\n",
       "      <td>245.00</td>\n",
       "      <td>171.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>72.34</td>\n",
       "      <td>12.02</td>\n",
       "      <td>8.21</td>\n",
       "      <td>4.37</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv   other     mel     bcc   akiec\n",
       "freq  4052.00  673.00  460.00  245.00  171.00\n",
       "%       72.34   12.02    8.21    4.37    3.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lesions: 5601 (74.98% of all lesions).\n",
      "\n",
      "\n",
      "=========================================\n",
      "DISTRIBUTION OF LESIONS BY DIAGNOSIS: VAL\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1351.00</td>\n",
       "      <td>225.00</td>\n",
       "      <td>154.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>57.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>72.28</td>\n",
       "      <td>12.04</td>\n",
       "      <td>8.24</td>\n",
       "      <td>4.39</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv   other     mel    bcc  akiec\n",
       "freq  1351.00  225.00  154.00  82.00  57.00\n",
       "%       72.28   12.04    8.24   4.39   3.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lesions: 1869 (25.02% of all lesions).\n",
      "\n",
      "\n",
      "============================================\n",
      "DISTRIBUTION OF IMAGES BY DIAGNOSIS: OVERALL\n",
      "============================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6705.00</td>\n",
       "      <td>1356.00</td>\n",
       "      <td>1113.00</td>\n",
       "      <td>514.00</td>\n",
       "      <td>327.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>66.95</td>\n",
       "      <td>13.54</td>\n",
       "      <td>11.11</td>\n",
       "      <td>5.13</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv    other      mel     bcc   akiec\n",
       "freq  6705.00  1356.00  1113.00  514.00  327.00\n",
       "%       66.95    13.54    11.11    5.13    3.27"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 10015.\n",
      "\n",
      "\n",
      "==========================================\n",
      "DISTRIBUTION OF IMAGES BY DIAGNOSIS: TRAIN\n",
      "==========================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5007.00</td>\n",
       "      <td>1008.00</td>\n",
       "      <td>831.00</td>\n",
       "      <td>384.00</td>\n",
       "      <td>250.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>66.94</td>\n",
       "      <td>13.48</td>\n",
       "      <td>11.11</td>\n",
       "      <td>5.13</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv    other     mel     bcc   akiec\n",
       "freq  5007.00  1008.00  831.00  384.00  250.00\n",
       "%       66.94    13.48   11.11    5.13    3.34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 7480 (74.69% of all images).\n",
      "\n",
      "\n",
      "========================================\n",
      "DISTRIBUTION OF IMAGES BY DIAGNOSIS: VAL\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1698.00</td>\n",
       "      <td>348.00</td>\n",
       "      <td>282.00</td>\n",
       "      <td>130.00</td>\n",
       "      <td>77.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>66.98</td>\n",
       "      <td>13.73</td>\n",
       "      <td>11.12</td>\n",
       "      <td>5.13</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv   other     mel     bcc  akiec\n",
       "freq  1698.00  348.00  282.00  130.00  77.00\n",
       "%       66.98   13.73   11.12    5.13   3.04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 2535 (25.31% of all images).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for across in [\"lesions\", \"images\"]:\n",
    "    for subset in [\"all\", \"train\", \"val\"]:\n",
    "        process.dx_dist(demo, subset = subset, across = across)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86793889",
   "metadata": {},
   "source": [
    "<a id='trainval_split'></a>\n",
    "## Train/val split\n",
    "↑↑ [Contents](#contents) ↑ [Class distribution](#class_distribution) ↓ [Balancing the training set](#balancing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efbbd9e",
   "metadata": {},
   "source": [
    "<!-- <details>\n",
    "    <summary><b><i>Train test split explanation: click here to expand/collapse</i></b></summary> -->\n",
    "    \n",
    "We partition our dataset based on ```lesion_id```, **not** on ```image_id```: that way, every lesion will be represented in training or in validation, but not both.\n",
    "\n",
    "For each classification task, we will train a model by making use of\n",
    "* **exactly one** image for every lesion in our training set;\n",
    "* **all** images of every lesion in our training set.\n",
    "\n",
    "In both cases, we will vaildate our model by making use of \n",
    "* **exactly one** image for every lesion in our validation set;\n",
    "* **all** images of every lesion in our validation set (at least, _potentially_ all of them). \n",
    "\n",
    "**However**, we will make only one prediction per lesion (```lesion_id```) in our validation set: if there are multiple images of a lesion in the validation set, we will combine the predictions for the multiple images into a single prediction for the lesion.\n",
    "\n",
    "Accordingly, we proceed as follows. We'll explain by example, assuming the dataset is not filtered before splitting (if it is, the number of distinct lesions will be less than $7470$, and the proportions will be different).\n",
    "1. Randomly select (without replacement) a proportion of our $7470$ distinct ```lesion_id```s and label them with ```t``` (train). \n",
    "2. Label the remaining ```lesion_id```s with ```v``` (validate).\n",
    "3. For each ```lesion_id``` labeled with a ```t```:\n",
    "    * Select an ```image_id``` and label it ```t1```.\n",
    "    * Label all (if any) remaining ```image_id```s corresponding to this ```lesion_id``` with ```ta```.\n",
    "4.  For each ```lesion_id``` labeled with a ```v```:\n",
    "    * Select an ```image_id``` and label it ```v1```.\n",
    "    * Label all (if any) remaining ```image_id```s corresponding to this ```lesion_id``` with ```va```.\n",
    "\n",
    "In Step 1, the number of ```lesion_id```s randomly selected to be labeled ```t``` will be such that the ratio of ```t```s to ```v```s is as close as possible to a specified ratio ```tvr``` (we default to $3$, i.e. $\\approx75\\%$ of lesions are represented in training). In Steps 3 and 4, the first substep can be done randomly (our default choice), or we can simply choose the \"first\" image in our table that corresponds to the lesion (see ```keep_first``` attribute of the ```process``` class). \n",
    "\n",
    "The four train/val scenarios we could consider are:\n",
    "* ```t1v1```: train on precisely those images labeled ```t1``` and validate on precisely those labeled ```v1```.\n",
    "* ```t1va```: train on precisely those images labeled ```t1``` and validate on precisely those labeled ```v1``` **or** ```va```.\n",
    "* ```tav1```: train on precisely those images labeled ```t1``` **or** ```ta``` and validate on precisely those labeled ```v1```.\n",
    "* ```tava```: train on precisely those images labeled ```t1``` **or** ```ta``` and validate on precisely those labeled ```v1``` ***or*** ```va```.\n",
    "\n",
    "The mnemonic is ```t``` for training, ```v``` for validation, ```1``` for one-image-per-lesion, and ```a``` for all images.\n",
    "<!-- </details> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5f71744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================\n",
      "FIRST FIVE ROWS OF METADATA TABLE\n",
      "=================================\n",
      "\n",
      "ADDED COLUMNS\n",
      "\n",
      "- 'num_images': number of images of lesion in dataset\n",
      "- 'label': class to which lesion belongs\n",
      "- 'set': train/val assignment\n",
      "- 't*': lesion is in the training set\n",
      "- 'v*': lesion is in the validation set\n",
      "- 't1': we would train on this image if training a model on exactly one, or on all, image(s) per lesion in the training set\n",
      "- If training set is balanced using one image per lesion, this one image would be re-used as many times as necessary.\n",
      "- 'ta': we would train on this image if training a model on all images of each lesion in the training set\n",
      "- If training set is balanced using all images per lesion, images labeled ta would all be used before any image is repeated.\n",
      "- 'v1': we'd use this image if validating a model on exactly one, or on all, image(s) per lesion in the validation set\n",
      "- If a validation expansion factor is given, this one image would be re-used that many times\n",
      "- 'va': we'd use this image if validating on all images of each lesion in the validation set\n",
      "- If a validation expansion factor is given, iamges labeled va would all be used before any image is repeated.\n",
      "- NB: if more than one image is used for any lesion in validation, the predictions will be combined into a single prediction\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  num_images      image_id   dx  label dx_type   age   sex  \\\n",
       "0  HAM_0000118           2  ISIC_0027419  bkl      0   histo  80.0  male   \n",
       "1  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "2  HAM_0002730           2  ISIC_0026769  bkl      0   histo  80.0  male   \n",
       "3  HAM_0002730           2  ISIC_0025661  bkl      0   histo  80.0  male   \n",
       "4  HAM_0001466           2  ISIC_0031633  bkl      0   histo  75.0  male   \n",
       "\n",
       "  localization set  \n",
       "0        scalp  ta  \n",
       "1        scalp  t1  \n",
       "2        scalp  va  \n",
       "3        scalp  v1  \n",
       "4          ear  va  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's have a look at our metadata dataframe, which is now just an attribute of the metadata instance of the process class.\n",
    "from utils import print_header\n",
    "\n",
    "instance = demo\n",
    "df = instance.df\n",
    "\n",
    "print_header(\"First five rows of metadata table\")\n",
    "\n",
    "to_print = [\"Added columns\\n\".upper(), \n",
    "            \"\\'num_images\\': number of images of lesion in dataset\", \n",
    "            \"\\'label\\': class to which lesion belongs\",\n",
    "            \"\\'set\\': train/val assignment\",\n",
    "            \"\\'t*\\': lesion is in the training set\",\n",
    "            \"\\'v*\\': lesion is in the validation set\",\n",
    "            \"\\'t1\\': we would train on this image if training a model on exactly one, or on all, image(s) per lesion in the training set\",\n",
    "            \"If training set is balanced using one image per lesion, this one image would be re-used as many times as necessary.\",\n",
    "            \"\\'ta\\': we would train on this image if training a model on all images of each lesion in the training set\",\n",
    "            \"If training set is balanced using all images per lesion, images labeled ta would all be used before any image is repeated.\",\n",
    "            \"\\'v1': we\\'d use this image if validating a model on exactly one, or on all, image(s) per lesion in the validation set\",\n",
    "            \"If a validation expansion factor is given, this one image would be re-used that many times\",\n",
    "            \"\\'va': we\\'d use this image if validating on all images of each lesion in the validation set\" ,\n",
    "            \"If a validation expansion factor is given, iamges labeled va would all be used before any image is repeated.\",\n",
    "            \"NB: if more than one image is used for any lesion in validation, the predictions will be combined into a single prediction\"\n",
    "           ]\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb0736c",
   "metadata": {},
   "source": [
    "<a id='balancing'></a>\n",
    "## Balancing the training set\n",
    "↑↑ [Contents](#contents) ↑ [Train/val split](#trainval_split) ↓ [Expanding the validation set](#expanding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f4cb43",
   "metadata": {},
   "source": [
    "<!-- <details>\n",
    "    <summary><b><i>Balancing/upsampling explanation: click here to expand/collapse</i></b></summary> -->\n",
    "\n",
    "We explain the balancing procedure by way of example. (This is performed by the ```balance``` method of the ```process``` class in our ```processing``` module.) We assume the dataset has not been filtered, training to validation ratio is $3$, etc. There are $460$ distinct melanoma lesions represented in our training set. As most melanoma are represented by multiple distinct images, there are a total of $831$ distinct images of melanoma lesions in our training set. Suppose we want our training set to contain $2000$ melanoma images: each of the $460$ distinct melanoma lesions will be represented by $2000/460 \\approx 4.35$ images on average. We do not merely sample with replacement.\n",
    "\n",
    "The goal is to (a) have as little variance as possible in the number of times a lesion is represented, and (b) use as many distinct images as possible (taking advantage of the fact that there are multiple _distinct_ images of most melanoma). Thus, we note that $2000 = 4\\times 460 + 160$, so we will use each of the $460$ distinct melanoma lesions four times, and make the remainder up by randomly sample $160$ distinct lesions from the $160$. In other words, exactly $300$ distinct lesions will each be represented by exactly four images, and exactly $160$ distinct lesions will each be represented by exactly five images: $2000 = 300 \\times 4 + 160 \\times 5$. \n",
    "\n",
    "How do we select the four images of each distinct melanoma lesion (plus another one image for $160$ of them)? Consider lesion id ```HAM_0000871``` for example: there are three distinct images of this lesion in our data set. Thus, if ```train_one_img_per_lesion``` is ```False```, we will use all three of them, and then randomly select one more (or two more if this particular lesion were to be one of the $160$ that are represented five times). See below. On the other hand, if ```train_one_img_per_lesion``` is ```True```, we have no choice but to use the one image (label ```t1```) four times.\n",
    "    \n",
    "<!-- </details> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c4a51e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "EG: REPRESENTATIONS OF LESION HAM_0000871 IN BALANCED TRAINING SET\n",
      "==================================================================\n",
      "\n",
      "HAM_0000871 REPRESENTED BY FOUR IMAGES\n",
      "\n",
      "- Three distinct images of this lesion to choose from: ISIC_0025964, ISIC_0030623, and ISIC_0025964\n",
      "- Use ISIC_0025964 once, ISIC_0030623 twice, and ISIC_0025964 once\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0025964</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0030623</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0026506</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>trunk</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0026506</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>trunk</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id  lesion_mult  num_images      image_id  img_mult   dx  \\\n",
       "1773  HAM_0000871            4           3  ISIC_0025964         1  mel   \n",
       "1774  HAM_0000871            4           3  ISIC_0030623         1  mel   \n",
       "3086  HAM_0000871            4           3  ISIC_0026506         2  mel   \n",
       "3087  HAM_0000871            4           3  ISIC_0026506         2  mel   \n",
       "\n",
       "      label dx_type   age     sex localization set  \n",
       "1773      1   histo  40.0  female        chest  ta  \n",
       "1774      1   histo  40.0  female        chest  t1  \n",
       "3086      1   histo  40.0  female        trunk  ta  \n",
       "3087      1   histo  40.0  female        trunk  ta  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "\n",
    "# The specific numbers in this example assume a certain choice for the attributes, including \n",
    "# sample_size: Union[None, dict] = {\"mel\": 2000,         \n",
    "#                                   \"bcc\": 2000, \n",
    "#                                   \"akiec\": 2000, \n",
    "#                                   \"nv\": 2000,\n",
    "#                                   \"other\" : 2000,}\n",
    "\n",
    "instance = demo\n",
    "df = demo.df_train\n",
    "\n",
    "print_header(\"Eg: Representations of lesion HAM_0000871 in balanced training set\")\n",
    "\n",
    "to_print = [\"HAM_0000871 represented by four images\\n\".upper(),\n",
    "            \"Three distinct images of this lesion to choose from: ISIC_0025964, ISIC_0030623, and ISIC_0025964\",\n",
    "            \"Use ISIC_0025964 once, ISIC_0030623 twice, and ISIC_0025964 once\",]\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "display(df[df['lesion_id'] == 'HAM_0000871'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a797a173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================\n",
      "EG: MELANOMA IN BALANCED TRAINING SET\n",
      "=====================================\n",
      "\n",
      "VALUE COUNTS FOR 'LESION_MULT' COLUMN\n",
      "\n",
      "- 300 distinct melanoma lesions each represented by four images: 300*4 = 1200\n",
      "- 160 distinct melanoma lesions each represented by five images: 160*5 = 800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4    1200\n",
       "5     800\n",
       "Name: lesion_mult, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0025964</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0030623</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>HAM_0000040</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0027190</td>\n",
       "      <td>5</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>HAM_0000040</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0027190</td>\n",
       "      <td>5</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>HAM_0000040</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0027190</td>\n",
       "      <td>5</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7778</th>\n",
       "      <td>HAM_0002552</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0032936</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>HAM_0002552</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0033232</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>HAM_0002552</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0033232</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>HAM_0003521</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0032258</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>HAM_0003521</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0032258</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id  lesion_mult  num_images      image_id  img_mult   dx  \\\n",
       "1773  HAM_0000871            4           3  ISIC_0025964         1  mel   \n",
       "1774  HAM_0000871            4           3  ISIC_0030623         1  mel   \n",
       "1775  HAM_0000040            5           1  ISIC_0027190         5  mel   \n",
       "1776  HAM_0000040            5           1  ISIC_0027190         5  mel   \n",
       "1777  HAM_0000040            5           1  ISIC_0027190         5  mel   \n",
       "...           ...          ...         ...           ...       ...  ...   \n",
       "7778  HAM_0002552            5           3  ISIC_0032936         2  mel   \n",
       "7784  HAM_0002552            5           3  ISIC_0033232         2  mel   \n",
       "7785  HAM_0002552            5           3  ISIC_0033232         2  mel   \n",
       "9998  HAM_0003521            5           2  ISIC_0032258         2  mel   \n",
       "9999  HAM_0003521            5           2  ISIC_0032258         2  mel   \n",
       "\n",
       "      label dx_type   age     sex     localization set  \n",
       "1773      1   histo  40.0  female            chest  ta  \n",
       "1774      1   histo  40.0  female            chest  t1  \n",
       "1775      1   histo  80.0    male  upper extremity  t1  \n",
       "1776      1   histo  80.0    male  upper extremity  t1  \n",
       "1777      1   histo  80.0    male  upper extremity  t1  \n",
       "...     ...     ...   ...     ...              ...  ..  \n",
       "7778      1   histo  25.0    male  upper extremity  ta  \n",
       "7784      1   histo  25.0    male  upper extremity  ta  \n",
       "7785      1   histo  25.0    male  upper extremity  ta  \n",
       "9998      1   histo  70.0  female             back  ta  \n",
       "9999      1   histo  70.0  female             back  ta  \n",
       "\n",
       "[2000 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "# The specific numbers given in this example assume a certain choice for the attributes, including \n",
    "# sample_size: Union[None, dict] = {\"mel\": 2000,         \n",
    "#                                   \"bcc\": 2000, \n",
    "#                                   \"akiec\": 2000, \n",
    "#                                   \"nv\": 2000,\n",
    "#                                   \"other\" : 2000,}\n",
    "\n",
    "instance = demo\n",
    "df = demo.df_train\n",
    "df = df[df['set'].isin([\"ta\", \"t1\"]) & (df['dx'] == 'mel')]\n",
    "\n",
    "print_header(\"Eg: Melanoma in balanced training set\")\n",
    "\n",
    "to_print = [\"Value counts for \\'lesion_mult\\' column\\n\".upper(),\n",
    "            \"300 distinct melanoma lesions each represented by four images: 300*4 = 1200\",\n",
    "            \"160 distinct melanoma lesions each represented by five images: 160*5 = 800\",]\n",
    "\n",
    "print(\"\\n- \".join(to_print[:3]))\n",
    "display(df['lesion_mult'].value_counts())\n",
    "\n",
    "print(\"\\n- \".join(to_print[3:]))\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3d5ede",
   "metadata": {},
   "source": [
    "<a id='expanding'></a>\n",
    "## Expanding the validation set\n",
    "↑↑ [Contents](#contents) ↑ [Balancing the training set](#balancing) ↓ [Fine-tuning EfficientNet or ResNet18](#fine-tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5f3b8",
   "metadata": {},
   "source": [
    "As mentioned already, we make one prediction per lesion. However, we may have multiple images of a given lesion at our disposal: we could make a prediction for each of them and combine them somehow into a single prediction for the lesion. Even if there is only one image of a lesion, we could make multiple predictions on it: if a random transformation is applied to an image before our model makes a prediction on it, this would yield a different array of probabilities each time. Again, we could combine the results into a single prediction.\n",
    "\n",
    "This is what the attribute ```val_expansion_factor``` of the ```process``` class is concerned with. Similarly to the way we balance the training set, we can replicate one single image per lesion in the validation set as many times as specified by ```val_expansion_factor```, as in ```self.df_val1```, or we can take advantage of other images of the lesion (if available), as in ```self.val_a```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25bef7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "EG: MELANOMA IN EXPANDED VALIDATION SET (ONLY ONE IMAGE PER LESION USED)\n",
      "========================================================================\n",
      "\n",
      "- Note that 'lesion_mult' is always 3\n",
      "- HAM_0005678 represented by three images\n",
      "- Two distinct images of this lesion: ISIC_0031023 and ISIC_0028086\n",
      "- However, only use ISIC_0031023 (3 times)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>HAM_0006722</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031499</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>HAM_0006722</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031499</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>HAM_0004081</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0031957</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>HAM_0004081</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0031957</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028764</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028764</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028764</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id  lesion_mult  num_images      image_id  img_mult   dx  \\\n",
       "603   HAM_0005678            3           2  ISIC_0031023         3  mel   \n",
       "604   HAM_0005678            3           2  ISIC_0031023         3  mel   \n",
       "605   HAM_0005678            3           2  ISIC_0031023         3  mel   \n",
       "606   HAM_0006722            3           2  ISIC_0031499         3  mel   \n",
       "607   HAM_0006722            3           2  ISIC_0031499         3  mel   \n",
       "...           ...          ...         ...           ...       ...  ...   \n",
       "1060  HAM_0004081            3           1  ISIC_0031957         3  mel   \n",
       "1061  HAM_0004081            3           1  ISIC_0031957         3  mel   \n",
       "1062  HAM_0004746            3           2  ISIC_0028764         3  mel   \n",
       "1063  HAM_0004746            3           2  ISIC_0028764         3  mel   \n",
       "1064  HAM_0004746            3           2  ISIC_0028764         3  mel   \n",
       "\n",
       "      label dx_type   age     sex     localization set  \n",
       "603       1   histo  60.0    male            chest  v1  \n",
       "604       1   histo  60.0    male            chest  v1  \n",
       "605       1   histo  60.0    male            chest  v1  \n",
       "606       1   histo  85.0  female  lower extremity  v1  \n",
       "607       1   histo  85.0  female  lower extremity  v1  \n",
       "...     ...     ...   ...     ...              ...  ..  \n",
       "1060      1   histo  70.0  female  lower extremity  v1  \n",
       "1061      1   histo  70.0  female  lower extremity  v1  \n",
       "1062      1   histo  65.0  female             back  v1  \n",
       "1063      1   histo  65.0  female             back  v1  \n",
       "1064      1   histo  65.0  female             back  v1  \n",
       "\n",
       "[462 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================\n",
      "EG: MELANOMA IN EXPANDED VALIDATION SET (ALL IMAGES USED)\n",
      "=========================================================\n",
      "\n",
      "- Note that 'lesion_mult' is always 3\n",
      "- HAM_0005678 represented by three images\n",
      "- Two distinct images of this lesion to choose from: ISIC_0031023 and ISIC_0028086\n",
      "- Use ISIC_0031023 once, and ISIC_0028086 twice\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028086</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028086</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>HAM_0006722</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0030443</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>HAM_0006722</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031499</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028764</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028764</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0029021</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>HAM_0002525</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025188</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>HAM_0001953</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025611</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id  lesion_mult  num_images      image_id  img_mult   dx  \\\n",
       "603   HAM_0005678            3           2  ISIC_0031023         1  mel   \n",
       "604   HAM_0005678            3           2  ISIC_0028086         2  mel   \n",
       "605   HAM_0005678            3           2  ISIC_0028086         2  mel   \n",
       "606   HAM_0006722            3           2  ISIC_0030443         1  mel   \n",
       "607   HAM_0006722            3           2  ISIC_0031499         2  mel   \n",
       "...           ...          ...         ...           ...       ...  ...   \n",
       "1060  HAM_0004746            3           2  ISIC_0028764         2  mel   \n",
       "1061  HAM_0004746            3           2  ISIC_0028764         2  mel   \n",
       "1062  HAM_0004746            3           2  ISIC_0029021         1  mel   \n",
       "1063  HAM_0002525            3           2  ISIC_0025188         1  mel   \n",
       "1064  HAM_0001953            3           2  ISIC_0025611         1  mel   \n",
       "\n",
       "      label dx_type   age     sex     localization set  \n",
       "603       1   histo  60.0    male            chest  v1  \n",
       "604       1   histo  60.0    male            chest  va  \n",
       "605       1   histo  60.0    male            chest  va  \n",
       "606       1   histo  85.0  female  lower extremity  va  \n",
       "607       1   histo  85.0  female  lower extremity  v1  \n",
       "...     ...     ...   ...     ...              ...  ..  \n",
       "1060      1   histo  65.0  female             back  v1  \n",
       "1061      1   histo  65.0  female             back  v1  \n",
       "1062      1   histo  65.0  female             back  va  \n",
       "1063      1   histo  55.0    male             face  va  \n",
       "1064      1   histo  65.0    male             back  va  \n",
       "\n",
       "[462 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "# The specific numbers given in this example assume a certain choice for the attributes  \n",
    "\n",
    "instance = demo\n",
    "\n",
    "df = demo.df_val1\n",
    "df = df[df['set'].isin([\"va\", \"v1\"]) & (df['dx'] == 'mel')]\n",
    "\n",
    "print_header(\"Eg: Melanoma in expanded validation set (only one image per lesion used)\")\n",
    "\n",
    "to_print = [f\"- Note that \\'lesion_mult\\' is always {instance.val_expansion_factor}\",\n",
    "            \"HAM_0005678 represented by three images\",\n",
    "            \"Two distinct images of this lesion: ISIC_0031023 and ISIC_0028086\",\n",
    "            f\"However, only use ISIC_0031023 ({instance.val_expansion_factor} times)\",]\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "display(df)\n",
    "\n",
    "df = demo.df_val_a\n",
    "df = df[df['set'].isin([\"va\", \"v1\"]) & (df['dx'] == 'mel')]\n",
    "\n",
    "print_header(\"Eg: Melanoma in expanded validation set (all images used)\")\n",
    "\n",
    "to_print = [f\"- Note that \\'lesion_mult\\' is always {instance.val_expansion_factor}\",\n",
    "            \"HAM_0005678 represented by three images\",\n",
    "            \"Two distinct images of this lesion to choose from: ISIC_0031023 and ISIC_0028086\",\n",
    "            \"Use ISIC_0031023 once, and ISIC_0028086 twice\",]\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d46cea",
   "metadata": {},
   "source": [
    "<a id='fine-tuning'></a>\n",
    "## Fine-tuning EfficientNet or ResNet18\n",
    "↑↑ [Contents](#contents) ↑ [Expanding the validation set](#expanding) ↓ [Small sample for testing code](#small_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aa1884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's set values for the attributes of our resnet18 class (the model we will use with out processed data).\n",
    "# One of the attributes has to do with image transformations.\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    \n",
    "transforms.RandomCrop((300, 300)),\n",
    "transforms.Resize((224,224)), # Resize images to fit ResNet input size\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet stats\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17a72b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Union, List, Callable\n",
    "import torchvision.models as models\n",
    "\n",
    "source: Union[process, pd.DataFrame] = demo      # Processed data to be fed into model for training.\n",
    "                                                 # Must either be an instance of the process class, or a dataframe of the same format as source.df if source were an instance of the process class.\n",
    "model_dir: Path = path[\"models\"]                 # Path to directory where models/model info/model results are stored.\n",
    "transform: Union[None, \n",
    "                 transforms.Compose, \n",
    "                 List[Callable]] = transform     # Transform to be applied to images before feeding into neural network.\n",
    "batch_size: Union[None, int] = 32                # Mini-batch size: default 32.\n",
    "epochs: Union[None, int] = 10                    # Number of epochs (all layers unfrozen from the start): default 10.\n",
    "base_learning_rate: Union[None, float] = 1/1000  # Learning rate to start with: default 1/1000. Using Adam optimizer.\n",
    "filename_stem: Union[None, str] = \"rn18\"         # For saving model and related files. Default \"rn18\" (if ResNet model) or \"EffNet\" (if EfficientNet), or \"cnn\".\n",
    "filename_suffix: Union[None, str] = \"demo\"       # Something descriptive and unique for future reference. Default empty string \"\".\n",
    "overwrite: Union[None, bool] = True              # If False, any will generate an unused filename for saving .pth, .csv files etc., but appending a two-digit number.\n",
    "                                                 # If None, will default to False. Only set to True if confident that training done on previous instances with same filename stem and suffix can be over-written.\n",
    "code_test: Union[None, bool] = True\n",
    "# model: Union[None, models.ResNet, models.EfficientNet] = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT) # Pre-trained model. Default: ResNet18.   \n",
    "model: Union[None, models.ResNet, models.EfficientNet] = models.resnet18(weights=\"ResNet18_Weights.DEFAULT\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da0fe522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============\n",
      "CODE TEST MODE\n",
      "==============\n",
      "\n",
      "- self.epochs set to 1\n",
      "- self.Print set to True\n",
      "- self.filename_suffix set to 'test'\n",
      "- self.overwrite set to True\n",
      "- self.df_train, self.df_val1, self.df_val_a replaced with a small number of records\n",
      "- Change code_test attribute to False and re-create/create new cnn instance after testing is done.\n",
      "\n",
      "Existing files will be overwritten. \n",
      "Base filename: rn18_ta_bal_test_1e_test_00\n",
      "Attributes saved to file: D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_test_1e_test_00_attributes.json\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the resnet18 class with attribute values as above.\n",
    "from multiclass_models import cnn\n",
    "\n",
    "resnet_demo = cnn(                                   \n",
    "    source=source,                                           \n",
    "    model_dir=model_dir,\n",
    "    transform=transform,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,                                          \n",
    "    base_learning_rate=base_learning_rate,\n",
    "    filename_stem=filename_stem,\n",
    "    filename_suffix=filename_suffix,                         \n",
    "    overwrite=overwrite,\n",
    "    code_test=code_test,    \n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b087606d",
   "metadata": {},
   "source": [
    "<a id='small_sample'></a>\n",
    "## Small sample for testing code\n",
    "↑↑ [Contents](#contents) ↑ [Fine-tuning EfficientNet or ResNet18](#fine-tuning) ↓ [Model architecture and state dictionary](#model_architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7fa41b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================\n",
      "CODE TEST: TRAINING SET\n",
      "=======================\n",
      "\n",
      "170 IMAGES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0004400</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0030026</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0004400</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0030026</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0004400</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0030026</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000744</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0032230</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000744</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0032230</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  lesion_mult  num_images      image_id  img_mult   dx  label  \\\n",
       "0  HAM_0004400            3           1  ISIC_0030026         3  bkl      0   \n",
       "1  HAM_0004400            3           1  ISIC_0030026         3  bkl      0   \n",
       "2  HAM_0004400            3           1  ISIC_0030026         3  bkl      0   \n",
       "3  HAM_0000744            3           3  ISIC_0032230         2  bkl      0   \n",
       "4  HAM_0000744            3           3  ISIC_0032230         2  bkl      0   \n",
       "\n",
       "  dx_type   age     sex localization set  \n",
       "0   histo  75.0  female         face  t1  \n",
       "1   histo  75.0  female         face  t1  \n",
       "2   histo  75.0  female         face  t1  \n",
       "3   histo  70.0    male         face  t1  \n",
       "4   histo  70.0    male         face  t1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "CODE TEST: VALIDATION SET (ONE IMAGE PER LESION, REPEATED 3 TIMES)\n",
      "==================================================================\n",
      "\n",
      "42 IMAGES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  lesion_mult  num_images      image_id  img_mult   dx  label  \\\n",
       "0  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "1  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "2  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "3  HAM_0000983            3           1  ISIC_0033490         3  bkl      0   \n",
       "4  HAM_0000983            3           1  ISIC_0033490         3  bkl      0   \n",
       "\n",
       "     dx_type   age      sex localization set  \n",
       "0  consensus  75.0     male         back  v1  \n",
       "1  consensus  75.0     male         back  v1  \n",
       "2  consensus  75.0     male         back  v1  \n",
       "3  consensus   NaN  unknown      unknown  v1  \n",
       "4  consensus   NaN  unknown      unknown  v1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "CODE TEST: VALIDATION SET (3 POSSIBLY DIFFERENT IMAGES PER LESION)\n",
      "==================================================================\n",
      "\n",
      "42 IMAGES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0034125</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0034125</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0033060</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0003943</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0031078</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0003943</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0031464</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  lesion_mult  num_images      image_id  img_mult   dx  label  \\\n",
       "0  HAM_0004406            3           2  ISIC_0034125         2  bkl      0   \n",
       "1  HAM_0004406            3           2  ISIC_0034125         2  bkl      0   \n",
       "2  HAM_0004406            3           2  ISIC_0033060         1  bkl      0   \n",
       "3  HAM_0003943            3           3  ISIC_0031078         1  bkl      0   \n",
       "4  HAM_0003943            3           3  ISIC_0031464         1  bkl      0   \n",
       "\n",
       "  dx_type   age     sex     localization set  \n",
       "0   histo  80.0    male             back  va  \n",
       "1   histo  80.0    male             back  va  \n",
       "2   histo  80.0    male             back  v1  \n",
       "3   histo  80.0  female  lower extremity  va  \n",
       "4   histo  80.0  female  lower extremity  v1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "print_header(\"Code test: training set\")\n",
    "print(f\"{instance.df_train.shape[0]} images\".upper())\n",
    "display(instance.df_train.head())\n",
    "\n",
    "print_header(f\"Code test: validation set (one image per lesion, repeated {instance.source.val_expansion_factor} times)\")\n",
    "print(f\"{instance.df_val1.shape[0]} images\".upper())\n",
    "display(instance.df_val1.head())\n",
    "\n",
    "print_header(f\"Code test: validation set ({instance.source.val_expansion_factor} possibly different images per lesion)\")\n",
    "print(f\"{instance.df_val_a.shape[0]} images\".upper())\n",
    "display(instance.df_val_a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f198de9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================\n",
      "CODE TEST: TRAINING AND VALIDATION\n",
      "==================================\n",
      "\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032114, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029480, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0027770, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032230, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027149, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032652, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029474, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029099, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025927, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027149, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028076, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028314, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030953, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028549, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033975, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025302, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030953, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030026, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033278, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029099, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024973, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "outputs.shape: torch.Size([32, 5])\n",
      "loss: 1.9919414520263672\n",
      "image_id, label, ohe-label: ISIC_0033346, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029480, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029891, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030026, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027598, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025628, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0033860, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025927, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032652, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028314, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028340, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025927, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0032114, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030026, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026280, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028076, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031728, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0033551, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033991, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033065, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031728, 4, tensor([0., 0., 0., 0., 1.])\n",
      "outputs.shape: torch.Size([32, 5])\n",
      "loss: 1.384078025817871\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030142, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032715, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032230, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033571, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0027770, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033551, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0031728, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0027672, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024932, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027560, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027560, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033975, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031217, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030953, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0024973, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030230, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0032652, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0033551, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0025927, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029514, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027149, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0027598, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033860, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027149, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033991, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030230, 4, tensor([0., 0., 0., 0., 1.])\n",
      "outputs.shape: torch.Size([32, 5])\n",
      "loss: 1.01431405544281\n",
      "image_id, label, ohe-label: ISIC_0027560, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031526, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030230, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027811, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033571, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0032992, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025302, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027672, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030231, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031526, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0024932, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029099, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028076, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030953, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030953, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028314, 2, tensor([0., 0., 1., 0., 0.])\n",
      "outputs.shape: torch.Size([32, 5])\n",
      "loss: 0.9826165437698364\n",
      "image_id, label, ohe-label: ISIC_0033679, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027598, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028314, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025927, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027770, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030231, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027560, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033847, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028076, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033679, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030142, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0025628, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0026789, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0025302, 0, tensor([1., 0., 0., 0., 0.])\n",
      "outputs.shape: torch.Size([32, 5])\n",
      "loss: 0.34899282455444336\n",
      "image_id, label, ohe-label: ISIC_0030231, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030142, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028076, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026280, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025628, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031217, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025599, 0, tensor([1., 0., 0., 0., 0.])\n",
      "outputs.shape: torch.Size([10, 5])\n",
      "loss: 0.29143521189689636\n",
      "Validating (one image per lesion)...\n",
      "image_id, label, ohe-label: ISIC_0033305, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033305, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033305, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033490, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033490, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033490, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024991, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024991, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024991, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024937, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024937, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024937, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032410, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032410, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032410, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028735, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028735, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028735, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031498, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031498, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031498, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028930, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028930, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028930, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030956, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030956, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030956, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024867, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024867, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024867, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028739, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028739, 4, tensor([0., 0., 0., 0., 1.])\n",
      "outputs.shape: torch.Size([10, 5])\n",
      "val1_loss: 5.411742687225342\n",
      "image_id, label, ohe-label: ISIC_0028739, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029917, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029917, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029917, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0026014, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026014, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026014, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027254, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027254, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027254, 2, tensor([0., 0., 1., 0., 0.])\n",
      "outputs.shape: torch.Size([10, 5])\n",
      "val1_loss: 2.676271677017212\n",
      "Validating (all images per lesion)...\n",
      "image_id, label, ohe-label: ISIC_0034125, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0034125, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033060, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031078, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031464, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025973, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027484, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027484, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027484, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026598, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026598, 3, tensor([0., 0., 0., 1., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id, label, ohe-label: ISIC_0026598, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031372, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026313, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026313, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026629, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026629, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026629, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030443, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031499, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031499, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033299, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033299, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033299, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032692, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033608, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033969, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028680, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028680, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028680, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027058, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0027058, 4, tensor([0., 0., 0., 0., 1.])\n",
      "outputs.shape: torch.Size([10, 5])\n",
      "val_a_loss: 3.8005549907684326\n",
      "image_id, label, ohe-label: ISIC_0030114, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0026940, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0032429, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029951, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028816, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028816, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028232, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024329, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024329, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024329, 2, tensor([0., 0., 1., 0., 0.])\n",
      "outputs.shape: torch.Size([10, 5])\n",
      "val_a_loss: 3.579584836959839\n",
      "Epoch 1/1, Training Loss: 1.0022, Validation Loss 1: 4.0440, Validation Loss a: 3.6901\n",
      "Saving model.state_dict() as D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_test_1e_test_00.pth.\n",
      "model.state_dict() can now be accessed through state_dict attribute.\n",
      "Train/val losses can now be accessed through epoch_losses attribute.\n",
      "Epoch losses dictionary save as D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_test_1e_test_00_epoch_losses.json\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the specified training data by calling the train method:\n",
    "# from utils import print_header\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "print_header(\"Code test: training and validation\")\n",
    "instance.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a722d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========\n",
      "CODE TEST\n",
      "=========\n",
      "\n",
      "LOSS DICTIONARY (TRAINING AND VALIDATION LOSS FROM EACH EPOCH)\n",
      "- Key 'val1_loss' refers to validation set in which one image per lesion is used.\n",
      "- Key 'val_a_los' refers to validation set in which more than one image per lesion is potentially used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': array([1.00222969]),\n",
       " 'val1_loss': array([4.04400718]),\n",
       " 'val_a_loss': array([3.69006991])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import load_dict\n",
    "\n",
    "# Let's look at the training and validation loss for each epoch:\n",
    "instance = resnet_demo\n",
    "\n",
    "print_header(\"Code test\")\n",
    "print(\"Loss dictionary (training and validation loss from each epoch)\".upper())\n",
    "to_print = [\"- Key \\'val1_loss\\' refers to validation set in which one image per lesion is used.\",\n",
    "         \"Key \\'val_a_los\\' refers to validation set in which more than one image per lesion is potentially used.\"]\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "try:\n",
    "    if instance.epoch_losses is not None:\n",
    "        display(instance.epoch_losses)\n",
    "    else:\n",
    "        retrieved_epoch_losses = load_dict(instance.model_dir, instance._filename + \"_epoch_losses\")\n",
    "        display(retrieved_epoch_losses)\n",
    "except:\n",
    "    retrieved_epoch_losses = load_dict(instance.model_dir, instance._filename + \"_epoch_losses\")\n",
    "    display(retrieved_epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "573874be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========\n",
      "CODE TEST\n",
      "=========\n",
      "\n",
      "If we didn't just train the model and the epoch losses dictionary is not in memory, we can load it from a file during training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [1.0022296855847042],\n",
       " 'val1_loss': [4.044007182121277],\n",
       " 'val_a_loss': [3.6900699138641357]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import load_dict\n",
    "\n",
    "# Let's look at the training and validation loss for each epoch:\n",
    "instance = resnet_demo\n",
    "\n",
    "print_header(\"Code test\")\n",
    "print(\"If we didn't just train the model and the epoch losses dictionary is not in memory, we can load it from a file during training.\")\n",
    "\n",
    "display(load_dict(instance.model_dir, instance._filename + \"_epoch_losses\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b425b8",
   "metadata": {},
   "source": [
    "<a id='model_architecture'></a>\n",
    "## Model architecture and state dictionary\n",
    "↑↑ [Contents](#contents) ↑ [Small sample for testing code](#small_sample) ↓ [Inference: getting probabilities](#inference1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3552fe8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "CODE TEST: MODEL ARCHITECTURE AND STATE DICTIONARY\n",
      "==================================================\n",
      "\n",
      "\n",
      "=============================\n",
      "CODE TEST: MODEL ARCHITECTURE\n",
      "=============================\n",
      "\n",
      "NOTE: 'OUT_FEATURES = 5' AT THE END\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "if instance.state_dict is None:\n",
    "    print(\"Loading model and state dictionary from file\\n\".upper())\n",
    "    file_path_pth = instance.model_dir.joinpath(instance._filename + \".pth\")\n",
    "\n",
    "    # model = models.efficientnet_b0()  \n",
    "    model = models.resnet18()  \n",
    "    if isinstance(model,models.ResNet):\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "    elif isinstance(model,models.EfficientNet):\n",
    "        num_ftrs = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "\n",
    "    # Load the state dictionary into the model\n",
    "    state_dict = torch.load(file_path_pth)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    instance.model = model\n",
    "    instance.state_dict = state_dict\n",
    "    \n",
    "print_header(\"Code test: model architecture\")\n",
    "print(f\"Note: \\'out_features = {len(instance.label_codes)}\\' at the end\".upper())\n",
    "display(instance.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cb6aa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================\n",
      "CODE TEST: MODEL STATE DICTIONARY\n",
      "=================================\n",
      "\n",
      "OrderedDict([('conv1.weight', tensor([[[[-9.4734e-03, -5.2116e-03, -5.9452e-04,  ...,  5.8054e-02,\n",
      "            1.8560e-02, -1.1146e-02],\n",
      "          [ 1.2014e-02,  1.0617e-02, -1.0889e-01,  ..., -2.7213e-01,\n",
      "           -1.2776e-01,  3.0430e-03],\n",
      "          [-5.9763e-03,  6.0046e-02,  2.9645e-01,  ...,  5.2089e-01,\n",
      "            2.5754e-01,  6.2821e-02],\n",
      "          ...,\n",
      "          [-2.6718e-02,  1.7227e-02,  7.3482e-02,  ..., -3.3373e-01,\n",
      "           -4.2156e-01, -2.5888e-01],\n",
      "          [ 3.1190e-02,  4.2055e-02,  6.1787e-02,  ...,  4.1287e-01,\n",
      "            3.9258e-01,  1.6504e-01],\n",
      "          [-1.3263e-02, -4.8003e-03, -2.5220e-02,  ..., -1.5196e-01,\n",
      "           -8.3439e-02, -6.6822e-03]],\n",
      "\n",
      "         [[-8.4013e-03, -2.3473e-02, -3.1329e-02,  ...,  3.3832e-02,\n",
      "            1.6109e-03, -2.4748e-02],\n",
      "          [ 4.8986e-02,  3.6950e-02, -1.0112e-01,  ..., -3.1173e-01,\n",
      "           -1.5991e-01, -2.9361e-04],\n",
      "          [ 2.3979e-03,  1.0222e-01,  4.0576e-01,  ...,  7.0861e-01,\n",
      "            3.6938e-01,  1.2 \n",
      " ... LOTS OF PARAMETERS ...\n",
      "  0.0132, 0.0151, 0.0134, 0.0147, 0.0155,\n",
      "        0.0166, 0.0160, 0.0111, 0.0156, 0.0120, 0.0179, 0.0122, 0.0137, 0.0131,\n",
      "        0.0210, 0.0190, 0.0120, 0.0112, 0.0117, 0.0210, 0.0140, 0.0150, 0.0130,\n",
      "        0.0144, 0.0116, 0.0133, 0.0130, 0.0148, 0.0176, 0.0122, 0.0147, 0.0180,\n",
      "        0.0128, 0.0159, 0.0142, 0.0127, 0.0180, 0.0190, 0.0120, 0.0133, 0.0119,\n",
      "        0.0157, 0.0108, 0.0163, 0.0157, 0.0148, 0.0192, 0.0124, 0.0158, 0.0119,\n",
      "        0.0129, 0.0122, 0.0170, 0.0148, 0.0126, 0.0140, 0.0152, 0.0149])), ('layer4.1.bn2.num_batches_tracked', tensor(6)), ('fc.weight', tensor([[-0.0061,  0.0320,  0.0349,  ...,  0.0457,  0.0054,  0.0314],\n",
      "        [-0.0107,  0.0232,  0.0213,  ..., -0.0427, -0.0203,  0.0263],\n",
      "        [ 0.0115,  0.0186, -0.0090,  ..., -0.0205, -0.0052,  0.0027],\n",
      "        [-0.0099, -0.0319, -0.0253,  ...,  0.0198,  0.0243, -0.0181],\n",
      "        [ 0.0356,  0.0135,  0.0235,  ..., -0.0354, -0.0018, -0.0093]])), ('fc.bias', tensor([-0.0153, -0.0069,  0.0127, -0.0035,  0.0213]))])\n"
     ]
    }
   ],
   "source": [
    "print_header(\"Code test: model state dictionary\")\n",
    "print(str(instance.state_dict)[:1000], \"\\n ... LOTS OF PARAMETERS ...\\n\", str(instance.state_dict)[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a9a44d31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving probabilities: D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_test_1e_test_00_val1_probabilities.csv\n",
      "Saving probabilities: D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_test_1e_test_00_val_a_probabilities.csv\n",
      "\n",
      "===============================================================\n",
      "CODE TEST: PROBABILITIES, VALIDATION SET (ONE IMAGE PER LESION)\n",
      "===============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.909989</td>\n",
       "      <td>0.067869</td>\n",
       "      <td>0.020783</td>\n",
       "      <td>0.001012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.961752</td>\n",
       "      <td>0.013188</td>\n",
       "      <td>0.013692</td>\n",
       "      <td>0.011316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.928205</td>\n",
       "      <td>0.053561</td>\n",
       "      <td>0.013748</td>\n",
       "      <td>0.004301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.056986</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.940998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.360215</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.026391</td>\n",
       "      <td>0.611853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx  prob_other  prob_mel  prob_akiec   prob_nv  \\\n",
       "0  HAM_0003218  ISIC_0033305  bkl    0.000347  0.909989    0.067869  0.020783   \n",
       "1  HAM_0003218  ISIC_0033305  bkl    0.000052  0.961752    0.013188  0.013692   \n",
       "2  HAM_0003218  ISIC_0033305  bkl    0.000186  0.928205    0.053561  0.013748   \n",
       "3  HAM_0000983  ISIC_0033490  bkl    0.000012  0.056986    0.000047  0.001958   \n",
       "4  HAM_0000983  ISIC_0033490  bkl    0.000083  0.360215    0.001458  0.026391   \n",
       "\n",
       "   prob_bcc  \n",
       "0  0.001012  \n",
       "1  0.011316  \n",
       "2  0.004301  \n",
       "3  0.940998  \n",
       "4  0.611853  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================================\n",
      "CODE TEST: PROBABILITIES, VALIDATION SET (MORE THAN ONE IMAGE PER LESION)\n",
      "=========================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>ISIC_0034125</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.008977</td>\n",
       "      <td>0.721454</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.263809</td>\n",
       "      <td>0.000552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>ISIC_0034125</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.006242</td>\n",
       "      <td>0.664127</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.325128</td>\n",
       "      <td>0.000323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>ISIC_0033060</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.983301</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.006059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0003943</td>\n",
       "      <td>ISIC_0031078</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.004140</td>\n",
       "      <td>0.012328</td>\n",
       "      <td>0.979180</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.000604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0003943</td>\n",
       "      <td>ISIC_0031464</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.137206</td>\n",
       "      <td>0.748915</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.101236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx  prob_other  prob_mel  prob_akiec   prob_nv  \\\n",
       "0  HAM_0004406  ISIC_0034125  bkl    0.008977  0.721454    0.005207  0.263809   \n",
       "1  HAM_0004406  ISIC_0034125  bkl    0.006242  0.664127    0.004180  0.325128   \n",
       "2  HAM_0004406  ISIC_0033060  bkl    0.000041  0.983301    0.000597  0.010002   \n",
       "3  HAM_0003943  ISIC_0031078  bkl    0.004140  0.012328    0.979180  0.003748   \n",
       "4  HAM_0003943  ISIC_0031464  bkl    0.002361  0.137206    0.748915  0.010283   \n",
       "\n",
       "   prob_bcc  \n",
       "0  0.000552  \n",
       "1  0.000323  \n",
       "2  0.006059  \n",
       "3  0.000604  \n",
       "4  0.101236  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import get_probabilities\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "# model = models.efficientnet_b0()  \n",
    "# model = models.resnet18() \n",
    "# if isinstance(model,models.ResNet):\n",
    "#     num_ftrs = model.fc.in_features\n",
    "#     model.fc = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "# elif isinstance(model,models.EfficientNet):\n",
    "#     num_ftrs = model.classifier[1].in_features\n",
    "#     model.classifier[1] = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "\n",
    "instance.df_probabilities_val1 = get_probabilities(df=instance.df_val1,\n",
    "                                                   data_dir=instance.data_dir,\n",
    "                                                   model_dir=instance.model_dir,\n",
    "                                                   model=instance.model,\n",
    "                                                   filename=instance._filename,\n",
    "                                                   label_codes=instance.label_codes,\n",
    "                                                   transform=instance.transform,\n",
    "                                                   batch_size=instance.batch_size,\n",
    "                                                   Print=False,\n",
    "                                                   save_as=instance._filename + \"_val1\",)\n",
    "\n",
    "instance.df_probabilities_val_a = get_probabilities(df=instance.df_val_a,\n",
    "                                                    data_dir=instance.data_dir,\n",
    "                                                    model_dir=instance.model_dir,\n",
    "                                                    model=instance.model,\n",
    "                                                    filename=instance._filename,\n",
    "                                                    label_codes=instance.label_codes,\n",
    "                                                    transform=instance.transform,\n",
    "                                                    batch_size=instance.batch_size,\n",
    "                                                    Print=False,\n",
    "                                                    save_as=instance._filename + \"_val_a\",)\n",
    "\n",
    "print_header(\"Code test: probabilities, validation set (one image per lesion)\")\n",
    "display_columns = ['lesion_id', 'image_id', 'dx'] + [col for col in instance.df_probabilities_val1.columns if col.startswith('prob')]\n",
    "display(instance.df_probabilities_val1[display_columns].head())\n",
    "\n",
    "print_header(\"Code test: probabilities, validation set (more than one image per lesion)\")\n",
    "display(instance.df_probabilities_val_a[display_columns].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19414447",
   "metadata": {},
   "source": [
    "<a id='inference1'></a>\n",
    "## Inference: getting probabilities\n",
    "↑↑ [Contents](#contents) ↑ [Model architecture and state dictionary](#model_architecture) ↓ [Inference: combining probabilities](#inference2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa486a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================================\n",
      "CODE TEST: PREDICTION ON INDIVIDUAL IMAGES OR LESIONS\n",
      "=====================================================\n",
      "\n",
      "- We can make predictions for individual images or lesions.\n",
      "- We only require a dataframe with an 'image_id' column.\n",
      "- Given the filename of an image, the df_from_ids function will construct such a dataframe.\n",
      "- We can then feed this dataframe into the get_probabilities function.\n",
      "- Here is the result of passing 'filenames = ['ISIC_0033305','ISIC_0025661']' to df_from_ids:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0033305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0025661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id\n",
       "0  ISIC_0033305\n",
       "1  ISIC_0025661"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- And here are the corresponding probabilities:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.924487</td>\n",
       "      <td>0.031356</td>\n",
       "      <td>0.031861</td>\n",
       "      <td>0.011903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.351872</td>\n",
       "      <td>0.417792</td>\n",
       "      <td>0.158065</td>\n",
       "      <td>0.069817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  prob_other  prob_mel  prob_akiec   prob_nv  prob_bcc\n",
       "0  ISIC_0033305    0.000393  0.924487    0.031356  0.031861  0.011903\n",
       "1  ISIC_0025661    0.002455  0.351872    0.417792  0.158065  0.069817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- If we have a lesion_id with associated image_ids, we can also construct a small dataframe.\n",
      "- The df_from_ids function also takes arguments for the number of predictions we want to make for a given image/lesion.\n",
      "- Here is the result of passing 'lesion_ids = 'HAM_0000118', 'multiplicity = 3', and 'one_img_per_lesion = False' to df_from_ids:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id\n",
       "0  HAM_0000118  ISIC_0027419\n",
       "1  HAM_0000118  ISIC_0025030\n",
       "2  HAM_0000118  ISIC_0025030"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- We have filtered all columns except for lesion_id and image_id (knowing the diagnosis defeats the purpose).\n",
      "- Here are the associated probabilities:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.942904</td>\n",
       "      <td>0.035084</td>\n",
       "      <td>0.019931</td>\n",
       "      <td>0.001834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.982403</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.013661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.911008</td>\n",
       "      <td>0.043588</td>\n",
       "      <td>0.010123</td>\n",
       "      <td>0.035194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id  prob_other  prob_mel  prob_akiec   prob_nv  \\\n",
       "0  HAM_0000118  ISIC_0027419    0.000247  0.942904    0.035084  0.019931   \n",
       "1  HAM_0000118  ISIC_0025030    0.000034  0.982403    0.000663  0.003238   \n",
       "2  HAM_0000118  ISIC_0025030    0.000087  0.911008    0.043588  0.010123   \n",
       "\n",
       "   prob_bcc  \n",
       "0  0.001834  \n",
       "1  0.013661  \n",
       "2  0.035194  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Notice that the probabilities may vary with each execution of a prediction.\n",
      "- This is because a random transformation may be applied to each image before our model makes a prediction on it.\n"
     ]
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import df_from_ids, get_probabilities     \n",
    "\n",
    "instance = resnet_demo\n",
    "df = instance.df\n",
    "\n",
    "print_header(\"Code test: prediction on individual images or lesions\")\n",
    "\n",
    "to_print = [\"- We can make predictions for individual images or lesions.\",\n",
    "            \"We only require a dataframe with an \\'image_id\\' column.\",\n",
    "            \"Given the filename of an image, the df_from_ids function will construct such a dataframe.\",\n",
    "            \"We can then feed this dataframe into the get_probabilities function.\",\n",
    "            \"Here is the result of passing \\'filenames = [\\'ISIC_0033305\\',\\'ISIC_0025661\\']\\' to df_from_ids:\",\n",
    "            \"- And here are the corresponding probabilities:\",\n",
    "            \"- If we have a lesion_id with associated image_ids, we can also construct a small dataframe.\",\n",
    "            \"The df_from_ids function also takes arguments for the number of predictions we want to make for a given image/lesion.\",\n",
    "            \"Here is the result of passing \\'lesion_ids = \\'HAM_0000118\\', \\'multiplicity = 3\\', and \\'one_img_per_lesion = False\\' to df_from_ids:\",\n",
    "            \"- We have filtered all columns except for lesion_id and image_id (knowing the diagnosis defeats the purpose).\",\n",
    "            \"- Here are the associated probabilities:\",\n",
    "            \"- Notice that the probabilities may vary with each execution of a prediction.\",\n",
    "            \"This is because a random transformation may be applied to each image before our model makes a prediction on it.\"]\n",
    "\n",
    "df_2img = df_from_ids(filenames=['ISIC_0033305','ISIC_0025661'], # can be a string or a list of strings\n",
    "                       multiplicity=None,\n",
    "                       lesion_ids=None,\n",
    "                       df=df,\n",
    "                       one_img_per_lesion=None,)\n",
    "\n",
    "print(\"\\n- \".join(to_print[:5]))\n",
    "\n",
    "display(df_2img)\n",
    "\n",
    "df_2img_prob = get_probabilities(df=df_2img,\n",
    "                  data_dir=instance.data_dir,\n",
    "                  model_dir=instance.model_dir,\n",
    "                  model=instance.model,\n",
    "                  filename=instance._filename,\n",
    "                  label_codes=instance.label_codes,\n",
    "                  transform=instance.transform,\n",
    "                  batch_size=instance.batch_size,\n",
    "                  Print=False,\n",
    "                  save_as=None,)   \n",
    "\n",
    "print(to_print[5])\n",
    "display(df_2img_prob)\n",
    "\n",
    "print(\"\\n- \".join(to_print[6:9]))\n",
    "\n",
    "df_1les = df_from_ids(filenames=None,\n",
    "                       multiplicity=3,\n",
    "                       lesion_ids='HAM_0000118', # can be a string or a list of strings\n",
    "                       df=df,\n",
    "                       one_img_per_lesion=False,)\n",
    "\n",
    "display_columns = ['lesion_id', 'image_id'] \n",
    "display(df_1les[display_columns])\n",
    "\n",
    "print(\"\\n- \".join(to_print[9:10]))\n",
    "\n",
    "df_1les_prob = get_probabilities(df=df_1les,\n",
    "                  data_dir=instance.data_dir,\n",
    "                  model_dir=instance.model_dir,\n",
    "                  model=instance.model,\n",
    "                  filename=instance._filename,\n",
    "                  label_codes=instance.label_codes,\n",
    "                  transform=instance.transform,\n",
    "                  batch_size=instance.batch_size,\n",
    "                  Print=False,\n",
    "                  save_as=None,)   \n",
    "\n",
    "print(to_print[10])\n",
    "display_columns = ['lesion_id', 'image_id'] + [col for col in df_1les_prob if col.startswith('prob')]\n",
    "display(df_1les_prob[display_columns])\n",
    "\n",
    "print(\"\\n- \".join(to_print[11:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d995871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's another example of how we'd use df_from_ids on an arbitrary image from outside our dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_from_somewhere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_from_somewhere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_from_somewhere</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               image_id\n",
       "0  image_from_somewhere\n",
       "1  image_from_somewhere\n",
       "2  image_from_somewhere"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If it were an actual image in the data_dir folder, we could feed this dataframe into the get_probabilities function.\n"
     ]
    }
   ],
   "source": [
    "print(\"Here's another example of how we'd use df_from_ids on an arbitrary image from outside our dataset.\")\n",
    "\n",
    "display(df_from_ids(filenames='image_from_somewhere', multiplicity=3,))\n",
    "\n",
    "print(\"If it were an actual image in the data_dir folder, we could feed this dataframe into the get_probabilities function.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fd9ec0",
   "metadata": {},
   "source": [
    "<a id='inference2'></a>\n",
    "## Inference: combining probabilities\n",
    "↑↑ [Contents](#contents) ↑ [Inference: getting probabilities](#inference1) ↓ [Inference: combining predictions](#inference3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "825133c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================\n",
      "CODE TEST: COMBINING PROBABILITIES\n",
      "==================================\n",
      "\n",
      "- We can combine multiple probabilities for a single lesion, if available, by taking the maximum, minimum, or mean.\n",
      "- Here is the original dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.942904</td>\n",
       "      <td>0.035084</td>\n",
       "      <td>0.019931</td>\n",
       "      <td>0.001834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.982403</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.013661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.911008</td>\n",
       "      <td>0.043588</td>\n",
       "      <td>0.010123</td>\n",
       "      <td>0.035194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  num_images      image_id   dx  label dx_type   age   sex  \\\n",
       "0  HAM_0000118           2  ISIC_0027419  bkl      0   histo  80.0  male   \n",
       "1  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "2  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "\n",
       "  localization set  prob_other  prob_mel  prob_akiec   prob_nv  prob_bcc  \n",
       "0        scalp  ta    0.000247  0.942904    0.035084  0.019931  0.001834  \n",
       "1        scalp  t1    0.000034  0.982403    0.000663  0.003238  0.013661  \n",
       "2        scalp  t1    0.000087  0.911008    0.043588  0.010123  0.035194  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Here is the dataframe with max mel probability, minimum nv probability, mean akiec and bcc prob's, and 'other' left alone:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.982403</td>\n",
       "      <td>0.026445</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.016897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.982403</td>\n",
       "      <td>0.026445</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.016897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.982403</td>\n",
       "      <td>0.026445</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.016897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  num_images      image_id   dx  label dx_type   age   sex  \\\n",
       "0  HAM_0000118           2  ISIC_0027419  bkl      0   histo  80.0  male   \n",
       "1  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "2  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "\n",
       "  localization set  prob_other  prob_mel  prob_akiec   prob_nv  prob_bcc  \n",
       "0        scalp  ta    0.000247  0.982403    0.026445  0.003238  0.016897  \n",
       "1        scalp  t1    0.000034  0.982403    0.026445  0.003238  0.016897  \n",
       "2        scalp  t1    0.000087  0.982403    0.026445  0.003238  0.016897  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Here's another example (no lesion_id in this case):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.924487</td>\n",
       "      <td>0.031356</td>\n",
       "      <td>0.031861</td>\n",
       "      <td>0.011903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.351872</td>\n",
       "      <td>0.417792</td>\n",
       "      <td>0.158065</td>\n",
       "      <td>0.069817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  prob_other  prob_mel  prob_akiec   prob_nv  prob_bcc\n",
       "0  ISIC_0033305    0.000393  0.924487    0.031356  0.031861  0.011903\n",
       "1  ISIC_0025661    0.002455  0.351872    0.417792  0.158065  0.069817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.924487</td>\n",
       "      <td>0.031356</td>\n",
       "      <td>0.031861</td>\n",
       "      <td>0.011903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.351872</td>\n",
       "      <td>0.417792</td>\n",
       "      <td>0.158065</td>\n",
       "      <td>0.069817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  prob_other  prob_mel  prob_akiec   prob_nv  prob_bcc\n",
       "0  ISIC_0033305    0.000393  0.924487    0.031356  0.031861  0.011903\n",
       "1  ISIC_0025661    0.002455  0.351872    0.417792  0.158065  0.069817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import aggregate_probabilities\n",
    "\n",
    "print_header(\"Code test: combining probabilities\")\n",
    "\n",
    "method = { 'max' : ['mel'], 'min' : ['nv'], 'mean' : ['akiec', 'bcc'] }\n",
    "\n",
    "print(\"- We can combine multiple probabilities for a single lesion, if available, by taking the maximum, minimum, or mean.\")\n",
    "print(\"- Here is the original dataframe:\")\n",
    "display(df_1les_prob)\n",
    "print(\"- Here is the dataframe with max mel probability, minimum nv probability, mean akiec and bcc prob\\'s, and \\'other\\' left alone:\")\n",
    "display(aggregate_probabilities(df_1les_prob, method=method))\n",
    "\n",
    "print(\"- Here's another example (no lesion_id in this case):\")\n",
    "display(df_2img_prob)\n",
    "display(aggregate_probabilities(df_2img_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c5cb3b",
   "metadata": {},
   "source": [
    "<a id='inference3'></a>\n",
    "## Inference: combining predictions\n",
    "↑↑ [Contents](#contents) ↑ [Inference: combining probabilities](#inference2) ↓ [Evaluation](#evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a2f14f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================\n",
      "CODE TEST: MAKING PREDICTIONS\n",
      "=============================\n",
      "\n",
      "- There are various ways we can form a prediction based on the combined probabilities.\n",
      "- For instance, we can immediately predict mel if the probability of mel is greater than 0.4.\n",
      "- If that's not the case, we can continue down a list, e.g. predicting bcc if probability of bcc is at least 0.45.\n",
      "- We can also require, e.g., the probability of nv to be at least 0.6 before predicting nv.\n",
      "- Once we have predicted classes for each image of a lesion, we can then combined the predictions in various ways.\n",
      "- For instance, we might want to make a final prediction of mel if that is a prediction for at least one of the images.\n",
      "- If not, we might again go through an ordered list, voting e.g. for bcc if at least one image is predicted as bcc.\n",
      "- It doesn't have to be 'at least one prediction': we could say 'if at least two predictions are for bcc, then...'.\n",
      "- If we reach the end of this list, we'd proceed to select the most popular prediction as the final one for the lesion.\n",
      "- We don't have to specify a priority list at all: in that case we just take the most popular prediction as the final one.\n",
      "- We could do similar if we had no lesion_id but only image_ids repeated a number of times.\n",
      "- Below, by way of illustration, we've stated that we want to predict bcc if the probability for bcc is at least 0.01.\n",
      "- But then, we've stated that we want to make a final prediction of mel if at least one prediction is for mel.\n",
      "- The label codes are as follows: {0: 'other', 1: 'mel', 2: 'akiec', 3: 'nv', 4: 'bcc'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.942904</td>\n",
       "      <td>0.035084</td>\n",
       "      <td>0.019931</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.982403</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.013661</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.911008</td>\n",
       "      <td>0.043588</td>\n",
       "      <td>0.010123</td>\n",
       "      <td>0.035194</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  num_images      image_id   dx  label dx_type   age   sex  \\\n",
       "0  HAM_0000118           2  ISIC_0027419  bkl      0   histo  80.0  male   \n",
       "1  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "2  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "\n",
       "  localization set  prob_other  prob_mel  prob_akiec   prob_nv  prob_bcc  \\\n",
       "0        scalp  ta    0.000247  0.942904    0.035084  0.019931  0.001834   \n",
       "1        scalp  t1    0.000034  0.982403    0.000663  0.003238  0.013661   \n",
       "2        scalp  t1    0.000087  0.911008    0.043588  0.010123  0.035194   \n",
       "\n",
       "   pred  pred_final  \n",
       "0     1           1  \n",
       "1     4           1  \n",
       "2     4           1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import final_prediction\n",
    "\n",
    "print_header(\"Code test: making predictions\")\n",
    "\n",
    "raw_probabilities_df: pd.DataFrame = df_1les_prob \n",
    "raw_probabilities_df_a: pd.DataFrame = instance.df_probabilities_val_a\n",
    "aggregate_method: Union[None, Dict[str, List[str]]] = { 'max' : ['mel'], 'min' : ['nv'], 'mean' : ['akiec', 'bcc']}\n",
    "threshold_dict_help: Union[None, OrderedDict[str, float]] = OrderedDict([('bcc',0.01), ('mel',0.4)])\n",
    "threshold_dict_hinder: Union[None, OrderedDict[str, float]] = OrderedDict([('nv',0.6)])    \n",
    "votes_to_win_dict: Union[None, OrderedDict[str, int]] = OrderedDict([('mel',1)])\n",
    "label_codes: Dict[int, str] = instance.label_codes\n",
    "prefix: Union[None, str] = 'prob_'\n",
    "    \n",
    "to_print = [\"- There are various ways we can form a prediction based on the combined probabilities.\",\n",
    "            \"For instance, we can immediately predict mel if the probability of mel is greater than 0.4.\",\n",
    "            \"If that's not the case, we can continue down a list, e.g. predicting bcc if probability of bcc is at least 0.45.\",\n",
    "            \"We can also require, e.g., the probability of nv to be at least 0.6 before predicting nv.\",\n",
    "            \"Once we have predicted classes for each image of a lesion, we can then combined the predictions in various ways.\",\n",
    "            \"For instance, we might want to make a final prediction of mel if that is a prediction for at least one of the images.\",\n",
    "            \"If not, we might again go through an ordered list, voting e.g. for bcc if at least one image is predicted as bcc.\",\n",
    "            \"It doesn't have to be \\'at least one prediction\\': we could say \\'if at least two predictions are for bcc, then...\\'.\",\n",
    "            \"If we reach the end of this list, we'd proceed to select the most popular prediction as the final one for the lesion.\",\n",
    "            \"We don't have to specify a priority list at all: in that case we just take the most popular prediction as the final one.\",\n",
    "            \"We could do similar if we had no lesion_id but only image_ids repeated a number of times.\",\n",
    "            \"Below, by way of illustration, we've stated that we want to predict bcc if the probability for bcc is at least 0.01.\",\n",
    "            \"But then, we've stated that we want to make a final prediction of mel if at least one prediction is for mel.\",\n",
    "            f\"The label codes are as follows: {instance.label_codes}\",            \n",
    "            ]\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "display(final_prediction(raw_probabilities_df=raw_probabilities_df, \n",
    "                 threshold_dict_help=threshold_dict_help,\n",
    "                 threshold_dict_hinder=threshold_dict_hinder,\n",
    "                 votes_to_win_dict=votes_to_win_dict,\n",
    "                 label_codes=label_codes,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a756c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now apply this to our code test validation sets.\n",
    "# We can reload the probabilities dataframes from csv files saved earlier, if they are not already in memory\n",
    "file_path_val1 = instance.model_dir.joinpath(instance._filename + \"_val1_probabilities.csv\")\n",
    "file_path_val_a = instance.model_dir.joinpath(instance._filename + \"_val_a_probabilities.csv\")\n",
    "instance.df_val1_probabilities = pd.read_csv(file_path_val1,index_col=0)\n",
    "instance.df_val_a_probabilities = pd.read_csv(file_path_val_a,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1e3e87ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================\n",
      "CODE TEST: COMBINING PROBABILITIES AND MAKING PREDICTIONS\n",
      "=========================================================\n",
      "\n",
      "VALIDATION SET: ONE IMAGE PER LESION, REPEATED 3 TIMES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.909989</td>\n",
       "      <td>0.067869</td>\n",
       "      <td>0.020783</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.961752</td>\n",
       "      <td>0.013188</td>\n",
       "      <td>0.013692</td>\n",
       "      <td>0.011316</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.928205</td>\n",
       "      <td>0.053561</td>\n",
       "      <td>0.013748</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.056986</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.940998</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.360215</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.026391</td>\n",
       "      <td>0.611853</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  lesion_mult  num_images      image_id  img_mult   dx  label  \\\n",
       "0  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "1  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "2  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "3  HAM_0000983            3           1  ISIC_0033490         3  bkl      0   \n",
       "4  HAM_0000983            3           1  ISIC_0033490         3  bkl      0   \n",
       "\n",
       "     dx_type   age      sex localization set  prob_other  prob_mel  \\\n",
       "0  consensus  75.0     male         back  v1    0.000347  0.909989   \n",
       "1  consensus  75.0     male         back  v1    0.000052  0.961752   \n",
       "2  consensus  75.0     male         back  v1    0.000186  0.928205   \n",
       "3  consensus   NaN  unknown      unknown  v1    0.000012  0.056986   \n",
       "4  consensus   NaN  unknown      unknown  v1    0.000083  0.360215   \n",
       "\n",
       "   prob_akiec   prob_nv  prob_bcc  pred  pred_final  \n",
       "0    0.067869  0.020783  0.001012     1           1  \n",
       "1    0.013188  0.013692  0.011316     1           1  \n",
       "2    0.053561  0.013748  0.004301     1           1  \n",
       "3    0.000047  0.001958  0.940998     4           4  \n",
       "4    0.001458  0.026391  0.611853     4           4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALIDATION SET: 3 IMAGES PER LESION, USING ALL IMAGES BEFORE REPEATING\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0034125</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>va</td>\n",
       "      <td>0.008977</td>\n",
       "      <td>0.721454</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.263809</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0034125</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>va</td>\n",
       "      <td>0.006242</td>\n",
       "      <td>0.664127</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.325128</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0033060</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.983301</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.006059</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0003943</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0031078</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>va</td>\n",
       "      <td>0.004140</td>\n",
       "      <td>0.012328</td>\n",
       "      <td>0.979180</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0003943</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0031464</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.137206</td>\n",
       "      <td>0.748915</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.101236</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  lesion_mult  num_images      image_id  img_mult   dx  label  \\\n",
       "0  HAM_0004406            3           2  ISIC_0034125         2  bkl      0   \n",
       "1  HAM_0004406            3           2  ISIC_0034125         2  bkl      0   \n",
       "2  HAM_0004406            3           2  ISIC_0033060         1  bkl      0   \n",
       "3  HAM_0003943            3           3  ISIC_0031078         1  bkl      0   \n",
       "4  HAM_0003943            3           3  ISIC_0031464         1  bkl      0   \n",
       "\n",
       "  dx_type   age     sex     localization set  prob_other  prob_mel  \\\n",
       "0   histo  80.0    male             back  va    0.008977  0.721454   \n",
       "1   histo  80.0    male             back  va    0.006242  0.664127   \n",
       "2   histo  80.0    male             back  v1    0.000041  0.983301   \n",
       "3   histo  80.0  female  lower extremity  va    0.004140  0.012328   \n",
       "4   histo  80.0  female  lower extremity  v1    0.002361  0.137206   \n",
       "\n",
       "   prob_akiec   prob_nv  prob_bcc  pred  pred_final  \n",
       "0    0.005207  0.263809  0.000552     1           1  \n",
       "1    0.004180  0.325128  0.000323     1           1  \n",
       "2    0.000597  0.010002  0.006059     1           1  \n",
       "3    0.979180  0.003748  0.000604     2           2  \n",
       "4    0.748915  0.010283  0.101236     2           2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NOW WE SIMPLY DROP DUPLICATES (LESION_ID)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>label</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HAM_0003267</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HAM_0006318</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HAM_0005518</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HAM_0005663</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HAM_0001953</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HAM_0002591</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HAM_0005713</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>HAM_0007568</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HAM_0007313</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>HAM_0007364</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>HAM_0002882</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>HAM_0003949</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lesion_id  label  pred_final\n",
       "0   HAM_0003218      0           1\n",
       "3   HAM_0000983      0           4\n",
       "6   HAM_0003267      3           0\n",
       "9   HAM_0006318      3           1\n",
       "12  HAM_0005518      0           1\n",
       "15  HAM_0005663      0           1\n",
       "18  HAM_0001953      1           1\n",
       "21  HAM_0002591      1           4\n",
       "24  HAM_0005713      0           1\n",
       "27  HAM_0007568      0           0\n",
       "30  HAM_0007313      4           3\n",
       "33  HAM_0007364      4           4\n",
       "36  HAM_0002882      2           4\n",
       "39  HAM_0003949      2           4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>label</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0003943</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HAM_0001756</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HAM_0006602</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HAM_0007418</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HAM_0004065</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HAM_0006722</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HAM_0000107</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HAM_0000940</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>HAM_0007150</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HAM_0005998</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>HAM_0005973</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>HAM_0003123</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>HAM_0002954</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lesion_id  label  pred_final\n",
       "0   HAM_0004406      0           1\n",
       "3   HAM_0003943      0           2\n",
       "6   HAM_0001756      3           0\n",
       "9   HAM_0006602      3           0\n",
       "12  HAM_0007418      0           1\n",
       "15  HAM_0004065      0           1\n",
       "18  HAM_0006722      1           4\n",
       "21  HAM_0000107      1           2\n",
       "24  HAM_0000940      0           1\n",
       "27  HAM_0007150      0           1\n",
       "30  HAM_0005998      4           1\n",
       "33  HAM_0005973      4           1\n",
       "36  HAM_0003123      2           1\n",
       "39  HAM_0002954      2           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import final_prediction\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "raw_probabilities_df1: pd.DataFrame = instance.df_probabilities_val1 \n",
    "raw_probabilities_df_a: pd.DataFrame = instance.df_probabilities_val_a\n",
    "aggregate_method: Union[None, Dict[str, List[str]]] = { 'max' : ['mel'], 'min' : ['nv'], 'mean' : ['bcc']}\n",
    "threshold_dict_help: Union[None, OrderedDict[str, float]] = OrderedDict([('mel',0.4), ('bcc',0.45)])\n",
    "threshold_dict_hinder: Union[None, OrderedDict[str, float]] = OrderedDict([('nv',0.6)])    \n",
    "votes_to_win_dict: Union[None, OrderedDict[str, int]] = OrderedDict([('mel',1)])\n",
    "label_codes: Dict[int, str] = instance.label_codes\n",
    "prefix: Union[None, str] = 'prob_'\n",
    "\n",
    "print_header(\"Code test: combining probabilities and making predictions\")\n",
    "\n",
    "print(f\"Validation set: one image per lesion, repeated {instance.source.val_expansion_factor} times\".upper())\n",
    "\n",
    "instance.df_pred_val1 = final_prediction(raw_probabilities_df=raw_probabilities_df1, \n",
    "                                         threshold_dict_help=threshold_dict_help,\n",
    "                                         threshold_dict_hinder=threshold_dict_hinder,\n",
    "                                         votes_to_win_dict=votes_to_win_dict,\n",
    "                                         label_codes=label_codes,)\n",
    "\n",
    "display(instance.df_pred_val1.head())\n",
    "\n",
    "print(f\"\\nValidation set: {instance.source.val_expansion_factor} images per lesion, using all images before repeating\".upper())\n",
    "\n",
    "instance.df_pred_val_a = final_prediction(raw_probabilities_df=raw_probabilities_df_a, \n",
    "                                         threshold_dict_help=threshold_dict_help,\n",
    "                                         threshold_dict_hinder=threshold_dict_hinder,\n",
    "                                         votes_to_win_dict=votes_to_win_dict,\n",
    "                                         label_codes=label_codes,)\n",
    "\n",
    "display(instance.df_pred_val_a.head())\n",
    "\n",
    "print(\"\\nNow we simply drop duplicates (lesion_id)...\".upper())\n",
    "\n",
    "display(instance.df_pred_val1.drop_duplicates(subset='lesion_id')[['lesion_id','label','pred_final']])\n",
    "\n",
    "display(instance.df_pred_val_a.drop_duplicates(subset='lesion_id')[['lesion_id','label','pred_final']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3662b55b",
   "metadata": {},
   "source": [
    "<a id='evaluation'></a>\n",
    "## Evaluation\n",
    "↑↑ [Contents](#contents) ↑ [Inference: combining predictions](#inference3) ↓ [Trivial models](#trivial_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3b8844a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================\n",
      "CODE TEST: CONFUSION MATRIX (VALIDATION SET)\n",
      "============================================\n",
      "\n",
      "- The overall evaluation metric would appear at the bottom right, if it were defined (this code test set is too small).\n",
      "- It would be a class-wise weighted average fbeta score, beta and weights as specified (default values 1).\n",
      "- One could also pass None, a float, or a different function to the func parameter in confusion_matrix_with_metric.\n",
      "\n",
      "ONE IMAGE PER LESION, REPEATED 3 TIMES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>akiec</th>\n",
       "      <th>nv</th>\n",
       "      <th>bcc</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>_</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted other       mel akiec   nv  bcc All    recall\n",
       "actual                                                 \n",
       "other         1         4     0    0    1   6  0.166667\n",
       "mel           0         1     0    0    1   2       0.5\n",
       "akiec         0         0     0    0    2   2       0.0\n",
       "nv            1         1     0    0    0   2       0.0\n",
       "bcc           0         0     0    1    1   2       0.5\n",
       "All           2         6     0    1    5  14         _\n",
       "precision   0.5  0.166667     _  0.0  0.2   _         _"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 IMAGES PER LESION, USING ALL AVAILABLE IMAGES BEFORE REPEATING\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>akiec</th>\n",
       "      <th>nv</th>\n",
       "      <th>bcc</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>_</td>\n",
       "      <td>0.0</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted other  mel akiec nv  bcc All recall\n",
       "actual                                       \n",
       "other         0    5     1  0    0   6    0.0\n",
       "mel           0    0     1  0    1   2    0.0\n",
       "akiec         0    2     0  0    0   2    0.0\n",
       "nv            2    0     0  0    0   2    0.0\n",
       "bcc           0    2     0  0    0   2    0.0\n",
       "All           2    9     2  0    1  14      _\n",
       "precision   0.0  0.0   0.0  _  0.0   _      _"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from evaluation import weighted_average_f, confusion_matrix_with_metric\n",
    "\n",
    "instance = resnet_demo\n",
    "map_labels = instance.label_codes\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label'] \n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final'] \n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']  \n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']  \n",
    "\n",
    "txp1 = pd.crosstab(target1,prediction1,margins=True,dropna=False)\n",
    "txp_a = pd.crosstab(target_a,prediction_a,margins=True,dropna=False)\n",
    "\n",
    "beta = 1\n",
    "# Weights inversely proportional to relative class size in the training set, giving more importance to smaller classes.\n",
    "weights = 1/instance.df_train['label'].value_counts(normalize=True).sort_index().values # None\n",
    "\n",
    "instance.cm1 = confusion_matrix_with_metric(AxB=txp1,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "instance.cm_a = confusion_matrix_with_metric(AxB=txp_a,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "print_header(\"Code test: confusion matrix (validation set)\")\n",
    "\n",
    "to_print = [\"- The overall evaluation metric would appear at the bottom right, if it were defined (this code test set is too small).\",\n",
    "            \"It would be a class-wise weighted average fbeta score, beta and weights as specified (default values 1).\",\n",
    "            \"One could also pass None, a float, or a different function to the func parameter in confusion_matrix_with_metric.\"]\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "print(f\"\\nOne image per lesion, repeated {instance.source.val_expansion_factor} times\".upper())\n",
    "display(instance.cm1.fillna('_'))\n",
    "\n",
    "print(f\"\\n{instance.source.val_expansion_factor} images per lesion, using all available images before repeating\".upper())\n",
    "display(instance.cm_a.fillna('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b0a5ae88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "CODE TEST: OTHER METRICS\n",
      "========================\n",
      "\n",
      "- ACC: accuracy\n",
      "- BACC: balanced accuracy\n",
      "- precision: macro-averaged precision (equal weight to each class)\n",
      "- recal: macro-averaged recall (equal weight to each class)\n",
      "- Fbeta: macro-averaged F_beta score (equal weight to each class)\n",
      "- MCC: Matthews correlation coefficient\n",
      "- ROC-AUC mac: macro-averaged ROC-AUC (equal weight to each class)\n",
      "- ROC-AUC wt: weighted-average ROC-AUC (larger class -> more weight)\n",
      "- ROC-AUC wt*: weighted-average ROC-AUC (larger class -> *less weight)\n",
      "\n",
      " ONE IMAGE PER LESION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.155345</td>\n",
       "      <td>0.157143</td>\n",
       "      <td>0.186813</td>\n",
       "      <td>0.043853</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC      BACC  precision    recall      F1/2        F1        F2  \\\n",
       "0  0.214286  0.233333   0.216667  0.233333  0.155345  0.157143  0.186813   \n",
       "\n",
       "        MCC  ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0  0.043853     0.616667    0.583333     0.616667  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " POSSIBLY MORE THAN ONE IMAGE PER LESION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.291386</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.434524</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACC  BACC  precision  recall  F1/2   F1   F2       MCC  ROC-AUC mac  \\\n",
       "0  0.0   0.0        0.0     0.0   0.0  0.0  0.0 -0.291386        0.425   \n",
       "\n",
       "   ROC-AUC wt  ROC-AUC wt*  \n",
       "0    0.434524     0.416667  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from evaluation import metric_dictionary\n",
    "# import pandas as pd\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label'] \n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final'] \n",
    "probabilities1 = instance.df_probabilities_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_') \n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']  \n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']  \n",
    "probabilities_a = instance.df_probabilities_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_') \n",
    "\n",
    "beta = 1\n",
    "# Weights inversely proportional to relative class size, giving more importance to smaller classes.\n",
    "weights = 1/instance.df_train['label'].value_counts(normalize=True).sort_index().values # None\n",
    "\n",
    "print_header(\"Code test: other metrics\")\n",
    "\n",
    "to_print = [\"- ACC: accuracy\",\n",
    "            \"BACC: balanced accuracy\",\n",
    "            \"precision: macro-averaged precision (equal weight to each class)\",\n",
    "            \"recal: macro-averaged recall (equal weight to each class)\",\n",
    "            \"Fbeta: macro-averaged F_beta score (equal weight to each class)\",\n",
    "            \"MCC: Matthews correlation coefficient\",\n",
    "            \"ROC-AUC mac: macro-averaged ROC-AUC (equal weight to each class)\",\n",
    "            \"ROC-AUC wt: weighted-average ROC-AUC (larger class -> more weight)\",\n",
    "            \"ROC-AUC wt*: weighted-average ROC-AUC (larger class -> *less weight)\",            \n",
    "            ]\n",
    "\n",
    "instance.metric_dict1 = metric_dictionary(target=target1, \n",
    "                                          prediction=prediction1, \n",
    "                                          probabilities=probabilities1)\n",
    "\n",
    "instance.metric_dict_a = metric_dictionary(target=target_a, \n",
    "                                          prediction=prediction_a, \n",
    "                                          probabilities=probabilities_a)\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "print(\"\\n One image per lesion\".upper())\n",
    "display(pd.DataFrame(instance.metric_dict1))\n",
    "\n",
    "print(\"\\n Possibly more than one image per lesion\".upper())\n",
    "display(pd.DataFrame(instance.metric_dict_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523552d9",
   "metadata": {},
   "source": [
    "<a id='trivial_models'></a>\n",
    "# Trivial models\n",
    "↑↑ [Contents](#contents) ↑ [Evaluation](#evaluation) ↓ [Baseline models](#baseline_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27939a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type, Union      # For type hints\n",
    "from processing import process      # Custom module for processing metadata\n",
    "\n",
    "data_dir: Path = path[\"images\"]     # Path to directory containing metadata.csv file\n",
    "csv_filename: str = \"metadata.csv\"  # The filename\n",
    "    \n",
    "tvr: int = 3              # Ratio of training set to validation set. See discussion below for explanation.\n",
    "seed: int = 0             # Random seed for parts of the process where randomness is called for.\n",
    "keep_first: bool = False  # If False, then, for each lesion, we choose a random image to assign to our training set. \n",
    "stratified: bool = True   # If True, we stratify classes so that the proportions remain as stable as possible after train/val split. \n",
    "                          # If False, the proportions will be roughly similar.\n",
    "\n",
    "to_classify: Union[list, dict] = [\"mel\",   # These are the lesion types we are interested in classifying. \n",
    "                                  \"bcc\",   # Any missing ones will be grouped together as the 0-label class: no need to write \"other\" here.\n",
    "                                  \"akiec\", # If 'other' is not desired, use restrict_to attribute above\n",
    "                                  \"nv\",]   # Can also be a dictionary, like { 'malignant' : ['mel', 'bcc'], 'benign' : ['nv', 'bkl']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "388f4712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded file 'D:\\projects\\skin-lesion-classification\\images\\metadata.csv'.\n",
      "- Inserted 'num_images' column in dataframe, to the right of 'lesion_id' column.\n",
      "- Inserted 'label' column in dataframe, to the right of 'dx' column: \n",
      "  {'df': 0, 'bkl': 0, 'vasc': 0, 'nv': 1, 'akiec': 2, 'mel': 3, 'bcc': 4}\n",
      "- Added 'set' column to dataframe, with values 't1', 'v1', 'ta', and 'va', to the right of 'localization' column.\n",
      "- Basic, overall dataframe (pre-train/test split): self.df\n",
      "- Training set (not balanced, all images per lesion): self.df_train\n",
      "- Validation set (not expanded, one image per lesion): self.df_val1\n",
      "- Validation set (not expanded, use all images of each lesion): self.df_val_a\n",
      "- Small sample dataframes for code testing: self._df_train_code_test, self._df_val1_code_test, self._df_val_a_code_test\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the process class with attribute values as above.\n",
    "trivial = process(data_dir=data_dir,\n",
    "               csv_filename=csv_filename,\n",
    "               tvr=tvr,\n",
    "               seed=seed,\n",
    "               keep_first=keep_first,\n",
    "               stratified=stratified,\n",
    "               to_classify=to_classify,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e06c0981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "TRIVIAL PREDICTION: ALL LABELS MAJORITY CLASS\n",
      "=============================================\n",
      "\n",
      "\n",
      " ONE IMAGE PER LESION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>nv</th>\n",
       "      <th>akiec</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>0</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,351</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0</td>\n",
       "      <td>1,869</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,869</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>_</td>\n",
       "      <td>0.722846</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted other        nv akiec mel bcc    All recall\n",
       "actual                                               \n",
       "other         0       225     0   0   0    225    0.0\n",
       "nv            0     1,351     0   0   0  1,351    1.0\n",
       "akiec         0        57     0   0   0     57    0.0\n",
       "mel           0       154     0   0   0    154    0.0\n",
       "bcc           0        82     0   0   0     82    0.0\n",
       "All           0     1,869     0   0   0  1,869      _\n",
       "precision     _  0.722846     _   _   _      _      _"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.722846</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.722846</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.153053</td>\n",
       "      <td>0.167826</td>\n",
       "      <td>0.185756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC  BACC  precision  recall      F1/2        F1        F2  MCC  \\\n",
       "0  0.722846   0.2   0.722846     0.2  0.153053  0.167826  0.185756  0.0   \n",
       "\n",
       "   ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0          0.5         0.5          0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ALL IMAGES PER LESION\n",
      "\n",
      "This is the same as the one image per lesion case, because the validation sets are identical after dropping duplicates.\n",
      "\n",
      "However, we include it here as a check.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>nv</th>\n",
       "      <th>akiec</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>0</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,351</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0</td>\n",
       "      <td>1,869</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,869</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>_</td>\n",
       "      <td>0.722846</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted other        nv akiec mel bcc    All recall\n",
       "actual                                               \n",
       "other         0       225     0   0   0    225    0.0\n",
       "nv            0     1,351     0   0   0  1,351    1.0\n",
       "akiec         0        57     0   0   0     57    0.0\n",
       "mel           0       154     0   0   0    154    0.0\n",
       "bcc           0        82     0   0   0     82    0.0\n",
       "All           0     1,869     0   0   0  1,869      _\n",
       "precision     _  0.722846     _   _   _      _      _"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.722846</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.722846</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.153053</td>\n",
       "      <td>0.167826</td>\n",
       "      <td>0.185756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC  BACC  precision  recall      F1/2        F1        F2  MCC  \\\n",
       "0  0.722846   0.2   0.722846     0.2  0.153053  0.167826  0.185756  0.0   \n",
       "\n",
       "   ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0          0.5         0.5          0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import print_header\n",
    "import pandas as pd\n",
    "from multiclass_models import trivial_prediction, final_prediction\n",
    "from evaluation import weighted_average_f, confusion_matrix_with_metric, metric_dictionary\n",
    "\n",
    "instance = trivial\n",
    "\n",
    "y_train = instance.df_train['label']\n",
    "y_val1 = instance.df_val1['label']\n",
    "y_val_a = instance.df_val_a['label']\n",
    "label_codes = instance.label_codes\n",
    "\n",
    "_, prediction1, probabilities1 = trivial_prediction(y_train, \n",
    "                                                    num_preds=y_val1.shape[0],\n",
    "                                                    label_codes=label_codes,\n",
    "                                                    pos_label='majority_class',)\n",
    "\n",
    "_, prediction_a, probabilities_a = trivial_prediction(y_train, \n",
    "                                                      num_preds=y_val_a.shape[0],\n",
    "                                                      label_codes=label_codes,\n",
    "                                                      pos_label='majority_class',)\n",
    "\n",
    "instance.df_probabilities_val1 = instance.df_val1.copy()\n",
    "instance.df_probabilities_val_a = instance.df_val_a.copy()\n",
    "for i, dx in label_codes.items():\n",
    "    instance.df_probabilities_val1['prob_' + dx] = probabilities1[:,i]\n",
    "    instance.df_probabilities_val_a['prob_' + dx] = probabilities_a[:,i]\n",
    "    \n",
    "raw_probabilities_df1 = instance.df_probabilities_val1 \n",
    "raw_probabilities_df_a = instance.df_probabilities_val_a\n",
    "\n",
    "instance.df_pred_val1 = final_prediction(raw_probabilities_df=raw_probabilities_df1, \n",
    "                                         label_codes=label_codes,)   \n",
    "\n",
    "instance.df_pred_val_a = final_prediction(raw_probabilities_df=raw_probabilities_df_a, \n",
    "                                         label_codes=label_codes,)  \n",
    "\n",
    "map_labels = label_codes\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label'] \n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final'] \n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']  \n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']  \n",
    "\n",
    "txp1 = pd.crosstab(target1,prediction1,margins=True,dropna=False)\n",
    "txp_a = pd.crosstab(target_a,prediction_a,margins=True,dropna=False)\n",
    "\n",
    "beta = 2\n",
    "# Weights inversely proportional to relative class size in the training set, giving more importance to smaller classes.\n",
    "weights = 1/instance.df_train['label'].value_counts(normalize=True).sort_index().values # None\n",
    "\n",
    "instance.cm1 = confusion_matrix_with_metric(AxB=txp1,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "instance.cm_a = confusion_matrix_with_metric(AxB=txp_a,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label'] \n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final'] \n",
    "probabilities1 = instance.df_probabilities_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_') \n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']  \n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']  \n",
    "probabilities_a = instance.df_probabilities_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_') \n",
    "\n",
    "instance.metric_dict1 = metric_dictionary(target=target1, \n",
    "                                          prediction=prediction1, \n",
    "                                          probabilities=probabilities1)\n",
    "\n",
    "instance.metric_dict_a = metric_dictionary(target=target_a, \n",
    "                                          prediction=prediction_a, \n",
    "                                          probabilities=probabilities_a)\n",
    "\n",
    "print_header(\"Trivial prediction: all labels majority class\")\n",
    "\n",
    "print(\"\\nOne image per lesion\".upper())\n",
    "\n",
    "display(instance.cm1.fillna('_'))\n",
    "display(pd.DataFrame(instance.metric_dict1))\n",
    "\n",
    "print(\"\\nAll images per lesion\".upper())\n",
    "print(\"- This is the same as the one image per lesion case, because the validation sets are identical after dropping duplicates.\")\n",
    "print(\"- However, we include it here as a check.\")\n",
    "display(instance.cm_a.fillna('_'))\n",
    "display(pd.DataFrame(instance.metric_dict_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8c6753f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "TRIVIAL PREDICTION: ALL LABELS MINORITY CLASS\n",
      "=============================================\n",
      "\n",
      "\n",
      "ONE IMAGE PER LESION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>nv</th>\n",
       "      <th>akiec</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,869</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,869</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>0.030498</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted other nv     akiec mel bcc    All recall\n",
       "actual                                            \n",
       "other         0  0       225   0   0    225    0.0\n",
       "nv            0  0     1,351   0   0  1,351    0.0\n",
       "akiec         0  0        57   0   0     57    1.0\n",
       "mel           0  0       154   0   0    154    0.0\n",
       "bcc           0  0        82   0   0     82    0.0\n",
       "All           0  0     1,869   0   0  1,869      _\n",
       "precision     _  _  0.030498   _   _      _      _"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030498</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.030498</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>0.011838</td>\n",
       "      <td>0.027182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC  BACC  precision  recall      F1/2        F1        F2  MCC  \\\n",
       "0  0.030498   0.2   0.030498     0.2  0.007567  0.011838  0.027182  0.0   \n",
       "\n",
       "   ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0          0.5         0.5          0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ALL IMAGES PER LESION\n",
      "- This is the same as the one image per lesion case, because the validation sets are identical after dropping duplicates.\n",
      "- However, we include it here as a check.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>nv</th>\n",
       "      <th>akiec</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,869</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,869</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>0.030498</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted other nv     akiec mel bcc    All recall\n",
       "actual                                            \n",
       "other         0  0       225   0   0    225    0.0\n",
       "nv            0  0     1,351   0   0  1,351    0.0\n",
       "akiec         0  0        57   0   0     57    1.0\n",
       "mel           0  0       154   0   0    154    0.0\n",
       "bcc           0  0        82   0   0     82    0.0\n",
       "All           0  0     1,869   0   0  1,869      _\n",
       "precision     _  _  0.030498   _   _      _      _"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030498</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.030498</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>0.011838</td>\n",
       "      <td>0.027182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC  BACC  precision  recall      F1/2        F1        F2  MCC  \\\n",
       "0  0.030498   0.2   0.030498     0.2  0.007567  0.011838  0.027182  0.0   \n",
       "\n",
       "   ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0          0.5         0.5          0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import print_header\n",
    "import pandas as pd\n",
    "from multiclass_models import trivial_prediction, final_prediction\n",
    "from evaluation import weighted_average_f, confusion_matrix_with_metric, metric_dictionary\n",
    "\n",
    "instance = trivial\n",
    "\n",
    "y_train = instance.df_train['label']\n",
    "y_val1 = instance.df_val1['label']\n",
    "y_val_a = instance.df_val_a['label']\n",
    "label_codes = instance.label_codes\n",
    "\n",
    "_, prediction1, probabilities1 = trivial_prediction(y_train, \n",
    "                                                    num_preds=y_val1.shape[0],\n",
    "                                                    label_codes=label_codes,\n",
    "                                                    pos_label='minority_class',)\n",
    "\n",
    "_, prediction_a, probabilities_a = trivial_prediction(y_train, \n",
    "                                                      num_preds=y_val_a.shape[0],\n",
    "                                                      label_codes=label_codes,\n",
    "                                                      pos_label='minority_class',)\n",
    "\n",
    "instance.df_probabilities_val1 = instance.df_val1.copy()\n",
    "instance.df_probabilities_val_a = instance.df_val_a.copy()\n",
    "for i, dx in label_codes.items():\n",
    "    instance.df_probabilities_val1['prob_' + dx] = probabilities1[:,i]\n",
    "    instance.df_probabilities_val_a['prob_' + dx] = probabilities_a[:,i]\n",
    "    \n",
    "raw_probabilities_df1 = instance.df_probabilities_val1 \n",
    "raw_probabilities_df_a = instance.df_probabilities_val_a\n",
    "\n",
    "instance.df_pred_val1 = final_prediction(raw_probabilities_df=raw_probabilities_df1, \n",
    "                                         label_codes=label_codes,)   \n",
    "\n",
    "instance.df_pred_val_a = final_prediction(raw_probabilities_df=raw_probabilities_df_a, \n",
    "                                         label_codes=label_codes,)  \n",
    "\n",
    "map_labels = label_codes\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label'] \n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final'] \n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']  \n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']  \n",
    "\n",
    "txp1 = pd.crosstab(target1,prediction1,margins=True,dropna=False)\n",
    "txp_a = pd.crosstab(target_a,prediction_a,margins=True,dropna=False)\n",
    "\n",
    "beta = 2\n",
    "# Weights inversely proportional to relative class size in the training set, giving more importance to smaller classes.\n",
    "weights = 1/instance.df_train['label'].value_counts(normalize=True).sort_index().values # None\n",
    "\n",
    "instance.cm1 = confusion_matrix_with_metric(AxB=txp1,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "instance.cm_a = confusion_matrix_with_metric(AxB=txp_a,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label'] \n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final'] \n",
    "probabilities1 = instance.df_probabilities_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_') \n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']  \n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']  \n",
    "probabilities_a = instance.df_probabilities_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_') \n",
    "\n",
    "instance.metric_dict1 = metric_dictionary(target=target1, \n",
    "                                          prediction=prediction1, \n",
    "                                          probabilities=probabilities1)\n",
    "\n",
    "instance.metric_dict_a = metric_dictionary(target=target_a, \n",
    "                                          prediction=prediction_a, \n",
    "                                          probabilities=probabilities_a)\n",
    "\n",
    "print_header(\"Trivial prediction: all labels minority class\")\n",
    "\n",
    "print(\"\\nOne image per lesion\".upper())\n",
    "\n",
    "display(instance.cm1.fillna('_'))\n",
    "display(pd.DataFrame(instance.metric_dict1))\n",
    "\n",
    "print(\"\\nAll images per lesion\".upper())\n",
    "print(\"- This is the same as the one image per lesion case, because the validation sets are identical after dropping duplicates.\")\n",
    "print(\"- However, we include it here as a check.\")\n",
    "display(instance.cm_a.fillna('_'))\n",
    "display(pd.DataFrame(instance.metric_dict_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "437dfcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================\n",
      "TRIVIAL PREDICTION: ALL LABELS MEL\n",
      "==================================\n",
      "\n",
      "\n",
      "ONE IMAGE PER LESION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>nv</th>\n",
       "      <th>akiec</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,869</td>\n",
       "      <td>0</td>\n",
       "      <td>1,869</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>0.082397</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted other nv akiec       mel bcc    All recall\n",
       "actual                                              \n",
       "other         0  0     0       225   0    225    0.0\n",
       "nv            0  0     0     1,351   0  1,351    0.0\n",
       "akiec         0  0     0        57   0     57    0.0\n",
       "mel           0  0     0       154   0    154    1.0\n",
       "bcc           0  0     0        82   0     82    0.0\n",
       "All           0  0     0     1,869   0  1,869      _\n",
       "precision     _  _     _  0.082397   _      _      _"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.082397</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.082397</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.020183</td>\n",
       "      <td>0.03045</td>\n",
       "      <td>0.061972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC  BACC  precision  recall      F1/2       F1        F2  MCC  \\\n",
       "0  0.082397   0.2   0.082397     0.2  0.020183  0.03045  0.061972  0.0   \n",
       "\n",
       "   ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0          0.5         0.5          0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ALL IMAGES PER LESION\n",
      "- This is the same as the one image per lesion case, because the validation sets are identical after dropping duplicates.\n",
      "- However, we include it here as a check.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>nv</th>\n",
       "      <th>akiec</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,869</td>\n",
       "      <td>0</td>\n",
       "      <td>1,869</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>0.082397</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted other nv akiec       mel bcc    All recall\n",
       "actual                                              \n",
       "other         0  0     0       225   0    225    0.0\n",
       "nv            0  0     0     1,351   0  1,351    0.0\n",
       "akiec         0  0     0        57   0     57    0.0\n",
       "mel           0  0     0       154   0    154    1.0\n",
       "bcc           0  0     0        82   0     82    0.0\n",
       "All           0  0     0     1,869   0  1,869      _\n",
       "precision     _  _     _  0.082397   _      _      _"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.082397</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.082397</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.020183</td>\n",
       "      <td>0.03045</td>\n",
       "      <td>0.061972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC  BACC  precision  recall      F1/2       F1        F2  MCC  \\\n",
       "0  0.082397   0.2   0.082397     0.2  0.020183  0.03045  0.061972  0.0   \n",
       "\n",
       "   ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0          0.5         0.5          0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import print_header\n",
    "import pandas as pd\n",
    "from multiclass_models import trivial_prediction, final_prediction\n",
    "from evaluation import weighted_average_f, confusion_matrix_with_metric, metric_dictionary\n",
    "\n",
    "instance = trivial\n",
    "\n",
    "y_train = instance.df_train['label']\n",
    "y_val1 = instance.df_val1['label']\n",
    "y_val_a = instance.df_val_a['label']\n",
    "label_codes = instance.label_codes\n",
    "\n",
    "_, prediction1, probabilities1 = trivial_prediction(y_train, \n",
    "                                                    num_preds=y_val1.shape[0],\n",
    "                                                    label_codes=label_codes,\n",
    "                                                    pos_label='mel',)\n",
    "\n",
    "_, prediction_a, probabilities_a = trivial_prediction(y_train, \n",
    "                                                      num_preds=y_val_a.shape[0],\n",
    "                                                      label_codes=label_codes,\n",
    "                                                      pos_label='mel',)\n",
    "\n",
    "instance.df_probabilities_val1 = instance.df_val1.copy()\n",
    "instance.df_probabilities_val_a = instance.df_val_a.copy()\n",
    "for i, dx in label_codes.items():\n",
    "    instance.df_probabilities_val1['prob_' + dx] = probabilities1[:,i]\n",
    "    instance.df_probabilities_val_a['prob_' + dx] = probabilities_a[:,i]\n",
    "    \n",
    "raw_probabilities_df1 = instance.df_probabilities_val1 \n",
    "raw_probabilities_df_a = instance.df_probabilities_val_a\n",
    "\n",
    "instance.df_pred_val1 = final_prediction(raw_probabilities_df=raw_probabilities_df1, \n",
    "                                         label_codes=label_codes,)   \n",
    "\n",
    "instance.df_pred_val_a = final_prediction(raw_probabilities_df=raw_probabilities_df_a, \n",
    "                                         label_codes=label_codes,)  \n",
    "\n",
    "map_labels = label_codes\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label'] \n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final'] \n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']  \n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']  \n",
    "\n",
    "txp1 = pd.crosstab(target1,prediction1,margins=True,dropna=False)\n",
    "txp_a = pd.crosstab(target_a,prediction_a,margins=True,dropna=False)\n",
    "\n",
    "beta = 2\n",
    "# Weights inversely proportional to relative class size in the training set, giving more importance to smaller classes.\n",
    "weights = 1/instance.df_train['label'].value_counts(normalize=True).sort_index().values # None\n",
    "\n",
    "instance.cm1 = confusion_matrix_with_metric(AxB=txp1,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "instance.cm_a = confusion_matrix_with_metric(AxB=txp_a,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label'] \n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final'] \n",
    "probabilities1 = instance.df_probabilities_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_') \n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']  \n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']  \n",
    "probabilities_a = instance.df_probabilities_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_') \n",
    "\n",
    "instance.metric_dict1 = metric_dictionary(target=target1, \n",
    "                                          prediction=prediction1, \n",
    "                                          probabilities=probabilities1)\n",
    "\n",
    "instance.metric_dict_a = metric_dictionary(target=target_a, \n",
    "                                          prediction=prediction_a, \n",
    "                                          probabilities=probabilities_a)\n",
    "\n",
    "print_header(\"Trivial prediction: all labels mel\")\n",
    "\n",
    "print(\"\\nOne image per lesion\".upper())\n",
    "\n",
    "display(instance.cm1.fillna('_'))\n",
    "display(pd.DataFrame(instance.metric_dict1))\n",
    "\n",
    "print(\"\\nAll images per lesion\".upper())\n",
    "print(\"- This is the same as the one image per lesion case, because the validation sets are identical after dropping duplicates.\")\n",
    "print(\"- However, we include it here as a check.\")\n",
    "display(instance.cm_a.fillna('_'))\n",
    "display(pd.DataFrame(instance.metric_dict_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ef75cf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================\n",
      "TRIVIAL PREDICTION: ALL LABELS BCC\n",
      "==================================\n",
      "\n",
      "\n",
      "ONE IMAGE PER LESION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>nv</th>\n",
       "      <th>akiec</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,351</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,869</td>\n",
       "      <td>1,869</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>0.043874</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted other nv akiec mel       bcc    All recall\n",
       "actual                                              \n",
       "other         0  0     0   0       225    225    0.0\n",
       "nv            0  0     0   0     1,351  1,351    0.0\n",
       "akiec         0  0     0   0        57     57    0.0\n",
       "mel           0  0     0   0       154    154    0.0\n",
       "bcc           0  0     0   0        82     82    1.0\n",
       "All           0  0     0   0     1,869  1,869      _\n",
       "precision     _  _     _   _  0.043874      _      _"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043874</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.043874</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010849</td>\n",
       "      <td>0.016812</td>\n",
       "      <td>0.037324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC  BACC  precision  recall      F1/2        F1        F2  MCC  \\\n",
       "0  0.043874   0.2   0.043874     0.2  0.010849  0.016812  0.037324  0.0   \n",
       "\n",
       "   ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0          0.5         0.5          0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ALL IMAGES PER LESION\n",
      "- This is the same as the one image per lesion case, because the validation sets are identical after dropping duplicates.\n",
      "- However, we include it here as a check.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>nv</th>\n",
       "      <th>akiec</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,351</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,869</td>\n",
       "      <td>1,869</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>0.043874</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted other nv akiec mel       bcc    All recall\n",
       "actual                                              \n",
       "other         0  0     0   0       225    225    0.0\n",
       "nv            0  0     0   0     1,351  1,351    0.0\n",
       "akiec         0  0     0   0        57     57    0.0\n",
       "mel           0  0     0   0       154    154    0.0\n",
       "bcc           0  0     0   0        82     82    1.0\n",
       "All           0  0     0   0     1,869  1,869      _\n",
       "precision     _  _     _   _  0.043874      _      _"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043874</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.043874</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010849</td>\n",
       "      <td>0.016812</td>\n",
       "      <td>0.037324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC  BACC  precision  recall      F1/2        F1        F2  MCC  \\\n",
       "0  0.043874   0.2   0.043874     0.2  0.010849  0.016812  0.037324  0.0   \n",
       "\n",
       "   ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0          0.5         0.5          0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import print_header\n",
    "import pandas as pd\n",
    "from multiclass_models import trivial_prediction, final_prediction\n",
    "from evaluation import weighted_average_f, confusion_matrix_with_metric, metric_dictionary\n",
    "\n",
    "instance = trivial\n",
    "\n",
    "y_train = instance.df_train['label']\n",
    "y_val1 = instance.df_val1['label']\n",
    "y_val_a = instance.df_val_a['label']\n",
    "label_codes = instance.label_codes\n",
    "\n",
    "_, prediction1, probabilities1 = trivial_prediction(y_train, \n",
    "                                                    num_preds=y_val1.shape[0],\n",
    "                                                    label_codes=label_codes,\n",
    "                                                    pos_label='bcc',)\n",
    "\n",
    "_, prediction_a, probabilities_a = trivial_prediction(y_train, \n",
    "                                                      num_preds=y_val_a.shape[0],\n",
    "                                                      label_codes=label_codes,\n",
    "                                                      pos_label='bcc',)\n",
    "\n",
    "instance.df_probabilities_val1 = instance.df_val1.copy()\n",
    "instance.df_probabilities_val_a = instance.df_val_a.copy()\n",
    "for i, dx in label_codes.items():\n",
    "    instance.df_probabilities_val1['prob_' + dx] = probabilities1[:,i]\n",
    "    instance.df_probabilities_val_a['prob_' + dx] = probabilities_a[:,i]\n",
    "    \n",
    "raw_probabilities_df1 = instance.df_probabilities_val1 \n",
    "raw_probabilities_df_a = instance.df_probabilities_val_a\n",
    "\n",
    "instance.df_pred_val1 = final_prediction(raw_probabilities_df=raw_probabilities_df1, \n",
    "                                         label_codes=label_codes,)   \n",
    "\n",
    "instance.df_pred_val_a = final_prediction(raw_probabilities_df=raw_probabilities_df_a, \n",
    "                                         label_codes=label_codes,)  \n",
    "\n",
    "map_labels = label_codes\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label'] \n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final'] \n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']  \n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']  \n",
    "\n",
    "txp1 = pd.crosstab(target1,prediction1,margins=True,dropna=False)\n",
    "txp_a = pd.crosstab(target_a,prediction_a,margins=True,dropna=False)\n",
    "\n",
    "beta = 2\n",
    "# Weights inversely proportional to relative class size in the training set, giving more importance to smaller classes.\n",
    "weights = 1/instance.df_train['label'].value_counts(normalize=True).sort_index().values # None\n",
    "\n",
    "instance.cm1 = confusion_matrix_with_metric(AxB=txp1,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "instance.cm_a = confusion_matrix_with_metric(AxB=txp_a,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label'] \n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final'] \n",
    "probabilities1 = instance.df_probabilities_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_') \n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']  \n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']  \n",
    "probabilities_a = instance.df_probabilities_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_') \n",
    "\n",
    "instance.metric_dict1 = metric_dictionary(target=target1, \n",
    "                                          prediction=prediction1, \n",
    "                                          probabilities=probabilities1)\n",
    "\n",
    "instance.metric_dict_a = metric_dictionary(target=target_a, \n",
    "                                          prediction=prediction_a, \n",
    "                                          probabilities=probabilities_a)\n",
    "\n",
    "print_header(\"Trivial prediction: all labels bcc\")\n",
    "\n",
    "print(\"\\nOne image per lesion\".upper())\n",
    "\n",
    "display(instance.cm1.fillna('_'))\n",
    "display(pd.DataFrame(instance.metric_dict1))\n",
    "\n",
    "print(\"\\nAll images per lesion\".upper())\n",
    "print(\"- This is the same as the one image per lesion case, because the validation sets are identical after dropping duplicates.\")\n",
    "print(\"- However, we include it here as a check.\")\n",
    "display(instance.cm_a.fillna('_'))\n",
    "display(pd.DataFrame(instance.metric_dict_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "33509422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================\n",
      "TRIVIAL PREDICTION: ALL LABELS OTHER\n",
      "====================================\n",
      "\n",
      "\n",
      "ONE IMAGE PER LESION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>nv</th>\n",
       "      <th>akiec</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>1,351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1,869</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,869</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.120385</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted     other nv akiec mel bcc    All recall\n",
       "actual                                            \n",
       "other           225  0     0   0   0    225    1.0\n",
       "nv            1,351  0     0   0   0  1,351    0.0\n",
       "akiec            57  0     0   0   0     57    0.0\n",
       "mel             154  0     0   0   0    154    0.0\n",
       "bcc              82  0     0   0   0     82    0.0\n",
       "All           1,869  0     0   0   0  1,869      _\n",
       "precision  0.120385  _     _   _   _      _      _"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.120385</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.120385</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.029217</td>\n",
       "      <td>0.04298</td>\n",
       "      <td>0.081257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC  BACC  precision  recall      F1/2       F1        F2  MCC  \\\n",
       "0  0.120385   0.2   0.120385     0.2  0.029217  0.04298  0.081257  0.0   \n",
       "\n",
       "   ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0          0.5         0.5          0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ALL IMAGES PER LESION\n",
      "- This is the same as the one image per lesion case, because the validation sets are identical after dropping duplicates.\n",
      "- However, we include it here as a check.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>nv</th>\n",
       "      <th>akiec</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>1,351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1,869</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,869</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.120385</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted     other nv akiec mel bcc    All recall\n",
       "actual                                            \n",
       "other           225  0     0   0   0    225    1.0\n",
       "nv            1,351  0     0   0   0  1,351    0.0\n",
       "akiec            57  0     0   0   0     57    0.0\n",
       "mel             154  0     0   0   0    154    0.0\n",
       "bcc              82  0     0   0   0     82    0.0\n",
       "All           1,869  0     0   0   0  1,869      _\n",
       "precision  0.120385  _     _   _   _      _      _"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.120385</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.120385</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.029217</td>\n",
       "      <td>0.04298</td>\n",
       "      <td>0.081257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC  BACC  precision  recall      F1/2       F1        F2  MCC  \\\n",
       "0  0.120385   0.2   0.120385     0.2  0.029217  0.04298  0.081257  0.0   \n",
       "\n",
       "   ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0          0.5         0.5          0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import print_header\n",
    "import pandas as pd\n",
    "from multiclass_models import trivial_prediction, final_prediction\n",
    "from evaluation import weighted_average_f, confusion_matrix_with_metric, metric_dictionary\n",
    "\n",
    "instance = trivial\n",
    "\n",
    "y_train = instance.df_train['label']\n",
    "y_val1 = instance.df_val1['label']\n",
    "y_val_a = instance.df_val_a['label']\n",
    "label_codes = instance.label_codes\n",
    "\n",
    "_, prediction1, probabilities1 = trivial_prediction(y_train, \n",
    "                                                    num_preds=y_val1.shape[0],\n",
    "                                                    label_codes=label_codes,\n",
    "                                                    pos_label='other',)\n",
    "\n",
    "_, prediction_a, probabilities_a = trivial_prediction(y_train, \n",
    "                                                      num_preds=y_val_a.shape[0],\n",
    "                                                      label_codes=label_codes,\n",
    "                                                      pos_label='other',)\n",
    "\n",
    "instance.df_probabilities_val1 = instance.df_val1.copy()\n",
    "instance.df_probabilities_val_a = instance.df_val_a.copy()\n",
    "for i, dx in label_codes.items():\n",
    "    instance.df_probabilities_val1['prob_' + dx] = probabilities1[:,i]\n",
    "    instance.df_probabilities_val_a['prob_' + dx] = probabilities_a[:,i]\n",
    "    \n",
    "raw_probabilities_df1 = instance.df_probabilities_val1 \n",
    "raw_probabilities_df_a = instance.df_probabilities_val_a\n",
    "\n",
    "instance.df_pred_val1 = final_prediction(raw_probabilities_df=raw_probabilities_df1, \n",
    "                                         label_codes=label_codes,)   \n",
    "\n",
    "instance.df_pred_val_a = final_prediction(raw_probabilities_df=raw_probabilities_df_a, \n",
    "                                         label_codes=label_codes,)  \n",
    "\n",
    "map_labels = label_codes\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label'] \n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final'] \n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']  \n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']  \n",
    "\n",
    "txp1 = pd.crosstab(target1,prediction1,margins=True,dropna=False)\n",
    "txp_a = pd.crosstab(target_a,prediction_a,margins=True,dropna=False)\n",
    "\n",
    "beta = 2\n",
    "# Weights inversely proportional to relative class size in the training set, giving more importance to smaller classes.\n",
    "weights = 1/instance.df_train['label'].value_counts(normalize=True).sort_index().values # None\n",
    "\n",
    "instance.cm1 = confusion_matrix_with_metric(AxB=txp1,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "instance.cm_a = confusion_matrix_with_metric(AxB=txp_a,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label'] \n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final'] \n",
    "probabilities1 = instance.df_probabilities_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_') \n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']  \n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']  \n",
    "probabilities_a = instance.df_probabilities_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_') \n",
    "\n",
    "instance.metric_dict1 = metric_dictionary(target=target1, \n",
    "                                          prediction=prediction1, \n",
    "                                          probabilities=probabilities1)\n",
    "\n",
    "instance.metric_dict_a = metric_dictionary(target=target_a, \n",
    "                                          prediction=prediction_a, \n",
    "                                          probabilities=probabilities_a)\n",
    "\n",
    "print_header(\"Trivial prediction: all labels other\")\n",
    "\n",
    "print(\"\\nOne image per lesion\".upper())\n",
    "\n",
    "display(instance.cm1.fillna('_'))\n",
    "display(pd.DataFrame(instance.metric_dict1))\n",
    "\n",
    "print(\"\\nAll images per lesion\".upper())\n",
    "print(\"- This is the same as the one image per lesion case, because the validation sets are identical after dropping duplicates.\")\n",
    "print(\"- However, we include it here as a check.\")\n",
    "display(instance.cm_a.fillna('_'))\n",
    "display(pd.DataFrame(instance.metric_dict_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e128cd9",
   "metadata": {},
   "source": [
    "<a id='baseline_models'></a>\n",
    "# Baseline models\n",
    "↑↑ [Contents](#contents) ↑ [Trivial models](#trivial_models) ↓ [Models with balancing](#models_with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "762eb068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type, Union      # For type hints\n",
    "from processing import process      # Custom module for processing metadata\n",
    "\n",
    "data_dir: Path = path[\"images\"]     # Path to directory containing metadata.csv file\n",
    "csv_filename: str = \"metadata.csv\"  # The filename\n",
    "    \n",
    "tvr: int = 3              # Ratio of training set to validation set. See discussion below for explanation.\n",
    "seed: int = 0             # Random seed for parts of the process where randomness is called for.\n",
    "keep_first: bool = False  # If False, then, for each lesion, we choose a random image to assign to our training set. \n",
    "stratified: bool = True   # If True, we stratify classes so that the proportions remain as stable as possible after train/val split. \n",
    "                          # If False, the proportions will be roughly similar.\n",
    "\n",
    "to_classify: Union[list, dict] = [\"mel\",   # These are the lesion types we are interested in classifying. \n",
    "                                  \"bcc\",   # Any missing ones will be grouped together as the 0-label class: no need to write \"other\" here.\n",
    "                                  \"akiec\", # If 'other' is not desired, use restrict_to attribute above\n",
    "                                  \"nv\",]   # Can also be a dictionary, like { 'malignant' : ['mel', 'bcc'], 'benign' : ['nv', 'bkl']}\n",
    "    \n",
    "train_one_img_per_lesion: Union[None, bool] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f5538a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded file 'D:\\projects\\skin-lesion-classification\\images\\metadata.csv'.\n",
      "- Inserted 'num_images' column in dataframe, to the right of 'lesion_id' column.\n",
      "- Inserted 'label' column in dataframe, to the right of 'dx' column: \n",
      "  {'df': 0, 'bkl': 0, 'vasc': 0, 'nv': 1, 'akiec': 2, 'mel': 3, 'bcc': 4}\n",
      "- Added 'set' column to dataframe, with values 't1', 'v1', 'ta', and 'va', to the right of 'localization' column.\n",
      "- Basic, overall dataframe (pre-train/test split): self.df\n",
      "- Training set (not balanced, one image per lesion): self.df_train\n",
      "- Validation set (not expanded, one image per lesion): self.df_val1\n",
      "- Validation set (not expanded, use all images of each lesion): self.df_val_a\n",
      "- Small sample dataframes for code testing: self._df_train_code_test, self._df_val1_code_test, self._df_val_a_code_test\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the process class with attribute values as above.\n",
    "rn18_defaults = process(data_dir=data_dir,\n",
    "                        csv_filename=csv_filename,\n",
    "                        tvr=tvr,\n",
    "                        seed=seed,\n",
    "                        keep_first=keep_first,\n",
    "                        stratified=stratified,\n",
    "                        to_classify=to_classify,\n",
    "                        train_one_img_per_lesion=train_one_img_per_lesion,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9708f5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Union, List, Callable\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "source: Union[process, pd.DataFrame] = rn18_defaults  # Processed data to be fed into model for training.\n",
    "                                                      # Must either be an instance of the process class, or a dataframe of the same format as source.df if source were an instance of the process class.\n",
    "model_dir: Path = path[\"models\"]                      # Path to directory where models/model info/model results are stored.\n",
    "\n",
    "transform: Union[None, \n",
    "                 transforms.Compose, \n",
    "                 List[Callable]] = None          # Transform to be applied to images before feeding into neural network.\n",
    "    \n",
    "filename_stem: Union[None, str] = \"rn18\"         # For saving model and related files. Default \"rn18\" (if ResNet model) or \"EffNet\" (if EfficientNet), or \"cnn\".\n",
    "filename_suffix: Union[None, str] = \"defaults\"   # Something descriptive and unique for future reference. Default empty string \"\".\n",
    "\n",
    "# model: Union[None, models.ResNet, models.EfficientNet] = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT) # Pre-trained model. Default: ResNet18.   \n",
    "model: Union[None, models.ResNet, models.EfficientNet] = models.resnet18(weights=\"ResNet18_Weights.DEFAULT\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "afa6ac8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New files will be created. \n",
      "Base filename: rn18_t1_10e_defaults_00\n",
      "Attributes saved to file: D:\\projects\\skin-lesion-classification\\models\\rn18_t1_10e_defaults_00_attributes.json\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the resnet18 class with attribute values as above.\n",
    "from multiclass_models import cnn\n",
    "\n",
    "rn18_defaults = cnn(source=source,                                           \n",
    "                    model_dir=model_dir,\n",
    "                    transform=transform,\n",
    "                    filename_stem=filename_stem,\n",
    "                    filename_suffix=filename_suffix,                         \n",
    "                    model=model,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9f8e1a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import print_header\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "instance = rn18_defaults\n",
    "\n",
    "model = models.resnet18()  \n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "\n",
    "# model = models.efficientnet_b0()  \n",
    "# num_ftrs = model.classifier[1].in_features\n",
    "# model.classifier[1] = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "\n",
    "instance.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e18781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import get_probabilities\n",
    "\n",
    "instance = rn18_defaults\n",
    "\n",
    "instance.df_probabilities_val1 = get_probabilities(df=instance.df_val1,\n",
    "                                                   data_dir=instance.data_dir,\n",
    "                                                   model_dir=instance.model_dir,\n",
    "                                                   model=instance.model,\n",
    "                                                   filename=instance._filename,\n",
    "                                                   label_codes=instance.label_codes,\n",
    "                                                   transform=instance.transform,\n",
    "                                                   batch_size=instance.batch_size,\n",
    "                                                   Print=False,\n",
    "                                                   save_as=instance._filename + \"_val1\",)\n",
    "\n",
    "instance.df_probabilities_val_a = get_probabilities(df=instance.df_val_a,\n",
    "                                                    data_dir=instance.data_dir,\n",
    "                                                    model_dir=instance.model_dir,\n",
    "                                                    model=instance.model,\n",
    "                                                    filename=instance._filename,\n",
    "                                                    label_codes=instance.label_codes,\n",
    "                                                    transform=instance.transform,\n",
    "                                                    batch_size=instance.batch_size,\n",
    "                                                    Print=False,\n",
    "                                                    save_as=instance._filename + \"_val_a\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e4002",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_header(\"...\")\n",
    "display_columns = ['lesion_id', 'image_id', 'dx'] + [col for col in instance.df_probabilities_val1.columns if col.startswith('prob')]\n",
    "display(instance.df_probabilities_val1[display_columns].head())\n",
    "\n",
    "print_header(\"...\")\n",
    "display(instance.df_probabilities_val_a[display_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98618f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "461e5ba8",
   "metadata": {},
   "source": [
    "<a id='models_with'></a>\n",
    "# Models with balancing\n",
    "↑↑ [Contents](#contents) ↑ [Baseline models](#baseline_models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa5ac4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0d7808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc84af86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ac72eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
