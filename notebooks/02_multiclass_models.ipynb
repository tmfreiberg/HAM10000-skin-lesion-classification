{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f32ebf",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c92e86b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path['project'] : D:\\projects\\skin-lesion-classification\n",
      "path['images'] : D:\\projects\\skin-lesion-classification\\images\n",
      "path['models'] : D:\\projects\\skin-lesion-classification\\models\n",
      "path['expository'] : D:\\projects\\skin-lesion-classification\\expository\n",
      "path['literature'] : D:\\projects\\skin-lesion-classification\\literature\n",
      "path['notebooks'] : D:\\projects\\skin-lesion-classification\\notebooks\n",
      "path['presentation'] : D:\\projects\\skin-lesion-classification\\presentation\n",
      "path['scripts'] : D:\\projects\\skin-lesion-classification\\scripts\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# If we're using Google Colab, we set the environment variable to point to the relevant folder in our Google Drive:\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.environ['SKIN_LESION_CLASSIFICATION'] = '/content/drive/MyDrive/Colab Notebooks/skin-lesion-classification'\n",
    "\n",
    "# Otherwise, we use the environment variable on our local system:\n",
    "project_environment_variable = \"SKIN_LESION_CLASSIFICATION\"\n",
    "\n",
    "# Path to the root directory of the project:\n",
    "project_path = Path(os.environ.get(project_environment_variable))\n",
    "\n",
    "# Relative path to /scripts (from where custom modules will be imported):\n",
    "scripts_path = project_path.joinpath(\"scripts\")\n",
    "\n",
    "# Add this path to sys.path so that Python will look there for modules:\n",
    "sys.path.append(str(scripts_path))\n",
    "\n",
    "# Now import path_step from our custom utils module to create a dictionary to all subdirectories in our root directory:\n",
    "from utils import path_setup\n",
    "path = path_setup.subfolders(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16849006",
   "metadata": {},
   "source": [
    "## Loading and preprocessing metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1200a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type, Union      # For type hints\n",
    "from processing import process      # Custom module for processing metadata\n",
    "\n",
    "data_dir: Path = path[\"images\"]     # Path to directory containing metadata.csv file\n",
    "csv_filename: str = \"metadata.csv\"  # The filename\n",
    "    \n",
    "restrict_to: Union[dict, None] = None                   # Remove all records *unless* column k lies in list v, for k : v in restrict_to dictionary.    \n",
    "remove_if: Union[dict, None] = None                     # Remove all records if column k lies in list v, for k : v in remove_if dictionary.    \n",
    "drop_row_if_missing_value_in: Union[list, None] = None  # We drop all rows for which there is a missing value in a column from this list.   \n",
    "                                    \n",
    "tvr: int = 3              # Ratio of training set to validation set. See discussion below for explanation.\n",
    "seed: int = 0             # Random seed for parts of the process where randomness is called for.\n",
    "keep_first: bool = False  # If False, then, for each lesion, we choose a random image to assign to our training set. \n",
    "stratified: bool = True   # If True, we stratify classes so that the proportions remain as stable as possible after train/val split. \n",
    "                          # If False, the proportions will be roughly similar.\n",
    "\n",
    "to_classify: Union[list, dict] = [\"mel\",   # These are the lesion types we are interested in classifying. \n",
    "                                  \"bcc\",   # Any missing ones will be grouped together as the 0-label class: no need to write \"other\" here.\n",
    "                                  \"akiec\", # If 'other' is not desired, use restrict_to attribute above\n",
    "                                  \"nv\",]   # Can also be a dictionary, like { 'malignant' : ['mel', 'bcc'], 'benign' : ['nv', 'bkl']}\n",
    "\n",
    "train_one_img_per_lesion: Union[bool, None] = False # If False, we take advantage of the (in some cases) multiple images of a lesion in our dataset\n",
    "val_one_img_per_lesion: Union[bool, None] = False   # If False, we will validate our model by combining multiple predictions for a lesion (for multiple images of it) into a single prediction\n",
    "val_expansion_factor: Union[int, None] = 3          # A random transformation may be applied to an image before making a prediction.\n",
    "                                                    # For a given lesion, we may make multiple predictions (as specified here), and combine them into a single prediction.\n",
    "    \n",
    "sample_size: Union[None, dict] = {\"mel\": 2000,     # Handling class imbalance by upsampling minority classes/downsampling majority classes     \n",
    "                                  \"bcc\": 2000,     # Specify how many images of each lesion diagnosis we want in our training set.\n",
    "                                  \"akiec\": 2000, \n",
    "                                  \"nv\": 2000,\n",
    "                                  \"other\" : 2000,} # Could also leave out \"other\" here, and include e.g. \"df: 2000\" if we wanted to.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbcb4935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded file 'D:\\projects\\skin-lesion-classification\\images\\metadata.csv'.\n",
      "- Inserted 'num_images' column in dataframe, to the right of 'lesion_id' column.\n",
      "- Inserted 'label' column in dataframe, to the right of 'dx' column: \n",
      "  {'bkl': 0, 'df': 0, 'vasc': 0, 'mel': 1, 'akiec': 2, 'nv': 3, 'bcc': 4}\n",
      "- Added 'set' column to dataframe, with values 't1', 'v1', 'ta', and 'va', to the right of 'localization' column.\n",
      "- Basic, overall dataframe (pre-train/test split): self.df\n",
      "- Balancing classes in training set.\n",
      "- Balanced training set (uses as many different images per lesion as possible): self.df_train\n",
      "- Expanding validation set: will combine 3 predictions into one, for each lesion in val set.\n",
      "- Expanded validation set (one image per lesion, repeated 3 times): self.df_val1\n",
      "- Expanded validation set (use up to 3 different images per lesion, if available): self.df_val_a\n",
      "- Small sample dataframes for code testing: self._df_train_code_test, self._df_val1_code_test, self._df_val_a_code_test\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the process class with attribute values as above.\n",
    "demo = process(data_dir=data_dir,\n",
    "               csv_filename=csv_filename,\n",
    "               restrict_to=restrict_to,\n",
    "               remove_if=remove_if,\n",
    "               drop_row_if_missing_value_in=drop_row_if_missing_value_in,\n",
    "               tvr=tvr,\n",
    "               seed=seed,\n",
    "               keep_first=keep_first,\n",
    "               stratified=stratified,\n",
    "               to_classify=to_classify,\n",
    "               train_one_img_per_lesion=train_one_img_per_lesion,\n",
    "               val_expansion_factor=val_expansion_factor,\n",
    "               sample_size=sample_size,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0205ff",
   "metadata": {},
   "source": [
    "## Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b841851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "DISTRIBUTION OF LESIONS BY DIAGNOSIS: OVERALL\n",
      "=============================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5403.00</td>\n",
       "      <td>898.00</td>\n",
       "      <td>614.00</td>\n",
       "      <td>327.00</td>\n",
       "      <td>228.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>72.33</td>\n",
       "      <td>12.02</td>\n",
       "      <td>8.22</td>\n",
       "      <td>4.38</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv   other     mel     bcc   akiec\n",
       "freq  5403.00  898.00  614.00  327.00  228.00\n",
       "%       72.33   12.02    8.22    4.38    3.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lesions: 7470.\n",
      "\n",
      "\n",
      "===========================================\n",
      "DISTRIBUTION OF LESIONS BY DIAGNOSIS: TRAIN\n",
      "===========================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4052.00</td>\n",
       "      <td>673.00</td>\n",
       "      <td>460.00</td>\n",
       "      <td>245.00</td>\n",
       "      <td>171.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>72.34</td>\n",
       "      <td>12.02</td>\n",
       "      <td>8.21</td>\n",
       "      <td>4.37</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv   other     mel     bcc   akiec\n",
       "freq  4052.00  673.00  460.00  245.00  171.00\n",
       "%       72.34   12.02    8.21    4.37    3.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lesions: 5601 (74.98% of all lesions).\n",
      "\n",
      "\n",
      "=========================================\n",
      "DISTRIBUTION OF LESIONS BY DIAGNOSIS: VAL\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1351.00</td>\n",
       "      <td>225.00</td>\n",
       "      <td>154.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>57.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>72.28</td>\n",
       "      <td>12.04</td>\n",
       "      <td>8.24</td>\n",
       "      <td>4.39</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv   other     mel    bcc  akiec\n",
       "freq  1351.00  225.00  154.00  82.00  57.00\n",
       "%       72.28   12.04    8.24   4.39   3.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lesions: 1869 (25.02% of all lesions).\n",
      "\n",
      "\n",
      "============================================\n",
      "DISTRIBUTION OF IMAGES BY DIAGNOSIS: OVERALL\n",
      "============================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6705.00</td>\n",
       "      <td>1356.00</td>\n",
       "      <td>1113.00</td>\n",
       "      <td>514.00</td>\n",
       "      <td>327.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>66.95</td>\n",
       "      <td>13.54</td>\n",
       "      <td>11.11</td>\n",
       "      <td>5.13</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv    other      mel     bcc   akiec\n",
       "freq  6705.00  1356.00  1113.00  514.00  327.00\n",
       "%       66.95    13.54    11.11    5.13    3.27"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 10015.\n",
      "\n",
      "\n",
      "==========================================\n",
      "DISTRIBUTION OF IMAGES BY DIAGNOSIS: TRAIN\n",
      "==========================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5007.00</td>\n",
       "      <td>1008.00</td>\n",
       "      <td>831.00</td>\n",
       "      <td>384.00</td>\n",
       "      <td>250.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>66.94</td>\n",
       "      <td>13.48</td>\n",
       "      <td>11.11</td>\n",
       "      <td>5.13</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv    other     mel     bcc   akiec\n",
       "freq  5007.00  1008.00  831.00  384.00  250.00\n",
       "%       66.94    13.48   11.11    5.13    3.34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 7480 (74.69% of all images).\n",
      "\n",
      "\n",
      "========================================\n",
      "DISTRIBUTION OF IMAGES BY DIAGNOSIS: VAL\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dx</th>\n",
       "      <th>nv</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>akiec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1698.00</td>\n",
       "      <td>348.00</td>\n",
       "      <td>282.00</td>\n",
       "      <td>130.00</td>\n",
       "      <td>77.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>66.98</td>\n",
       "      <td>13.73</td>\n",
       "      <td>11.12</td>\n",
       "      <td>5.13</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dx         nv   other     mel     bcc  akiec\n",
       "freq  1698.00  348.00  282.00  130.00  77.00\n",
       "%       66.98   13.73   11.12    5.13   3.04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 2535 (25.31% of all images).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for across in [\"lesions\", \"images\"]:\n",
    "    for subset in [\"all\", \"train\", \"val\"]:\n",
    "        process.dx_dist(demo, subset = subset, across = across)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86793889",
   "metadata": {},
   "source": [
    "## Train/val split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efbbd9e",
   "metadata": {},
   "source": [
    "<!-- <details>\n",
    "    <summary><b><i>Train test split explanation: click here to expand/collapse</i></b></summary> -->\n",
    "    \n",
    "We partition our dataset based on ```lesion_id```, **not** on ```image_id```: that way, every lesion will be represented in training or in validation, but not both.\n",
    "\n",
    "For each classification task, we will train a model by making use of\n",
    "* **exactly one** image for every lesion in our training set;\n",
    "* **all** images of every lesion in our training set.\n",
    "\n",
    "In both cases, we will vaildate our model by making use of \n",
    "* **exactly one** image for every lesion in our validation set;\n",
    "* **all** images of every lesion in our validation set (at least, _potentially_ all of them). \n",
    "\n",
    "**However**, we will make only one prediction per lesion (```lesion_id```) in our validation set: if there are multiple images of a lesion in the validation set, we will combine the predictions for the multiple images into a single prediction for the lesion.\n",
    "\n",
    "Accordingly, we proceed as follows. We'll explain by example, assuming the dataset is not filtered before splitting (if it is, the number of distinct lesions will be less than $7470$, and the proportions will be different).\n",
    "1. Randomly select (without replacement) a proportion of our $7470$ distinct ```lesion_id```s and label them with ```t``` (train). \n",
    "2. Label the remaining ```lesion_id```s with ```v``` (validate).\n",
    "3. For each ```lesion_id``` labeled with a ```t```:\n",
    "    * Select an ```image_id``` and label it ```t1```.\n",
    "    * Label all (if any) remaining ```image_id```s corresponding to this ```lesion_id``` with ```ta```.\n",
    "4.  For each ```lesion_id``` labeled with a ```v```:\n",
    "    * Select an ```image_id``` and label it ```v1```.\n",
    "    * Label all (if any) remaining ```image_id```s corresponding to this ```lesion_id``` with ```va```.\n",
    "\n",
    "In Step 1, the number of ```lesion_id```s randomly selected to be labeled ```t``` will be such that the ratio of ```t```s to ```v```s is as close as possible to a specified ratio ```tvr``` (we default to $3$, i.e. $\\approx75\\%$ of lesions are represented in training). In Steps 3 and 4, the first substep can be done randomly (our default choice), or we can simply choose the \"first\" image in our table that corresponds to the lesion (see ```keep_first``` attribute of the ```process``` class). \n",
    "\n",
    "The four train/val scenarios we could consider are:\n",
    "* ```t1v1```: train on precisely those images labeled ```t1``` and validate on precisely those labeled ```v1```.\n",
    "* ```t1va```: train on precisely those images labeled ```t1``` and validate on precisely those labeled ```v1``` **or** ```va```.\n",
    "* ```tav1```: train on precisely those images labeled ```t1``` **or** ```ta``` and validate on precisely those labeled ```v1```.\n",
    "* ```tava```: train on precisely those images labeled ```t1``` **or** ```ta``` and validate on precisely those labeled ```v1``` ***or*** ```va```.\n",
    "\n",
    "The mnemonic is ```t``` for training, ```v``` for validation, ```1``` for one-image-per-lesion, and ```a``` for all images.\n",
    "<!-- </details> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5f71744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================\n",
      "FIRST FIVE ROWS OF METADATA TABLE\n",
      "=================================\n",
      "\n",
      "ADDED COLUMNS\n",
      "\n",
      "- 'num_images': number of images of lesion in dataset\n",
      "- 'label': class to which lesion belongs\n",
      "- 'set': train/val assignment\n",
      "- 't*': lesion is in the training set\n",
      "- 'v*': lesion is in the validation set\n",
      "- 't1': we would train on this image if training a model on exactly one, or on all, image(s) per lesion in the training set\n",
      "- If training set is balanced using one image per lesion, this one image would be re-used as many times as necessary.\n",
      "- 'ta': we would train on this image if training a model on all images of each lesion in the training set\n",
      "- If training set is balanced using all images per lesion, images labeled ta would all be used before any image is repeated.\n",
      "- 'v1': we'd use this image if validating a model on exactly one, or on all, image(s) per lesion in the validation set\n",
      "- If a validation expansion factor is given, this one image would be re-used that many times\n",
      "- 'va': we'd use this image if validating on all images of each lesion in the validation set\n",
      "- If a validation expansion factor is given, iamges labeled va would all be used before any image is repeated.\n",
      "- NB: if more than one image is used for any lesion in validation, the predictions will be combined into a single prediction\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  num_images      image_id   dx  label dx_type   age   sex  \\\n",
       "0  HAM_0000118           2  ISIC_0027419  bkl      0   histo  80.0  male   \n",
       "1  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "2  HAM_0002730           2  ISIC_0026769  bkl      0   histo  80.0  male   \n",
       "3  HAM_0002730           2  ISIC_0025661  bkl      0   histo  80.0  male   \n",
       "4  HAM_0001466           2  ISIC_0031633  bkl      0   histo  75.0  male   \n",
       "\n",
       "  localization set  \n",
       "0        scalp  ta  \n",
       "1        scalp  t1  \n",
       "2        scalp  va  \n",
       "3        scalp  v1  \n",
       "4          ear  va  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's have a look at our metadata dataframe, which is now just an attribute of the metadata instance of the process class.\n",
    "from utils import print_header\n",
    "\n",
    "instance = demo\n",
    "df = instance.df\n",
    "\n",
    "print_header(\"First five rows of metadata table\")\n",
    "\n",
    "to_print = [\"Added columns\\n\".upper(), \n",
    "            \"\\'num_images\\': number of images of lesion in dataset\", \n",
    "            \"\\'label\\': class to which lesion belongs\",\n",
    "            \"\\'set\\': train/val assignment\",\n",
    "            \"\\'t*\\': lesion is in the training set\",\n",
    "            \"\\'v*\\': lesion is in the validation set\",\n",
    "            \"\\'t1\\': we would train on this image if training a model on exactly one, or on all, image(s) per lesion in the training set\",\n",
    "            \"If training set is balanced using one image per lesion, this one image would be re-used as many times as necessary.\",\n",
    "            \"\\'ta\\': we would train on this image if training a model on all images of each lesion in the training set\",\n",
    "            \"If training set is balanced using all images per lesion, images labeled ta would all be used before any image is repeated.\",\n",
    "            \"\\'v1': we\\'d use this image if validating a model on exactly one, or on all, image(s) per lesion in the validation set\",\n",
    "            \"If a validation expansion factor is given, this one image would be re-used that many times\",\n",
    "            \"\\'va': we\\'d use this image if validating on all images of each lesion in the validation set\" ,\n",
    "            \"If a validation expansion factor is given, iamges labeled va would all be used before any image is repeated.\",\n",
    "            \"NB: if more than one image is used for any lesion in validation, the predictions will be combined into a single prediction\"\n",
    "           ]\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb0736c",
   "metadata": {},
   "source": [
    "## Balancing the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f4cb43",
   "metadata": {},
   "source": [
    "<!-- <details>\n",
    "    <summary><b><i>Balancing/upsampling explanation: click here to expand/collapse</i></b></summary> -->\n",
    "\n",
    "We explain the balancing procedure by way of example. (This is performed by the ```balance``` method of the ```process``` class in our ```processing``` module.) We assume the dataset has not been filtered, training to validation ratio is $3$, etc. There are $460$ distinct melanoma lesions represented in our training set. As most melanoma are represented by multiple distinct images, there are a total of $831$ distinct images of melanoma lesions in our training set. Suppose we want our training set to contain $2000$ melanoma images: each of the $460$ distinct melanoma lesions will be represented by $2000/460 \\approx 4.35$ images on average. We do not merely sample with replacement.\n",
    "\n",
    "The goal is to (a) have as little variance as possible in the number of times a lesion is represented, and (b) use as many distinct images as possible (taking advantage of the fact that there are multiple _distinct_ images of most melanoma). Thus, we note that $2000 = 4\\times 460 + 160$, so we will use each of the $460$ distinct melanoma lesions four times, and make the remainder up by randomly sample $160$ distinct lesions from the $160$. In other words, exactly $300$ distinct lesions will each be represented by exactly four images, and exactly $160$ distinct lesions will each be represented by exactly five images: $2000 = 300 \\times 4 + 160 \\times 5$. \n",
    "\n",
    "How do we select the four images of each distinct melanoma lesion (plus another one image for $160$ of them)? Consider lesion id ```HAM_0000871``` for example: there are three distinct images of this lesion in our data set. Thus, if ```train_one_img_per_lesion``` is ```False```, we will use all three of them, and then randomly select one more (or two more if this particular lesion were to be one of the $160$ that are represented five times). See below. On the other hand, if ```train_one_img_per_lesion``` is ```True```, we have no choice but to use the one image (label ```t1```) four times.\n",
    "    \n",
    "<!-- </details> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c4a51e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "EG: REPRESENTATIONS OF LESION HAM_0000871 IN BALANCED TRAINING SET\n",
      "==================================================================\n",
      "\n",
      "HAM_0000871 REPRESENTED BY FOUR IMAGES\n",
      "\n",
      "- Three distinct images of this lesion to choose from: ISIC_0025964, ISIC_0030623, and ISIC_0025964\n",
      "- Use ISIC_0025964 once, ISIC_0030623 twice, and ISIC_0025964 once\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0025964</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0030623</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0026506</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>trunk</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0026506</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>trunk</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id  lesion_mult  num_images      image_id  img_mult   dx  \\\n",
       "1773  HAM_0000871            4           3  ISIC_0025964         1  mel   \n",
       "1774  HAM_0000871            4           3  ISIC_0030623         1  mel   \n",
       "3086  HAM_0000871            4           3  ISIC_0026506         2  mel   \n",
       "3087  HAM_0000871            4           3  ISIC_0026506         2  mel   \n",
       "\n",
       "      label dx_type   age     sex localization set  \n",
       "1773      1   histo  40.0  female        chest  ta  \n",
       "1774      1   histo  40.0  female        chest  t1  \n",
       "3086      1   histo  40.0  female        trunk  ta  \n",
       "3087      1   histo  40.0  female        trunk  ta  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "\n",
    "# The specific numbers in this example assume a certain choice for the attributes, including \n",
    "# sample_size: Union[None, dict] = {\"mel\": 2000,         \n",
    "#                                   \"bcc\": 2000, \n",
    "#                                   \"akiec\": 2000, \n",
    "#                                   \"nv\": 2000,\n",
    "#                                   \"other\" : 2000,}\n",
    "\n",
    "instance = demo\n",
    "df = demo.df_train\n",
    "\n",
    "print_header(\"Eg: Representations of lesion HAM_0000871 in balanced training set\")\n",
    "\n",
    "to_print = [\"HAM_0000871 represented by four images\\n\".upper(),\n",
    "            \"Three distinct images of this lesion to choose from: ISIC_0025964, ISIC_0030623, and ISIC_0025964\",\n",
    "            \"Use ISIC_0025964 once, ISIC_0030623 twice, and ISIC_0025964 once\",]\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "display(df[df['lesion_id'] == 'HAM_0000871'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a797a173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================\n",
      "EG: MELANOMA IN BALANCED TRAINING SET\n",
      "=====================================\n",
      "\n",
      "VALUE COUNTS FOR 'LESION_MULT' COLUMN\n",
      "\n",
      "- 300 distinct melanoma lesions each represented by four images: 300*4 = 1200\n",
      "- 160 distinct melanoma lesions each represented by five images: 160*5 = 800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4    1200\n",
       "5     800\n",
       "Name: lesion_mult, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0025964</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>HAM_0000871</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0030623</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>HAM_0000040</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0027190</td>\n",
       "      <td>5</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>HAM_0000040</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0027190</td>\n",
       "      <td>5</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>HAM_0000040</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0027190</td>\n",
       "      <td>5</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7778</th>\n",
       "      <td>HAM_0002552</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0032936</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>HAM_0002552</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0033232</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>HAM_0002552</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0033232</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>HAM_0003521</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0032258</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>HAM_0003521</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0032258</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>ta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id  lesion_mult  num_images      image_id  img_mult   dx  \\\n",
       "1773  HAM_0000871            4           3  ISIC_0025964         1  mel   \n",
       "1774  HAM_0000871            4           3  ISIC_0030623         1  mel   \n",
       "1775  HAM_0000040            5           1  ISIC_0027190         5  mel   \n",
       "1776  HAM_0000040            5           1  ISIC_0027190         5  mel   \n",
       "1777  HAM_0000040            5           1  ISIC_0027190         5  mel   \n",
       "...           ...          ...         ...           ...       ...  ...   \n",
       "7778  HAM_0002552            5           3  ISIC_0032936         2  mel   \n",
       "7784  HAM_0002552            5           3  ISIC_0033232         2  mel   \n",
       "7785  HAM_0002552            5           3  ISIC_0033232         2  mel   \n",
       "9998  HAM_0003521            5           2  ISIC_0032258         2  mel   \n",
       "9999  HAM_0003521            5           2  ISIC_0032258         2  mel   \n",
       "\n",
       "      label dx_type   age     sex     localization set  \n",
       "1773      1   histo  40.0  female            chest  ta  \n",
       "1774      1   histo  40.0  female            chest  t1  \n",
       "1775      1   histo  80.0    male  upper extremity  t1  \n",
       "1776      1   histo  80.0    male  upper extremity  t1  \n",
       "1777      1   histo  80.0    male  upper extremity  t1  \n",
       "...     ...     ...   ...     ...              ...  ..  \n",
       "7778      1   histo  25.0    male  upper extremity  ta  \n",
       "7784      1   histo  25.0    male  upper extremity  ta  \n",
       "7785      1   histo  25.0    male  upper extremity  ta  \n",
       "9998      1   histo  70.0  female             back  ta  \n",
       "9999      1   histo  70.0  female             back  ta  \n",
       "\n",
       "[2000 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "# The specific numbers given in this example assume a certain choice for the attributes, including \n",
    "# sample_size: Union[None, dict] = {\"mel\": 2000,         \n",
    "#                                   \"bcc\": 2000, \n",
    "#                                   \"akiec\": 2000, \n",
    "#                                   \"nv\": 2000,\n",
    "#                                   \"other\" : 2000,}\n",
    "\n",
    "instance = demo\n",
    "df = demo.df_train\n",
    "df = df[df['set'].isin([\"ta\", \"t1\"]) & (df['dx'] == 'mel')]\n",
    "\n",
    "print_header(\"Eg: Melanoma in balanced training set\")\n",
    "\n",
    "to_print = [\"Value counts for \\'lesion_mult\\' column\\n\".upper(),\n",
    "            \"300 distinct melanoma lesions each represented by four images: 300*4 = 1200\",\n",
    "            \"160 distinct melanoma lesions each represented by five images: 160*5 = 800\",]\n",
    "\n",
    "print(\"\\n- \".join(to_print[:3]))\n",
    "display(df['lesion_mult'].value_counts())\n",
    "\n",
    "print(\"\\n- \".join(to_print[3:]))\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3d5ede",
   "metadata": {},
   "source": [
    "## Expanding the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5f3b8",
   "metadata": {},
   "source": [
    "As mentioned already, we make one prediction per lesion. However, we may have multiple images of a given lesion at our disposal: we could make a prediction for each of them and combine them somehow into a single prediction for the lesion. Even if there is only one image of a lesion, we could make multiple predictions on it: if a random transformation is applied to an image before our model makes a prediction on it, this would yield a different array of probabilities each time. Again, we could combine the results into a single prediction.\n",
    "\n",
    "This is what the attribute ```val_expansion_factor``` of the ```process``` class is concerned with. Similarly to the way we balance the training set, we can replicate one single image per lesion in the validation set as many times as specified by ```val_expansion_factor```, as in ```self.df_val1```, or we can take advantage of other images of the lesion (if available), as in ```self.val_a```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25bef7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "EG: MELANOMA IN EXPANDED VALIDATION SET (ONLY ONE IMAGE PER LESION USED)\n",
      "========================================================================\n",
      "\n",
      "- Note that 'lesion_mult' is always 3\n",
      "- HAM_0005678 represented by three images\n",
      "- Two distinct images of this lesion: ISIC_0031023 and ISIC_0028086\n",
      "- However, only use ISIC_0031023 (3 times)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>HAM_0006722</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031499</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>HAM_0006722</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031499</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>HAM_0004081</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0031957</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>HAM_0004081</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0031957</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028764</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028764</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028764</td>\n",
       "      <td>3</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id  lesion_mult  num_images      image_id  img_mult   dx  \\\n",
       "603   HAM_0005678            3           2  ISIC_0031023         3  mel   \n",
       "604   HAM_0005678            3           2  ISIC_0031023         3  mel   \n",
       "605   HAM_0005678            3           2  ISIC_0031023         3  mel   \n",
       "606   HAM_0006722            3           2  ISIC_0031499         3  mel   \n",
       "607   HAM_0006722            3           2  ISIC_0031499         3  mel   \n",
       "...           ...          ...         ...           ...       ...  ...   \n",
       "1060  HAM_0004081            3           1  ISIC_0031957         3  mel   \n",
       "1061  HAM_0004081            3           1  ISIC_0031957         3  mel   \n",
       "1062  HAM_0004746            3           2  ISIC_0028764         3  mel   \n",
       "1063  HAM_0004746            3           2  ISIC_0028764         3  mel   \n",
       "1064  HAM_0004746            3           2  ISIC_0028764         3  mel   \n",
       "\n",
       "      label dx_type   age     sex     localization set  \n",
       "603       1   histo  60.0    male            chest  v1  \n",
       "604       1   histo  60.0    male            chest  v1  \n",
       "605       1   histo  60.0    male            chest  v1  \n",
       "606       1   histo  85.0  female  lower extremity  v1  \n",
       "607       1   histo  85.0  female  lower extremity  v1  \n",
       "...     ...     ...   ...     ...              ...  ..  \n",
       "1060      1   histo  70.0  female  lower extremity  v1  \n",
       "1061      1   histo  70.0  female  lower extremity  v1  \n",
       "1062      1   histo  65.0  female             back  v1  \n",
       "1063      1   histo  65.0  female             back  v1  \n",
       "1064      1   histo  65.0  female             back  v1  \n",
       "\n",
       "[462 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================\n",
      "EG: MELANOMA IN EXPANDED VALIDATION SET (ALL IMAGES USED)\n",
      "=========================================================\n",
      "\n",
      "- Note that 'lesion_mult' is always 3\n",
      "- HAM_0005678 represented by three images\n",
      "- Two distinct images of this lesion to choose from: ISIC_0031023 and ISIC_0028086\n",
      "- Use ISIC_0031023 once, and ISIC_0028086 twice\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028086</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028086</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>HAM_0006722</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0030443</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>HAM_0006722</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031499</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028764</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028764</td>\n",
       "      <td>2</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0029021</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>HAM_0002525</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025188</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>HAM_0001953</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025611</td>\n",
       "      <td>1</td>\n",
       "      <td>mel</td>\n",
       "      <td>1</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id  lesion_mult  num_images      image_id  img_mult   dx  \\\n",
       "603   HAM_0005678            3           2  ISIC_0031023         1  mel   \n",
       "604   HAM_0005678            3           2  ISIC_0028086         2  mel   \n",
       "605   HAM_0005678            3           2  ISIC_0028086         2  mel   \n",
       "606   HAM_0006722            3           2  ISIC_0030443         1  mel   \n",
       "607   HAM_0006722            3           2  ISIC_0031499         2  mel   \n",
       "...           ...          ...         ...           ...       ...  ...   \n",
       "1060  HAM_0004746            3           2  ISIC_0028764         2  mel   \n",
       "1061  HAM_0004746            3           2  ISIC_0028764         2  mel   \n",
       "1062  HAM_0004746            3           2  ISIC_0029021         1  mel   \n",
       "1063  HAM_0002525            3           2  ISIC_0025188         1  mel   \n",
       "1064  HAM_0001953            3           2  ISIC_0025611         1  mel   \n",
       "\n",
       "      label dx_type   age     sex     localization set  \n",
       "603       1   histo  60.0    male            chest  v1  \n",
       "604       1   histo  60.0    male            chest  va  \n",
       "605       1   histo  60.0    male            chest  va  \n",
       "606       1   histo  85.0  female  lower extremity  va  \n",
       "607       1   histo  85.0  female  lower extremity  v1  \n",
       "...     ...     ...   ...     ...              ...  ..  \n",
       "1060      1   histo  65.0  female             back  v1  \n",
       "1061      1   histo  65.0  female             back  v1  \n",
       "1062      1   histo  65.0  female             back  va  \n",
       "1063      1   histo  55.0    male             face  va  \n",
       "1064      1   histo  65.0    male             back  va  \n",
       "\n",
       "[462 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "# The specific numbers given in this example assume a certain choice for the attributes  \n",
    "\n",
    "instance = demo\n",
    "\n",
    "df = demo.df_val1\n",
    "df = df[df['set'].isin([\"va\", \"v1\"]) & (df['dx'] == 'mel')]\n",
    "\n",
    "print_header(\"Eg: Melanoma in expanded validation set (only one image per lesion used)\")\n",
    "\n",
    "to_print = [f\"- Note that \\'lesion_mult\\' is always {instance.val_expansion_factor}\",\n",
    "            \"HAM_0005678 represented by three images\",\n",
    "            \"Two distinct images of this lesion: ISIC_0031023 and ISIC_0028086\",\n",
    "            f\"However, only use ISIC_0031023 ({instance.val_expansion_factor} times)\",]\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "display(df)\n",
    "\n",
    "df = demo.df_val_a\n",
    "df = df[df['set'].isin([\"va\", \"v1\"]) & (df['dx'] == 'mel')]\n",
    "\n",
    "print_header(\"Eg: Melanoma in expanded validation set (all images used)\")\n",
    "\n",
    "to_print = [f\"- Note that \\'lesion_mult\\' is always {instance.val_expansion_factor}\",\n",
    "            \"HAM_0005678 represented by three images\",\n",
    "            \"Two distinct images of this lesion to choose from: ISIC_0031023 and ISIC_0028086\",\n",
    "            \"Use ISIC_0031023 once, and ISIC_0028086 twice\",]\n",
    "\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d46cea",
   "metadata": {},
   "source": [
    "## Fine-tuning EfficientNet or ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de51e9f",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aa1884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's set values for the attributes of our resnet18 class (the model we will use with out processed data).\n",
    "# One of the attributes has to do with image transformations.\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    \n",
    "transforms.RandomCrop((300, 300)),\n",
    "transforms.Resize((224,224)), # Resize images to fit ResNet input size\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet stats\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17a72b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Union, List, Callable\n",
    "import torchvision.models as models\n",
    "\n",
    "source: Union[process, pd.DataFrame] = demo      # Processed data to be fed into model for training.\n",
    "                                                 # Must either be an instance of the process class, or a dataframe of the same format as source.df if source were an instance of the process class.\n",
    "model_dir: Path = path[\"models\"]                 # Path to directory where models/model info/model results are stored.\n",
    "transform: Union[None, \n",
    "                 transforms.Compose, \n",
    "                 List[Callable]] = transform     # Transform to be applied to images before feeding into neural network.\n",
    "batch_size: Union[None, int] = 32                # Mini-batch size: default 32.\n",
    "epochs: Union[None, int] = 10                    # Number of epochs (all layers unfrozen from the start): default 10.\n",
    "base_learning_rate: Union[None, float] = 1/1000  # Learning rate to start with: default 1/1000. Using Adam optimizer.\n",
    "filename_stem: Union[None, str] = \"rn18\"         # For saving model and related files. Default \"rn18\" (if ResNet model) or \"EffNet\" (if EfficientNet), or \"cnn\".\n",
    "filename_suffix: Union[None, str] = \"demo\"       # Something descriptive and unique for future reference. Default empty string \"\".\n",
    "overwrite: Union[None, bool] = True              # If False, any will generate an unused filename for saving .pth, .csv files etc., but appending a two-digit number.\n",
    "                                                 # If None, will default to False. Only set to True if confident that training done on previous instances with same filename stem and suffix can be over-written.\n",
    "code_test: Union[None, bool] = True\n",
    "# model: Union[None, models.ResNet, models.EfficientNet] = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT) # Pre-trained model. Default: ResNet18.   \n",
    "model: Union[None, models.ResNet, models.EfficientNet] = models.resnet18(weights=\"ResNet18_Weights.DEFAULT\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da0fe522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============\n",
      "CODE TEST MODE\n",
      "==============\n",
      "\n",
      "- self.epochs set to 1\n",
      "- self.Print set to True\n",
      "- self.filename_suffix set to 'test'\n",
      "- self.overwrite set to True\n",
      "- self.df_train, self.df_val1, self.df_val_a replaced with a small number of records\n",
      "- Change code_test attribute to False and re-create/create new cnn instance after testing is done.\n",
      "\n",
      "Existing files will be overwritten. \n",
      "Base filename: rn18_ta_bal_test_1e_test_00\n",
      "Attributes saved to file: D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_test_1e_test_00_attributes.json\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the resnet18 class with attribute values as above.\n",
    "from multiclass_models import cnn\n",
    "\n",
    "resnet_demo = cnn(                                   \n",
    "    source=source,                                           \n",
    "    model_dir=model_dir,\n",
    "    transform=transform,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,                                          \n",
    "    base_learning_rate=base_learning_rate,\n",
    "    filename_stem=filename_stem,\n",
    "    filename_suffix=filename_suffix,                         \n",
    "    overwrite=overwrite,\n",
    "    code_test=code_test,    \n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b087606d",
   "metadata": {},
   "source": [
    "### Code test with small batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7fa41b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================\n",
      "CODE TEST: TRAINING SET\n",
      "=======================\n",
      "\n",
      "170 IMAGES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0004400</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0030026</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0004400</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0030026</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0004400</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0030026</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000744</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0032230</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000744</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0032230</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  lesion_mult  num_images      image_id  img_mult   dx  label  \\\n",
       "0  HAM_0004400            3           1  ISIC_0030026         3  bkl      0   \n",
       "1  HAM_0004400            3           1  ISIC_0030026         3  bkl      0   \n",
       "2  HAM_0004400            3           1  ISIC_0030026         3  bkl      0   \n",
       "3  HAM_0000744            3           3  ISIC_0032230         2  bkl      0   \n",
       "4  HAM_0000744            3           3  ISIC_0032230         2  bkl      0   \n",
       "\n",
       "  dx_type   age     sex localization set  \n",
       "0   histo  75.0  female         face  t1  \n",
       "1   histo  75.0  female         face  t1  \n",
       "2   histo  75.0  female         face  t1  \n",
       "3   histo  70.0    male         face  t1  \n",
       "4   histo  70.0    male         face  t1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "CODE TEST: VALIDATION SET (ONE IMAGE PER LESION, REPEATED 3 TIMES)\n",
      "==================================================================\n",
      "\n",
      "42 IMAGES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  lesion_mult  num_images      image_id  img_mult   dx  label  \\\n",
       "0  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "1  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "2  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "3  HAM_0000983            3           1  ISIC_0033490         3  bkl      0   \n",
       "4  HAM_0000983            3           1  ISIC_0033490         3  bkl      0   \n",
       "\n",
       "     dx_type   age      sex localization set  \n",
       "0  consensus  75.0     male         back  v1  \n",
       "1  consensus  75.0     male         back  v1  \n",
       "2  consensus  75.0     male         back  v1  \n",
       "3  consensus   NaN  unknown      unknown  v1  \n",
       "4  consensus   NaN  unknown      unknown  v1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "CODE TEST: VALIDATION SET (3 POSSIBLY DIFFERENT IMAGES PER LESION)\n",
      "==================================================================\n",
      "\n",
      "42 IMAGES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0034125</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0034125</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0033060</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0003943</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0031078</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0003943</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0031464</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  lesion_mult  num_images      image_id  img_mult   dx  label  \\\n",
       "0  HAM_0004406            3           2  ISIC_0034125         2  bkl      0   \n",
       "1  HAM_0004406            3           2  ISIC_0034125         2  bkl      0   \n",
       "2  HAM_0004406            3           2  ISIC_0033060         1  bkl      0   \n",
       "3  HAM_0003943            3           3  ISIC_0031078         1  bkl      0   \n",
       "4  HAM_0003943            3           3  ISIC_0031464         1  bkl      0   \n",
       "\n",
       "  dx_type   age     sex     localization set  \n",
       "0   histo  80.0    male             back  va  \n",
       "1   histo  80.0    male             back  va  \n",
       "2   histo  80.0    male             back  v1  \n",
       "3   histo  80.0  female  lower extremity  va  \n",
       "4   histo  80.0  female  lower extremity  v1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "print_header(\"Code test: training set\")\n",
    "print(f\"{instance.df_train.shape[0]} images\".upper())\n",
    "display(instance.df_train.head())\n",
    "\n",
    "print_header(f\"Code test: validation set (one image per lesion, repeated {instance.source.val_expansion_factor} times)\")\n",
    "print(f\"{instance.df_val1.shape[0]} images\".upper())\n",
    "display(instance.df_val1.head())\n",
    "\n",
    "print_header(f\"Code test: validation set ({instance.source.val_expansion_factor} possibly different images per lesion)\")\n",
    "print(f\"{instance.df_val_a.shape[0]} images\".upper())\n",
    "display(instance.df_val_a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f198de9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================\n",
      "CODE TEST: TRAINING AND VALIDATION\n",
      "==================================\n",
      "\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032114, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029480, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0027770, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032230, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027149, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032652, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029474, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029099, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025927, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027149, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028076, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028314, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030953, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028549, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033975, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025302, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030953, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030026, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033278, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029099, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024973, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "outputs.shape: torch.Size([32, 5])\n",
      "loss: 1.9919414520263672\n",
      "image_id, label, ohe-label: ISIC_0033346, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029480, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029891, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030026, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027598, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025628, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0033860, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025927, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032652, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028314, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028340, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025927, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0032114, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030026, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026280, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028076, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031728, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0033551, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033991, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033065, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031728, 4, tensor([0., 0., 0., 0., 1.])\n",
      "outputs.shape: torch.Size([32, 5])\n",
      "loss: 1.384078025817871\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030142, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032715, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032230, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033571, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0027770, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033551, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0031728, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0027672, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024932, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027560, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027560, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033975, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031217, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030953, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0024973, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030230, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0032652, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0033551, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0025927, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029514, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027149, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0027598, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033860, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027149, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033991, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030230, 4, tensor([0., 0., 0., 0., 1.])\n",
      "outputs.shape: torch.Size([32, 5])\n",
      "loss: 1.01431405544281\n",
      "image_id, label, ohe-label: ISIC_0027560, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031526, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030230, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027811, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033571, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0032992, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025302, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027672, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030231, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031526, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0024932, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029099, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028076, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030953, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030953, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028314, 2, tensor([0., 0., 1., 0., 0.])\n",
      "outputs.shape: torch.Size([32, 5])\n",
      "loss: 0.9826165437698364\n",
      "image_id, label, ohe-label: ISIC_0033679, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027598, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028314, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025927, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027770, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030231, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027560, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033847, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0030344, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028076, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033679, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030142, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0025628, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0029713, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0026789, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025350, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031272, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0025302, 0, tensor([1., 0., 0., 0., 0.])\n",
      "outputs.shape: torch.Size([32, 5])\n",
      "loss: 0.34899282455444336\n",
      "image_id, label, ohe-label: ISIC_0030231, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030142, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028994, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029278, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0025196, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028076, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026280, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025628, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031217, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025599, 0, tensor([1., 0., 0., 0., 0.])\n",
      "outputs.shape: torch.Size([10, 5])\n",
      "loss: 0.29143521189689636\n",
      "Validating (one image per lesion)...\n",
      "image_id, label, ohe-label: ISIC_0033305, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033305, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033305, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033490, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033490, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033490, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024991, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024991, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024991, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024937, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024937, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024937, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032410, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032410, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032410, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028735, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028735, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028735, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031498, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031498, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031498, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028930, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028930, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028930, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030956, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030956, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030956, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024867, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024867, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024867, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028739, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028739, 4, tensor([0., 0., 0., 0., 1.])\n",
      "outputs.shape: torch.Size([10, 5])\n",
      "val1_loss: 5.411742687225342\n",
      "image_id, label, ohe-label: ISIC_0028739, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029917, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029917, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029917, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0026014, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026014, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026014, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027254, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027254, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027254, 2, tensor([0., 0., 1., 0., 0.])\n",
      "outputs.shape: torch.Size([10, 5])\n",
      "val1_loss: 2.676271677017212\n",
      "Validating (all images per lesion)...\n",
      "image_id, label, ohe-label: ISIC_0034125, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0034125, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033060, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031078, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031464, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0025973, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027484, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027484, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027484, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026598, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026598, 3, tensor([0., 0., 0., 1., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id, label, ohe-label: ISIC_0026598, 3, tensor([0., 0., 0., 1., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031372, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026313, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026313, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026629, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026629, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0026629, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0030443, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031499, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0031499, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033299, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033299, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033299, 1, tensor([0., 1., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0032692, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033608, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0033969, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028680, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028680, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028680, 0, tensor([1., 0., 0., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0027058, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0027058, 4, tensor([0., 0., 0., 0., 1.])\n",
      "outputs.shape: torch.Size([10, 5])\n",
      "val_a_loss: 3.8005549907684326\n",
      "image_id, label, ohe-label: ISIC_0030114, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0026940, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0032429, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0029951, 4, tensor([0., 0., 0., 0., 1.])\n",
      "image_id, label, ohe-label: ISIC_0028816, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028816, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0028232, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024329, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024329, 2, tensor([0., 0., 1., 0., 0.])\n",
      "image_id, label, ohe-label: ISIC_0024329, 2, tensor([0., 0., 1., 0., 0.])\n",
      "outputs.shape: torch.Size([10, 5])\n",
      "val_a_loss: 3.579584836959839\n",
      "Epoch 1/1, Training Loss: 1.0022, Validation Loss 1: 4.0440, Validation Loss a: 3.6901\n",
      "Saving model.state_dict() as D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_test_1e_test_00.pth.\n",
      "model.state_dict() can now be accessed through state_dict attribute.\n",
      "Train/val losses can now be accessed through epoch_losses attribute.\n",
      "Epoch losses dictionary save as D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_test_1e_test_00_epoch_losses.json\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the specified training data by calling the train method:\n",
    "# from utils import print_header\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "print_header(\"Code test: training and validation\")\n",
    "instance.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a722d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========\n",
      "CODE TEST\n",
      "=========\n",
      "\n",
      "LOSS DICTIONARY (TRAINING AND VALIDATION LOSS FROM EACH EPOCH)\n",
      "- Key 'val1_loss' refers to validation set in which one image per lesion is used.\n",
      "- Key 'val_a_los' refers to validation set in which more than one image per lesion is potentially used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': array([1.00222969]),\n",
       " 'val1_loss': array([4.04400718]),\n",
       " 'val_a_loss': array([3.69006991])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import load_dict\n",
    "\n",
    "# Let's look at the training and validation loss for each epoch:\n",
    "instance = resnet_demo\n",
    "\n",
    "print_header(\"Code test\")\n",
    "print(\"Loss dictionary (training and validation loss from each epoch)\".upper())\n",
    "to_print = [\"- Key \\'val1_loss\\' refers to validation set in which one image per lesion is used.\",\n",
    "         \"Key \\'val_a_los\\' refers to validation set in which more than one image per lesion is potentially used.\"]\n",
    "print(\"\\n- \".join(to_print))\n",
    "\n",
    "try:\n",
    "    if instance.epoch_losses is not None:\n",
    "        display(instance.epoch_losses)\n",
    "    else:\n",
    "        retrieved_epoch_losses = load_dict(instance.model_dir, instance._filename + \"_epoch_losses\")\n",
    "        display(retrieved_epoch_losses)\n",
    "except:\n",
    "    retrieved_epoch_losses = load_dict(instance.model_dir, instance._filename + \"_epoch_losses\")\n",
    "    display(retrieved_epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36670ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========\n",
      "CODE TEST\n",
      "=========\n",
      "\n",
      "If we didn't just train the model and the epoch losses dictionary is not in memory, we can load it from a file during training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [1.0022296855847042],\n",
       " 'val1_loss': [4.044007182121277],\n",
       " 'val_a_loss': [3.6900699138641357]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import load_dict\n",
    "\n",
    "# Let's look at the training and validation loss for each epoch:\n",
    "instance = resnet_demo\n",
    "\n",
    "print_header(\"Code test\")\n",
    "print(\"If we didn't just train the model and the epoch losses dictionary is not in memory, we can load it from a file during training.\")\n",
    "\n",
    "display(load_dict(instance.model_dir, instance._filename + \"_epoch_losses\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3552fe8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "CODE TEST: MODEL ARCHITECTURE AND STATE DICTIONARY\n",
      "==================================================\n",
      "\n",
      "\n",
      "=============================\n",
      "CODE TEST: MODEL ARCHITECTURE\n",
      "=============================\n",
      "\n",
      "NOTE: 'OUT_FEATURES = 5' AT THE END\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "print_header(\"Code test: model architecture and state dictionary\")\n",
    "\n",
    "if instance.state_dict is None:\n",
    "    print(\"Loading model and state dictionary from file\\n\".upper())\n",
    "    file_path_pth = instance.model_dir.joinpath(instance._filename + \".pth\")\n",
    "\n",
    "    # model = models.efficientnet_b0()  \n",
    "    model = models.resnet18()  \n",
    "    if isinstance(model,models.ResNet):\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "    elif isinstance(model,models.EfficientNet):\n",
    "        num_ftrs = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "\n",
    "    # Load the state dictionary into the model\n",
    "    state_dict = torch.load(file_path_pth)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    instance.model = model\n",
    "    instance.state_dict = state_dict\n",
    "    \n",
    "print_header(\"Code test: model architecture\")\n",
    "print(f\"Note: \\'out_features = {len(instance.label_codes)}\\' at the end\".upper())\n",
    "display(instance.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cb6aa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================\n",
      "CODE TEST: MODEL STATE DICTIONARY\n",
      "=================================\n",
      "\n",
      "OrderedDict([('conv1.weight', tensor([[[[-9.4734e-03, -5.2116e-03, -5.9452e-04,  ...,  5.8054e-02,\n",
      "            1.8560e-02, -1.1146e-02],\n",
      "          [ 1.2014e-02,  1.0617e-02, -1.0889e-01,  ..., -2.7213e-01,\n",
      "           -1.2776e-01,  3.0430e-03],\n",
      "          [-5.9763e-03,  6.0046e-02,  2.9645e-01,  ...,  5.2089e-01,\n",
      "            2.5754e-01,  6.2821e-02],\n",
      "          ...,\n",
      "          [-2.6718e-02,  1.7227e-02,  7.3482e-02,  ..., -3.3373e-01,\n",
      "           -4.2156e-01, -2.5888e-01],\n",
      "          [ 3.1190e-02,  4.2055e-02,  6.1787e-02,  ...,  4.1287e-01,\n",
      "            3.9258e-01,  1.6504e-01],\n",
      "          [-1.3263e-02, -4.8003e-03, -2.5220e-02,  ..., -1.5196e-01,\n",
      "           -8.3439e-02, -6.6822e-03]],\n",
      "\n",
      "         [[-8.4013e-03, -2.3473e-02, -3.1329e-02,  ...,  3.3832e-02,\n",
      "            1.6109e-03, -2.4748e-02],\n",
      "          [ 4.8986e-02,  3.6950e-02, -1.0112e-01,  ..., -3.1173e-01,\n",
      "           -1.5991e-01, -2.9361e-04],\n",
      "          [ 2.3979e-03,  1.0222e-01,  4.0576e-01,  ...,  7.0861e-01,\n",
      "            3.6938e-01,  1.2 \n",
      " ... LOTS OF PARAMETERS ...\n",
      "  0.0132, 0.0151, 0.0134, 0.0147, 0.0155,\n",
      "        0.0166, 0.0160, 0.0111, 0.0156, 0.0120, 0.0179, 0.0122, 0.0137, 0.0131,\n",
      "        0.0210, 0.0190, 0.0120, 0.0112, 0.0117, 0.0210, 0.0140, 0.0150, 0.0130,\n",
      "        0.0144, 0.0116, 0.0133, 0.0130, 0.0148, 0.0176, 0.0122, 0.0147, 0.0180,\n",
      "        0.0128, 0.0159, 0.0142, 0.0127, 0.0180, 0.0190, 0.0120, 0.0133, 0.0119,\n",
      "        0.0157, 0.0108, 0.0163, 0.0157, 0.0148, 0.0192, 0.0124, 0.0158, 0.0119,\n",
      "        0.0129, 0.0122, 0.0170, 0.0148, 0.0126, 0.0140, 0.0152, 0.0149])), ('layer4.1.bn2.num_batches_tracked', tensor(6)), ('fc.weight', tensor([[-0.0061,  0.0320,  0.0349,  ...,  0.0457,  0.0054,  0.0314],\n",
      "        [-0.0107,  0.0232,  0.0213,  ..., -0.0427, -0.0203,  0.0263],\n",
      "        [ 0.0115,  0.0186, -0.0090,  ..., -0.0205, -0.0052,  0.0027],\n",
      "        [-0.0099, -0.0319, -0.0253,  ...,  0.0198,  0.0243, -0.0181],\n",
      "        [ 0.0356,  0.0135,  0.0235,  ..., -0.0354, -0.0018, -0.0093]])), ('fc.bias', tensor([-0.0153, -0.0069,  0.0127, -0.0035,  0.0213]))])\n"
     ]
    }
   ],
   "source": [
    "print_header(\"Code test: model state dictionary\")\n",
    "print(str(instance.state_dict)[:1000], \"\\n ... LOTS OF PARAMETERS ...\\n\", str(instance.state_dict)[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a9a44d31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving probabilities: D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_test_1e_test_00_val1_probabilities.csv\n",
      "Saving probabilities: D:\\projects\\skin-lesion-classification\\models\\rn18_ta_bal_test_1e_test_00_val_a_probabilities.csv\n",
      "\n",
      "===============================================================\n",
      "CODE TEST: PROBABILITIES, VALIDATION SET (ONE IMAGE PER LESION)\n",
      "===============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.909989</td>\n",
       "      <td>0.067869</td>\n",
       "      <td>0.020783</td>\n",
       "      <td>0.001012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.961752</td>\n",
       "      <td>0.013188</td>\n",
       "      <td>0.013692</td>\n",
       "      <td>0.011316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.928205</td>\n",
       "      <td>0.053561</td>\n",
       "      <td>0.013748</td>\n",
       "      <td>0.004301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.056986</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.940998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.360215</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.026391</td>\n",
       "      <td>0.611853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx  prob_other  prob_mel  prob_akiec   prob_nv  \\\n",
       "0  HAM_0003218  ISIC_0033305  bkl    0.000347  0.909989    0.067869  0.020783   \n",
       "1  HAM_0003218  ISIC_0033305  bkl    0.000052  0.961752    0.013188  0.013692   \n",
       "2  HAM_0003218  ISIC_0033305  bkl    0.000186  0.928205    0.053561  0.013748   \n",
       "3  HAM_0000983  ISIC_0033490  bkl    0.000012  0.056986    0.000047  0.001958   \n",
       "4  HAM_0000983  ISIC_0033490  bkl    0.000083  0.360215    0.001458  0.026391   \n",
       "\n",
       "   prob_bcc  \n",
       "0  0.001012  \n",
       "1  0.011316  \n",
       "2  0.004301  \n",
       "3  0.940998  \n",
       "4  0.611853  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================================\n",
      "CODE TEST: PROBABILITIES, VALIDATION SET (MORE THAN ONE IMAGE PER LESION)\n",
      "=========================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>ISIC_0034125</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.008977</td>\n",
       "      <td>0.721454</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.263809</td>\n",
       "      <td>0.000552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>ISIC_0034125</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.006242</td>\n",
       "      <td>0.664127</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.325128</td>\n",
       "      <td>0.000323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>ISIC_0033060</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.983301</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.006059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0003943</td>\n",
       "      <td>ISIC_0031078</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.004140</td>\n",
       "      <td>0.012328</td>\n",
       "      <td>0.979180</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.000604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0003943</td>\n",
       "      <td>ISIC_0031464</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.137206</td>\n",
       "      <td>0.748915</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.101236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx  prob_other  prob_mel  prob_akiec   prob_nv  \\\n",
       "0  HAM_0004406  ISIC_0034125  bkl    0.008977  0.721454    0.005207  0.263809   \n",
       "1  HAM_0004406  ISIC_0034125  bkl    0.006242  0.664127    0.004180  0.325128   \n",
       "2  HAM_0004406  ISIC_0033060  bkl    0.000041  0.983301    0.000597  0.010002   \n",
       "3  HAM_0003943  ISIC_0031078  bkl    0.004140  0.012328    0.979180  0.003748   \n",
       "4  HAM_0003943  ISIC_0031464  bkl    0.002361  0.137206    0.748915  0.010283   \n",
       "\n",
       "   prob_bcc  \n",
       "0  0.000552  \n",
       "1  0.000323  \n",
       "2  0.006059  \n",
       "3  0.000604  \n",
       "4  0.101236  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import get_probabilities\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "# model = models.efficientnet_b0()  \n",
    "# model = models.resnet18() \n",
    "# if isinstance(model,models.ResNet):\n",
    "#     num_ftrs = model.fc.in_features\n",
    "#     model.fc = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "# elif isinstance(model,models.EfficientNet):\n",
    "#     num_ftrs = model.classifier[1].in_features\n",
    "#     model.classifier[1] = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "\n",
    "instance.df_probabilities_val1 = get_probabilities(df=instance.df_val1,\n",
    "                                                   data_dir=instance.data_dir,\n",
    "                                                   model_dir=instance.model_dir,\n",
    "                                                   model=instance.model,\n",
    "                                                   filename=instance._filename,\n",
    "                                                   label_codes=instance.label_codes,\n",
    "                                                   transform=instance.transform,\n",
    "                                                   batch_size=instance.batch_size,\n",
    "                                                   Print=False,\n",
    "                                                   save_as=instance._filename + \"_val1\",)\n",
    "\n",
    "instance.df_probabilities_val_a = get_probabilities(df=instance.df_val_a,\n",
    "                                                    data_dir=instance.data_dir,\n",
    "                                                    model_dir=instance.model_dir,\n",
    "                                                    model=instance.model,\n",
    "                                                    filename=instance._filename,\n",
    "                                                    label_codes=instance.label_codes,\n",
    "                                                    transform=instance.transform,\n",
    "                                                    batch_size=instance.batch_size,\n",
    "                                                    Print=False,\n",
    "                                                    save_as=instance._filename + \"_val_a\",)\n",
    "\n",
    "print_header(\"Code test: probabilities, validation set (one image per lesion)\")\n",
    "display_columns = ['lesion_id', 'image_id', 'dx'] + [col for col in instance.df_probabilities_val1.columns if col.startswith('prob')]\n",
    "display(instance.df_probabilities_val1[display_columns].head())\n",
    "\n",
    "print_header(\"Code test: probabilities, validation set (more than one image per lesion)\")\n",
    "display(instance.df_probabilities_val_a[display_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa486a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================================\n",
      "CODE TEST: PREDICTION ON INDIVIDUAL IMAGES OR LESIONS\n",
      "=====================================================\n",
      "\n",
      "- We can make predictions for individual images or lesions.\n",
      "- We only require a dataframe with an 'image_id' column.\n",
      "- Given the filename of an image, the df_from_ids function will construct such a dataframe.\n",
      "- We can then feed this dataframe into the get_probabilities function.\n",
      "- Here is the result of passing 'filenames = ['ISIC_0033305','ISIC_0025661']' to df_from_ids:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0033305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0025661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id\n",
       "0  ISIC_0033305\n",
       "1  ISIC_0025661"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- And here are the corresponding probabilities:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.924487</td>\n",
       "      <td>0.031356</td>\n",
       "      <td>0.031861</td>\n",
       "      <td>0.011903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.351872</td>\n",
       "      <td>0.417792</td>\n",
       "      <td>0.158065</td>\n",
       "      <td>0.069817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  prob_other  prob_mel  prob_akiec   prob_nv  prob_bcc\n",
       "0  ISIC_0033305    0.000393  0.924487    0.031356  0.031861  0.011903\n",
       "1  ISIC_0025661    0.002455  0.351872    0.417792  0.158065  0.069817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- If we have a lesion_id with associated image_ids, we can also construct a small dataframe.\n",
      "- The df_from_ids function also takes arguments for the number of predictions we want to make for a given image/lesion.\n",
      "- Here is the result of passing 'lesion_ids = 'HAM_0000118', 'multiplicity = 3', and 'one_img_per_lesion = False' to df_from_ids:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id\n",
       "0  HAM_0000118  ISIC_0027419\n",
       "1  HAM_0000118  ISIC_0025030\n",
       "2  HAM_0000118  ISIC_0025030"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- We have filtered all columns except for lesion_id and image_id (knowing the diagnosis defeats the purpose).\n",
      "- Here are the associated probabilities:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.942904</td>\n",
       "      <td>0.035084</td>\n",
       "      <td>0.019931</td>\n",
       "      <td>0.001834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.982403</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.013661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.911008</td>\n",
       "      <td>0.043588</td>\n",
       "      <td>0.010123</td>\n",
       "      <td>0.035194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id  prob_other  prob_mel  prob_akiec   prob_nv  \\\n",
       "0  HAM_0000118  ISIC_0027419    0.000247  0.942904    0.035084  0.019931   \n",
       "1  HAM_0000118  ISIC_0025030    0.000034  0.982403    0.000663  0.003238   \n",
       "2  HAM_0000118  ISIC_0025030    0.000087  0.911008    0.043588  0.010123   \n",
       "\n",
       "   prob_bcc  \n",
       "0  0.001834  \n",
       "1  0.013661  \n",
       "2  0.035194  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Notice that the probabilities may vary with each execution of a prediction.\n",
      "- This is because a random transformation may be applied to each image before our model makes a prediction on it.\n"
     ]
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import df_from_ids, get_probabilities     \n",
    "\n",
    "instance = resnet_demo\n",
    "df = instance.df\n",
    "\n",
    "print_header(\"Code test: prediction on individual images or lesions\")\n",
    "\n",
    "to_print = [\"- We can make predictions for individual images or lesions.\",\n",
    "            \"We only require a dataframe with an \\'image_id\\' column.\",\n",
    "            \"Given the filename of an image, the df_from_ids function will construct such a dataframe.\",\n",
    "            \"We can then feed this dataframe into the get_probabilities function.\",\n",
    "            \"Here is the result of passing \\'filenames = [\\'ISIC_0033305\\',\\'ISIC_0025661\\']\\' to df_from_ids:\",\n",
    "            \"- And here are the corresponding probabilities:\",\n",
    "            \"- If we have a lesion_id with associated image_ids, we can also construct a small dataframe.\",\n",
    "            \"The df_from_ids function also takes arguments for the number of predictions we want to make for a given image/lesion.\",\n",
    "            \"Here is the result of passing \\'lesion_ids = \\'HAM_0000118\\', \\'multiplicity = 3\\', and \\'one_img_per_lesion = False\\' to df_from_ids:\",\n",
    "            \"- We have filtered all columns except for lesion_id and image_id (knowing the diagnosis defeats the purpose).\",\n",
    "            \"- Here are the associated probabilities:\",\n",
    "            \"- Notice that the probabilities may vary with each execution of a prediction.\",\n",
    "            \"This is because a random transformation may be applied to each image before our model makes a prediction on it.\"]\n",
    "\n",
    "df_2img = df_from_ids(filenames=['ISIC_0033305','ISIC_0025661'], # can be a string or a list of strings\n",
    "                       multiplicity=None,\n",
    "                       lesion_ids=None,\n",
    "                       df=df,\n",
    "                       one_img_per_lesion=None,)\n",
    "\n",
    "print(\"\\n- \".join(to_print[:5]))\n",
    "\n",
    "display(df_2img)\n",
    "\n",
    "df_2img_prob = get_probabilities(df=df_2img,\n",
    "                  data_dir=instance.data_dir,\n",
    "                  model_dir=instance.model_dir,\n",
    "                  model=instance.model,\n",
    "                  filename=instance._filename,\n",
    "                  label_codes=instance.label_codes,\n",
    "                  transform=instance.transform,\n",
    "                  batch_size=instance.batch_size,\n",
    "                  Print=False,\n",
    "                  save_as=None,)   \n",
    "\n",
    "print(to_print[5])\n",
    "display(df_2img_prob)\n",
    "\n",
    "print(\"\\n- \".join(to_print[6:9]))\n",
    "\n",
    "df_1les = df_from_ids(filenames=None,\n",
    "                       multiplicity=3,\n",
    "                       lesion_ids='HAM_0000118', # can be a string or a list of strings\n",
    "                       df=df,\n",
    "                       one_img_per_lesion=False,)\n",
    "\n",
    "display_columns = ['lesion_id', 'image_id'] \n",
    "display(df_1les[display_columns])\n",
    "\n",
    "print(\"\\n- \".join(to_print[9:10]))\n",
    "\n",
    "df_1les_prob = get_probabilities(df=df_1les,\n",
    "                  data_dir=instance.data_dir,\n",
    "                  model_dir=instance.model_dir,\n",
    "                  model=instance.model,\n",
    "                  filename=instance._filename,\n",
    "                  label_codes=instance.label_codes,\n",
    "                  transform=instance.transform,\n",
    "                  batch_size=instance.batch_size,\n",
    "                  Print=False,\n",
    "                  save_as=None,)   \n",
    "\n",
    "print(to_print[10])\n",
    "display_columns = ['lesion_id', 'image_id'] + [col for col in df_1les_prob if col.startswith('prob')]\n",
    "display(df_1les_prob[display_columns])\n",
    "\n",
    "print(\"\\n- \".join(to_print[11:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4874092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's another example of how we'd use df_from_ids on an arbitrary image from outside our dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_from_somewhere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_from_somewhere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_from_somewhere</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               image_id\n",
       "0  image_from_somewhere\n",
       "1  image_from_somewhere\n",
       "2  image_from_somewhere"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If it were an actual image in the data_dir folder, we could feed this dataframe into the get_probabilities function.\n"
     ]
    }
   ],
   "source": [
    "print(\"Here's another example of how we'd use df_from_ids on an arbitrary image from outside our dataset.\")\n",
    "\n",
    "display(df_from_ids(filenames='image_from_somewhere', multiplicity=3,))\n",
    "\n",
    "print(\"If it were an actual image in the data_dir folder, we could feed this dataframe into the get_probabilities function.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9ca4f9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.942904</td>\n",
       "      <td>0.035084</td>\n",
       "      <td>0.019931</td>\n",
       "      <td>0.001834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.982403</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.013661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.911008</td>\n",
       "      <td>0.043588</td>\n",
       "      <td>0.010123</td>\n",
       "      <td>0.035194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  num_images      image_id   dx  label dx_type   age   sex  \\\n",
       "0  HAM_0000118           2  ISIC_0027419  bkl      0   histo  80.0  male   \n",
       "1  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "2  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "\n",
       "  localization set  prob_other  prob_mel  prob_akiec   prob_nv  prob_bcc  \n",
       "0        scalp  ta    0.000247  0.942904    0.035084  0.019931  0.001834  \n",
       "1        scalp  t1    0.000034  0.982403    0.000663  0.003238  0.013661  \n",
       "2        scalp  t1    0.000087  0.911008    0.043588  0.010123  0.035194  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.982403</td>\n",
       "      <td>0.035084</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.001834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.982403</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.013661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.982403</td>\n",
       "      <td>0.043588</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.035194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  num_images      image_id   dx  label dx_type   age   sex  \\\n",
       "0  HAM_0000118           2  ISIC_0027419  bkl      0   histo  80.0  male   \n",
       "1  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "2  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "\n",
       "  localization set  prob_other  prob_mel  prob_akiec   prob_nv  prob_bcc  \n",
       "0        scalp  ta    0.000247  0.982403    0.035084  0.003238  0.001834  \n",
       "1        scalp  t1    0.000034  0.982403    0.000663  0.003238  0.013661  \n",
       "2        scalp  t1    0.000087  0.982403    0.043588  0.003238  0.035194  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.924487</td>\n",
       "      <td>0.031356</td>\n",
       "      <td>0.031861</td>\n",
       "      <td>0.011903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.351872</td>\n",
       "      <td>0.417792</td>\n",
       "      <td>0.158065</td>\n",
       "      <td>0.069817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  prob_other  prob_mel  prob_akiec   prob_nv  prob_bcc\n",
       "0  ISIC_0033305    0.000393  0.924487    0.031356  0.031861  0.011903\n",
       "1  ISIC_0025661    0.002455  0.351872    0.417792  0.158065  0.069817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.924487</td>\n",
       "      <td>0.031356</td>\n",
       "      <td>0.031861</td>\n",
       "      <td>0.011903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.351872</td>\n",
       "      <td>0.417792</td>\n",
       "      <td>0.158065</td>\n",
       "      <td>0.069817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  prob_other  prob_mel  prob_akiec   prob_nv  prob_bcc\n",
       "0  ISIC_0033305    0.000393  0.924487    0.031356  0.031861  0.011903\n",
       "1  ISIC_0025661    0.002455  0.351872    0.417792  0.158065  0.069817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from multiclass_models import aggregate_probabilities\n",
    "\n",
    "method = { 'max' : ['mel'], 'min' : ['nv'],}\n",
    "display(df_1les_prob)\n",
    "display(aggregate_probabilities(df_1les_prob, method=method))\n",
    "\n",
    "display(df_2img_prob)\n",
    "display(aggregate_probabilities(df_2img_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "98f667cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can reload the probabilities dataframes from csv files saved earlier, if they are not already in memory\n",
    "file_path_val1 = instance.model_dir.joinpath(instance._filename + \"_val1_probabilities.csv\")\n",
    "file_path_val_a = instance.model_dir.joinpath(instance._filename + \"_val_a_probabilities.csv\")\n",
    "instance.df_val1_probabilities = pd.read_csv(file_path_val1,index_col=0)\n",
    "instance.df_val_a_probabilities = pd.read_csv(file_path_val_a,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d8657487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================\n",
      "CODE TEST: COMBINING PROBABILITIES AND MAKING PREDICTIONS\n",
      "=========================================================\n",
      "\n",
      "VALIDATION SET: ONE IMAGE PER LESION, REPEATED 3 TIMES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.909989</td>\n",
       "      <td>0.067869</td>\n",
       "      <td>0.020783</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.961752</td>\n",
       "      <td>0.013188</td>\n",
       "      <td>0.013692</td>\n",
       "      <td>0.011316</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033305</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.928205</td>\n",
       "      <td>0.053561</td>\n",
       "      <td>0.013748</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.056986</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.940998</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0033490</td>\n",
       "      <td>3</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>consensus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.360215</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.026391</td>\n",
       "      <td>0.611853</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  lesion_mult  num_images      image_id  img_mult   dx  label  \\\n",
       "0  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "1  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "2  HAM_0003218            3           1  ISIC_0033305         3  bkl      0   \n",
       "3  HAM_0000983            3           1  ISIC_0033490         3  bkl      0   \n",
       "4  HAM_0000983            3           1  ISIC_0033490         3  bkl      0   \n",
       "\n",
       "     dx_type   age      sex localization set  prob_other  prob_mel  \\\n",
       "0  consensus  75.0     male         back  v1    0.000347  0.909989   \n",
       "1  consensus  75.0     male         back  v1    0.000052  0.961752   \n",
       "2  consensus  75.0     male         back  v1    0.000186  0.928205   \n",
       "3  consensus   NaN  unknown      unknown  v1    0.000012  0.056986   \n",
       "4  consensus   NaN  unknown      unknown  v1    0.000083  0.360215   \n",
       "\n",
       "   prob_akiec   prob_nv  prob_bcc  pred  pred_final  \n",
       "0    0.067869  0.020783  0.001012     1           1  \n",
       "1    0.013188  0.013692  0.011316     1           1  \n",
       "2    0.053561  0.013748  0.004301     1           1  \n",
       "3    0.000047  0.001958  0.940998     4           4  \n",
       "4    0.001458  0.026391  0.611853     4           4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALIDATION SET: 3 IMAGES PER LESION, USING ALL IMAGES BEFORE REPEATING\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>lesion_mult</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>img_mult</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0034125</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>va</td>\n",
       "      <td>0.008977</td>\n",
       "      <td>0.721454</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.263809</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0034125</td>\n",
       "      <td>2</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>va</td>\n",
       "      <td>0.006242</td>\n",
       "      <td>0.664127</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.325128</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0033060</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.983301</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.006059</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0003943</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0031078</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>va</td>\n",
       "      <td>0.004140</td>\n",
       "      <td>0.012328</td>\n",
       "      <td>0.979180</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0003943</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0031464</td>\n",
       "      <td>1</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.137206</td>\n",
       "      <td>0.748915</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.101236</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  lesion_mult  num_images      image_id  img_mult   dx  label  \\\n",
       "0  HAM_0004406            3           2  ISIC_0034125         2  bkl      0   \n",
       "1  HAM_0004406            3           2  ISIC_0034125         2  bkl      0   \n",
       "2  HAM_0004406            3           2  ISIC_0033060         1  bkl      0   \n",
       "3  HAM_0003943            3           3  ISIC_0031078         1  bkl      0   \n",
       "4  HAM_0003943            3           3  ISIC_0031464         1  bkl      0   \n",
       "\n",
       "  dx_type   age     sex     localization set  prob_other  prob_mel  \\\n",
       "0   histo  80.0    male             back  va    0.008977  0.721454   \n",
       "1   histo  80.0    male             back  va    0.006242  0.664127   \n",
       "2   histo  80.0    male             back  v1    0.000041  0.983301   \n",
       "3   histo  80.0  female  lower extremity  va    0.004140  0.012328   \n",
       "4   histo  80.0  female  lower extremity  v1    0.002361  0.137206   \n",
       "\n",
       "   prob_akiec   prob_nv  prob_bcc  pred  pred_final  \n",
       "0    0.005207  0.263809  0.000552     1           1  \n",
       "1    0.004180  0.325128  0.000323     1           1  \n",
       "2    0.000597  0.010002  0.006059     1           1  \n",
       "3    0.979180  0.003748  0.000604     2           2  \n",
       "4    0.748915  0.010283  0.101236     2           2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NOW WE SIMPLY DROP DUPLICATES (LESION_ID)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>label</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0003218</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000983</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HAM_0003267</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HAM_0006318</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HAM_0005518</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HAM_0005663</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HAM_0001953</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HAM_0002591</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HAM_0005713</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>HAM_0007568</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HAM_0007313</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>HAM_0007364</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>HAM_0002882</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>HAM_0003949</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lesion_id  label  pred_final\n",
       "0   HAM_0003218      0           1\n",
       "3   HAM_0000983      0           4\n",
       "6   HAM_0003267      3           0\n",
       "9   HAM_0006318      3           1\n",
       "12  HAM_0005518      0           1\n",
       "15  HAM_0005663      0           1\n",
       "18  HAM_0001953      1           1\n",
       "21  HAM_0002591      1           4\n",
       "24  HAM_0005713      0           1\n",
       "27  HAM_0007568      0           0\n",
       "30  HAM_0007313      4           3\n",
       "33  HAM_0007364      4           4\n",
       "36  HAM_0002882      2           4\n",
       "39  HAM_0003949      2           4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>label</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0004406</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0003943</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HAM_0001756</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HAM_0006602</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HAM_0007418</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HAM_0004065</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HAM_0006722</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HAM_0000107</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HAM_0000940</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>HAM_0007150</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HAM_0005998</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>HAM_0005973</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>HAM_0003123</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>HAM_0002954</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lesion_id  label  pred_final\n",
       "0   HAM_0004406      0           1\n",
       "3   HAM_0003943      0           2\n",
       "6   HAM_0001756      3           0\n",
       "9   HAM_0006602      3           0\n",
       "12  HAM_0007418      0           1\n",
       "15  HAM_0004065      0           1\n",
       "18  HAM_0006722      1           4\n",
       "21  HAM_0000107      1           2\n",
       "24  HAM_0000940      0           1\n",
       "27  HAM_0007150      0           1\n",
       "30  HAM_0005998      4           1\n",
       "33  HAM_0005973      4           1\n",
       "36  HAM_0003123      2           1\n",
       "39  HAM_0002954      2           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from multiclass_models import final_prediction\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List\n",
    "\n",
    "instance = resnet_demo\n",
    "\n",
    "raw_probabilities_df1: pd.DataFrame = instance.df_probabilities_val1 \n",
    "raw_probabilities_df_a: pd.DataFrame = instance.df_probabilities_val_a\n",
    "aggregate_method: Union[None, Dict[str, List[str]]] = { 'max' : ['mel'], 'min' : ['nv'], 'mean' : ['bcc']}\n",
    "threshold_dict_help: Union[None, OrderedDict[str, float]] = OrderedDict([('mel',0.4), ('bcc',0.45)])\n",
    "threshold_dict_hinder: Union[None, OrderedDict[str, float]] = OrderedDict([('nv',0.6)])    \n",
    "votes_to_win_dict: Union[None, OrderedDict[str, int]] = OrderedDict([('mel',1)])\n",
    "label_codes: Dict[int, str] = instance.label_codes\n",
    "prefix: Union[None, str] = 'prob_'\n",
    "\n",
    "print_header(\"Code test: combining probabilities and making predictions\")\n",
    "\n",
    "print(f\"Validation set: one image per lesion, repeated {instance.source.val_expansion_factor} times\".upper())\n",
    "\n",
    "instance.df_pred_val1 = final_prediction(raw_probabilities_df=raw_probabilities_df1, \n",
    "                                         threshold_dict_help=threshold_dict_help,\n",
    "                                         threshold_dict_hinder=threshold_dict_hinder,\n",
    "                                         votes_to_win_dict=votes_to_win_dict,\n",
    "                                         label_codes=label_codes,)\n",
    "\n",
    "display(instance.df_pred_val1.head())\n",
    "\n",
    "print(f\"\\nValidation set: {instance.source.val_expansion_factor} images per lesion, using all images before repeating\".upper())\n",
    "\n",
    "instance.df_pred_val_a = final_prediction(raw_probabilities_df=raw_probabilities_df_a, \n",
    "                                         threshold_dict_help=threshold_dict_help,\n",
    "                                         threshold_dict_hinder=threshold_dict_hinder,\n",
    "                                         votes_to_win_dict=votes_to_win_dict,\n",
    "                                         label_codes=label_codes,)\n",
    "\n",
    "display(instance.df_pred_val_a.head())\n",
    "\n",
    "print(\"\\nNow we simply drop duplicates (lesion_id)...\".upper())\n",
    "\n",
    "display(instance.df_pred_val1.drop_duplicates(subset='lesion_id')[['lesion_id','label','pred_final']])\n",
    "\n",
    "display(instance.df_pred_val_a.drop_duplicates(subset='lesion_id')[['lesion_id','label','pred_final']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f4b7817e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'multiclass_models' from 'D:\\\\projects\\\\skin-lesion-classification\\\\scripts\\\\multiclass_models.py'>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import multiclass_models\n",
    "\n",
    "importlib.reload(multiclass_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3b8844a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================\n",
      "CODE TEST: CONFUSION MATRIX (VALIDATION SET)\n",
      "============================================\n",
      "\n",
      "- The overall evaluation metric would appear at the bottom right, if it were defined (this code test set is too small).\n",
      "- It would be a class-wise weighted average fbeta score, beta and weights as specified (default values 1).\n",
      "- One could also pass None, a float, or a function other than weighted_average_f to the func parameter in confusion_matrix_with_metric.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>mel</th>\n",
       "      <th>bcc</th>\n",
       "      <th>nv</th>\n",
       "      <th>akiec</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted other  mel       bcc   nv     akiec All    recall\n",
       "actual                                                     \n",
       "other         3    1         2    2         1   9  0.333333\n",
       "mel           0    0         2    0         1   3       0.0\n",
       "bcc           0    0         3    0         0   3       1.0\n",
       "nv            1    1         1    0         0   3       0.0\n",
       "akiec         0    1         1    0         1   3  0.333333\n",
       "All           4    3         9    2         3  21         _\n",
       "precision  0.75  0.0  0.333333  0.0  0.333333   _         _"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from evaluation import weighted_average_f, confusion_matrix_with_metric\n",
    "\n",
    "instance = resnet18mc_test\n",
    "map_labels = instance.label_codes\n",
    "\n",
    "A = instance._predictions_df_val['label']\n",
    "B = instance._predictions_df_val['pred']\n",
    "AxB = pd.crosstab(A,B,margins=True,dropna=False)\n",
    "\n",
    "beta = 1\n",
    "weights = None\n",
    "\n",
    "instance._cm = confusion_matrix_with_metric(AxB=AxB,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "print_header(\"Code test: confusion matrix (validation set)\")\n",
    "\n",
    "to_print = [\"- The overall evaluation metric would appear at the bottom right, if it were defined (this code test set is too small).\",\n",
    "            \"It would be a class-wise weighted average fbeta score, beta and weights as specified (default values 1).\",\n",
    "            \"One could also pass None, a float, or a function other than weighted_average_f to the func parameter in confusion_matrix_with_metric.\"]\n",
    "print(\"\\n- \".join(to_print))\n",
    "display(instance._cm.fillna('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b0a5ae88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "CODE TEST: OTHER METRICS\n",
      "========================\n",
      "\n",
      "- ACC: accuracy\n",
      "- BACC: balanced accuracy\n",
      "- precision: macro-averaged precision (equal weight to each class)\n",
      "- recal: macro-averaged recall (equal weight to each class)\n",
      "- Fbeta: macro-averaged F_beta score (equal weight to each class)\n",
      "- MCC: Matthews correlation coefficient\n",
      "- ROC-AUC mac: macro-averaged ROC-AUC (equal weight to each class)\n",
      "- ROC-AUC wt: weighted-average ROC-AUC (larger class -> more weight)\n",
      "- ROC-AUC wt*: weighted-average ROC-AUC (larger class -> *less weight)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.350072</td>\n",
       "      <td>0.346472</td>\n",
       "      <td>0.350072</td>\n",
       "      <td>0.283516</td>\n",
       "      <td>0.271494</td>\n",
       "      <td>0.298296</td>\n",
       "      <td>0.158465</td>\n",
       "      <td>0.722044</td>\n",
       "      <td>0.72177</td>\n",
       "      <td>0.726919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC      BACC  precision    recall      F1/2        F1        F2  \\\n",
       "0  0.277778  0.350072   0.346472  0.350072  0.283516  0.271494  0.298296   \n",
       "\n",
       "        MCC  ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0  0.158465     0.722044     0.72177     0.726919  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from evaluation import metric_dictionary\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "instance = resnet18mc_test\n",
    "\n",
    "target = instance._predictions_df['label'] \n",
    "prediction = instance._predictions_df['pred'] \n",
    "probabilities = instance._predictions_df.filter(regex=r'^prob_')\n",
    "\n",
    "# target = pd.concat([target_, pd.Series([1,2])])\n",
    "# target = target.reset_index(drop=True)\n",
    "# prediction = pd.concat([prediction_, pd.Series([0,2])]) \n",
    "# prediction = prediction.reset_index(drop=True)\n",
    "# probabilities = probabilities_.copy()\n",
    "# probabilities.loc[16] = 0.2\n",
    "# probabilities.loc[17] = 0.2\n",
    "# probabilities = probabilities.values\n",
    "\n",
    "print_header(\"Code test: other metrics\")\n",
    "to_print = [\"- ACC: accuracy\",\n",
    "            \"BACC: balanced accuracy\",\n",
    "            \"precision: macro-averaged precision (equal weight to each class)\",\n",
    "            \"recal: macro-averaged recall (equal weight to each class)\",\n",
    "            \"Fbeta: macro-averaged F_beta score (equal weight to each class)\",\n",
    "            \"MCC: Matthews correlation coefficient\",\n",
    "            \"ROC-AUC mac: macro-averaged ROC-AUC (equal weight to each class)\",\n",
    "            \"ROC-AUC wt: weighted-average ROC-AUC (larger class -> more weight)\",\n",
    "            \"ROC-AUC wt*: weighted-average ROC-AUC (larger class -> *less weight)\",            \n",
    "            ]\n",
    "\n",
    "instance._metric_dict = metric_dictionary(target=target, \n",
    "                                          prediction=prediction, \n",
    "                                          probabilities=probabilities)\n",
    "print(\"\\n- \".join(to_print))\n",
    "display(pd.DataFrame(instance._metric_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104706f1",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "343159ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    \n",
    "transforms.RandomCrop((300, 300)),\n",
    "transforms.Resize((224,224)), # Resize images to fit ResNet input size\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet stats\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98981d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from typing import List, Callable\n",
    "\n",
    "df: pd.DataFrame = metadata.df                   # Background dataset for the model. metadata._df_sample_batch is a random selection of 64 rows of metadata.df. We use it for testing our code.\n",
    "train_set: Union[pd.DataFrame, list, str] = \"t1\" # \"t1\" (one image per lesion in training set); [\"t1\", \"ta\"] (all images for each lesion in training set); can also specify another sub-dataframe of self.df.\n",
    "val_set: Union[pd.DataFrame, list, str] = \"v1\"   # Similar to train_set above.\n",
    "label_codes: dict = metadata._label_codes        # Correspondence between label codes like 0 and label words like 'other'.\n",
    "data_dir: Path = path[\"images\"]                  # Path to directory where images are stored.\n",
    "model_dir: Path = path[\"models\"]                 # Path to directory where models/model info/model results are stored.\n",
    "transform: List[Callable] = transform            # Transform to be applied to images before feeding to ResNet-18\n",
    "batch_size: int = 32                             # Mini-batch size: default 32.\n",
    "epochs: int = 10                                 # Number of epochs (all layers unfrozen from the start): default 10.\n",
    "base_learning_rate: float = 0.001                # Learning rate to start with: default 0.001. Using Adam optimizer.\n",
    "filename_stem: str = \"rn18mc\"                    # For saving model and related files. train set and num epochs will be appended automatically. Default \"rn18mc\".\n",
    "filename_suffix: str = \"base\"                    # Something descriptive and unique for future reference and to avoid over-writing other files. Default empty string \"\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f407e3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18mc_base = resnet18(                                  \n",
    "    df=df, \n",
    "    train_set=train_set,\n",
    "    val_set=val_set,\n",
    "    label_codes=label_codes,\n",
    "    data_dir=data_dir,\n",
    "    model_dir=model_dir,\n",
    "    transform=transform,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,                                                \n",
    "    base_learning_rate=base_learning_rate,\n",
    "    filename_stem=filename_stem,\n",
    "    filename_suffix=filename_suffix,                                  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd97d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only need to do this once...\n",
    "# resnet18mc_base.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "913c5953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'evaluation' from 'D:\\\\projects\\\\skin-lesion-classification\\\\scripts\\\\evaluation.py'>"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "del instance._inference_df\n",
    "import evaluation\n",
    "\n",
    "importlib.reload(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "ca805556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================\n",
      "BASELINE MODEL: PROBABILITIES FOR ALL IMAGES\n",
      "============================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.190499</td>\n",
       "      <td>0.589043</td>\n",
       "      <td>0.070307</td>\n",
       "      <td>0.127727</td>\n",
       "      <td>0.022423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.325244</td>\n",
       "      <td>0.116826</td>\n",
       "      <td>0.034226</td>\n",
       "      <td>0.438181</td>\n",
       "      <td>0.085523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>va</td>\n",
       "      <td>0.025946</td>\n",
       "      <td>0.010540</td>\n",
       "      <td>0.299041</td>\n",
       "      <td>0.045798</td>\n",
       "      <td>0.618675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.039586</td>\n",
       "      <td>0.041373</td>\n",
       "      <td>0.251411</td>\n",
       "      <td>0.027629</td>\n",
       "      <td>0.640001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>va</td>\n",
       "      <td>0.110923</td>\n",
       "      <td>0.402103</td>\n",
       "      <td>0.215037</td>\n",
       "      <td>0.059775</td>\n",
       "      <td>0.212162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  num_images      image_id   dx  label dx_type   age   sex  \\\n",
       "0  HAM_0000118           2  ISIC_0027419  bkl      0   histo  80.0  male   \n",
       "1  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "2  HAM_0002730           2  ISIC_0026769  bkl      0   histo  80.0  male   \n",
       "3  HAM_0002730           2  ISIC_0025661  bkl      0   histo  80.0  male   \n",
       "4  HAM_0001466           2  ISIC_0031633  bkl      0   histo  75.0  male   \n",
       "\n",
       "  localization set  prob_other  prob_mel  prob_akiec   prob_nv  prob_bcc  \n",
       "0        scalp  ta    0.190499  0.589043    0.070307  0.127727  0.022423  \n",
       "1        scalp  t1    0.325244  0.116826    0.034226  0.438181  0.085523  \n",
       "2        scalp  va    0.025946  0.010540    0.299041  0.045798  0.618675  \n",
       "3        scalp  v1    0.039586  0.041373    0.251411  0.027629  0.640001  \n",
       "4          ear  va    0.110923  0.402103    0.215037  0.059775  0.212162  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BASELINE MODEL: PROBABILITIES AND PREDICTIONS FOR ALL IMAGES\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>ta</td>\n",
       "      <td>0.190499</td>\n",
       "      <td>0.589043</td>\n",
       "      <td>0.070307</td>\n",
       "      <td>0.127727</td>\n",
       "      <td>0.022423</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.325244</td>\n",
       "      <td>0.116826</td>\n",
       "      <td>0.034226</td>\n",
       "      <td>0.438181</td>\n",
       "      <td>0.085523</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>va</td>\n",
       "      <td>0.025946</td>\n",
       "      <td>0.010540</td>\n",
       "      <td>0.299041</td>\n",
       "      <td>0.045798</td>\n",
       "      <td>0.618675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.039586</td>\n",
       "      <td>0.041373</td>\n",
       "      <td>0.251411</td>\n",
       "      <td>0.027629</td>\n",
       "      <td>0.640001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>va</td>\n",
       "      <td>0.110923</td>\n",
       "      <td>0.402103</td>\n",
       "      <td>0.215037</td>\n",
       "      <td>0.059775</td>\n",
       "      <td>0.212162</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  num_images      image_id   dx  label dx_type   age   sex  \\\n",
       "0  HAM_0000118           2  ISIC_0027419  bkl      0   histo  80.0  male   \n",
       "1  HAM_0000118           2  ISIC_0025030  bkl      0   histo  80.0  male   \n",
       "2  HAM_0002730           2  ISIC_0026769  bkl      0   histo  80.0  male   \n",
       "3  HAM_0002730           2  ISIC_0025661  bkl      0   histo  80.0  male   \n",
       "4  HAM_0001466           2  ISIC_0031633  bkl      0   histo  75.0  male   \n",
       "\n",
       "  localization set  prob_other  prob_mel  prob_akiec   prob_nv  prob_bcc  pred  \n",
       "0        scalp  ta    0.190499  0.589043    0.070307  0.127727  0.022423     2  \n",
       "1        scalp  t1    0.325244  0.116826    0.034226  0.438181  0.085523     4  \n",
       "2        scalp  va    0.025946  0.010540    0.299041  0.045798  0.618675     1  \n",
       "3        scalp  v1    0.039586  0.041373    0.251411  0.027629  0.640001     1  \n",
       "4          ear  va    0.110923  0.402103    0.215037  0.059775  0.212162     2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================\n",
      "BASELINE MODEL: PROBABILITIES AND PREDICTIONS FOR IMAGES IN VALIDATION SET\n",
      "==========================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_akiec</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>prob_bcc</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.039586</td>\n",
       "      <td>0.041373</td>\n",
       "      <td>0.251411</td>\n",
       "      <td>0.027629</td>\n",
       "      <td>0.640001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0027850</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.118692</td>\n",
       "      <td>0.143967</td>\n",
       "      <td>0.113587</td>\n",
       "      <td>0.164686</td>\n",
       "      <td>0.459067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HAM_0002761</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0029068</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.041351</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.025426</td>\n",
       "      <td>0.131957</td>\n",
       "      <td>0.798437</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HAM_0004234</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0029396</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.045510</td>\n",
       "      <td>0.151270</td>\n",
       "      <td>0.007371</td>\n",
       "      <td>0.789996</td>\n",
       "      <td>0.005853</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HAM_0001949</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0025767</td>\n",
       "      <td>bkl</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>trunk</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.712821</td>\n",
       "      <td>0.006769</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.272685</td>\n",
       "      <td>0.006774</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lesion_id  num_images      image_id   dx  label dx_type   age     sex  \\\n",
       "3   HAM_0002730           2  ISIC_0025661  bkl      0   histo  80.0    male   \n",
       "5   HAM_0001466           2  ISIC_0027850  bkl      0   histo  75.0    male   \n",
       "7   HAM_0002761           2  ISIC_0029068  bkl      0   histo  60.0    male   \n",
       "11  HAM_0004234           2  ISIC_0029396  bkl      0   histo  85.0  female   \n",
       "13  HAM_0001949           2  ISIC_0025767  bkl      0   histo  70.0    male   \n",
       "\n",
       "   localization set  prob_other  prob_mel  prob_akiec   prob_nv  prob_bcc  \\\n",
       "3         scalp  v1    0.039586  0.041373    0.251411  0.027629  0.640001   \n",
       "5           ear  v1    0.118692  0.143967    0.113587  0.164686  0.459067   \n",
       "7          face  v1    0.041351  0.002828    0.025426  0.131957  0.798437   \n",
       "11        chest  v1    0.045510  0.151270    0.007371  0.789996  0.005853   \n",
       "13        trunk  v1    0.712821  0.006769    0.000950  0.272685  0.006774   \n",
       "\n",
       "    pred  \n",
       "3      1  \n",
       "5      1  \n",
       "7      1  \n",
       "11     4  \n",
       "13     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from evaluation import get_argmax, append_prediction, get_probabilities_df\n",
    "\n",
    "instance = resnet18mc_base\n",
    "\n",
    "# try:\n",
    "#     instance._inference_df = df_with_probabilities(instance)\n",
    "# except:\n",
    "filename = \"rn18mc_t1_10e_base_inference.csv\" #instance._filename + \"_infer.csv\" # \"rn18mc_t1_10e_base_inference.csv\"\n",
    "file_path_csv = instance.model_dir.joinpath(filename)\n",
    "instance._inference_df = df_with_probabilities(file_path_csv)\n",
    "instance._inference_df = pd.merge(instance.df, instance._inference_df, on='image_id', how='inner')\n",
    "\n",
    "print_header(\"Baseline model: probabilities for all images\".upper())\n",
    "\n",
    "display(instance._inference_df.head())\n",
    "\n",
    "inverse_label_codes = {value: key for key, value in instance.label_codes.items()}\n",
    "\n",
    "print_header(\"Baseline model: probabilities and predictions for all images\".upper())\n",
    "instance._predictions_df = append_prediction(original_df=instance._inference_df, \n",
    "                                        probabilities_df=instance._inference_df, \n",
    "                                        inverse_label_codes=inverse_label_codes,)\n",
    "\n",
    "display(instance._predictions_df.head())\n",
    "\n",
    "print_header(\"Baseline model: probabilities and predictions for images in validation set\".upper())\n",
    "instance._predictions_df_val = instance._predictions_df[instance._predictions_df[\"set\"] == \"v1\"]\n",
    "\n",
    "display(instance._predictions_df_val.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "8cc27bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "BASELINE MODEL: CONFUSION MATRIX (VALIDATION SET)\n",
      "=================================================\n",
      "\n",
      "OVERALL EVALUATION METRIC AT BOTTOM RIGHT: AVERAGE CLASS-WISE F2 SCORE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>bcc</th>\n",
       "      <th>mel</th>\n",
       "      <th>akiec</th>\n",
       "      <th>nv</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>78</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>71</td>\n",
       "      <td>225</td>\n",
       "      <td>0.346667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>82</td>\n",
       "      <td>0.560976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>69</td>\n",
       "      <td>154</td>\n",
       "      <td>0.422078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>0.350877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>1,259</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0.931902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>134</td>\n",
       "      <td>96</td>\n",
       "      <td>164</td>\n",
       "      <td>54</td>\n",
       "      <td>1,421</td>\n",
       "      <td>1,869</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.58209</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.396341</td>\n",
       "      <td>0.37037</td>\n",
       "      <td>0.885996</td>\n",
       "      <td>_</td>\n",
       "      <td>0.52265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted    other       bcc       mel    akiec        nv    All    recall\n",
       "actual                                                                    \n",
       "other           78        19        46       11        71    225  0.346667\n",
       "bcc              5        46         4        9        18     82  0.560976\n",
       "mel              9         2        65        9        69    154  0.422078\n",
       "akiec            7        20         6       20         4     57  0.350877\n",
       "nv              35         9        43        5     1,259  1,351  0.931902\n",
       "All            134        96       164       54     1,421  1,869         _\n",
       "precision  0.58209  0.479167  0.396341  0.37037  0.885996      _   0.52265"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>other</th>\n",
       "      <th>bcc</th>\n",
       "      <th>mel</th>\n",
       "      <th>akiec</th>\n",
       "      <th>nv</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>612</td>\n",
       "      <td>86</td>\n",
       "      <td>312</td>\n",
       "      <td>53</td>\n",
       "      <td>293</td>\n",
       "      <td>1,356</td>\n",
       "      <td>0.451327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcc</th>\n",
       "      <td>14</td>\n",
       "      <td>367</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>86</td>\n",
       "      <td>514</td>\n",
       "      <td>0.714008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>587</td>\n",
       "      <td>36</td>\n",
       "      <td>438</td>\n",
       "      <td>1,113</td>\n",
       "      <td>0.527403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akiec</th>\n",
       "      <td>19</td>\n",
       "      <td>70</td>\n",
       "      <td>14</td>\n",
       "      <td>200</td>\n",
       "      <td>24</td>\n",
       "      <td>327</td>\n",
       "      <td>0.611621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>184</td>\n",
       "      <td>54</td>\n",
       "      <td>278</td>\n",
       "      <td>19</td>\n",
       "      <td>6,170</td>\n",
       "      <td>6,705</td>\n",
       "      <td>0.920209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>874</td>\n",
       "      <td>584</td>\n",
       "      <td>1,217</td>\n",
       "      <td>329</td>\n",
       "      <td>7,011</td>\n",
       "      <td>10,015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.700229</td>\n",
       "      <td>0.628425</td>\n",
       "      <td>0.482334</td>\n",
       "      <td>0.607903</td>\n",
       "      <td>0.880046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.644286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted     other       bcc       mel     akiec        nv     All    recall\n",
       "actual                                                                       \n",
       "other           612        86       312        53       293   1,356  0.451327\n",
       "bcc              14       367        26        21        86     514  0.714008\n",
       "mel              45         7       587        36       438   1,113  0.527403\n",
       "akiec            19        70        14       200        24     327  0.611621\n",
       "nv              184        54       278        19     6,170   6,705  0.920209\n",
       "All             874       584     1,217       329     7,011  10,015       NaN\n",
       "precision  0.700229  0.628425  0.482334  0.607903  0.880046     NaN  0.644286"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from evaluation import weighted_average_f, confusion_matrix_with_metric\n",
    "\n",
    "instance = resnet18mc_base\n",
    "map_labels = instance.label_codes\n",
    "\n",
    "A = instance._predictions_df_val['label']\n",
    "B = instance._predictions_df_val['pred']\n",
    "AxB = pd.crosstab(A,B,margins=True,dropna=False)\n",
    "\n",
    "beta = 2\n",
    "\n",
    "instance._cm = confusion_matrix_with_metric(AxB=AxB,\n",
    "                                                lst=None,\n",
    "                                                full_pad=True,\n",
    "                                                func=weighted_average_f,\n",
    "                                                beta=beta,\n",
    "                                                weights=None,\n",
    "                                                percentage=False,\n",
    "                                                map_labels=map_labels)\n",
    "\n",
    "print_header(\"BASELINE MODEL: confusion matrix (validation set)\")\n",
    "\n",
    "print(f\"Overall evaluation metric at bottom right: average class-wise F{beta} score\".upper())\n",
    "display(instance._cm.fillna('_'))\n",
    "\n",
    "C = instance._predictions_df['label']\n",
    "D = instance._predictions_df['pred']\n",
    "CxD = pd.crosstab(C,D,margins=True,dropna=False)\n",
    "\n",
    "confusion_matrix_with_metric(AxB=CxD,\n",
    "                                                lst=None,\n",
    "                                                full_pad=True,\n",
    "                                                func=weighted_average_f,\n",
    "                                                beta=beta,\n",
    "                                                weights=None,\n",
    "                                                percentage=False,\n",
    "                                                map_labels=map_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9043467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
