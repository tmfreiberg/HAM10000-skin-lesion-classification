{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f32ebf",
   "metadata": {
    "id": "d9f32ebf"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c92e86b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c92e86b3",
    "outputId": "2ae17044-4d2b-4b1d-8a3c-1c9ee3d992f9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path['project'] : D:\\projects\\skin-lesion-classification\n",
      "path['images'] : D:\\projects\\skin-lesion-classification\\images\n",
      "path['models'] : D:\\projects\\skin-lesion-classification\\models\n",
      "path['expository'] : D:\\projects\\skin-lesion-classification\\expository\n",
      "path['literature'] : D:\\projects\\skin-lesion-classification\\literature\n",
      "path['notebooks'] : D:\\projects\\skin-lesion-classification\\notebooks\n",
      "path['presentation'] : D:\\projects\\skin-lesion-classification\\presentation\n",
      "path['scripts'] : D:\\projects\\skin-lesion-classification\\scripts\n",
      "path['streamlit'] : D:\\projects\\skin-lesion-classification\\streamlit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# If we're using Google Colab, we set the environment variable to point to the relevant folder in our Google Drive:\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.environ['SKIN_LESION_CLASSIFICATION'] = '/content/drive/MyDrive/Colab Notebooks/skin-lesion-classification'\n",
    "\n",
    "# Otherwise, we use the environment variable on our local system:\n",
    "project_environment_variable = \"SKIN_LESION_CLASSIFICATION\"\n",
    "\n",
    "# Path to the root directory of the project:\n",
    "project_path = Path(os.environ.get(project_environment_variable))\n",
    "\n",
    "# Relative path to /scripts (from where custom modules will be imported):\n",
    "scripts_path = project_path.joinpath(\"scripts\")\n",
    "\n",
    "# Add this path to sys.path so that Python will look there for modules:\n",
    "sys.path.append(str(scripts_path))\n",
    "\n",
    "# Now import path_step from our custom utils module to create a dictionary to all subdirectories in our root directory:\n",
    "from utils import path_setup\n",
    "path = path_setup.subfolders(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1af769c",
   "metadata": {
    "id": "e1af769c"
   },
   "source": [
    "<a id='model_setup'></a>\n",
    "# Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5f08207",
   "metadata": {
    "id": "f5f08207"
   },
   "outputs": [],
   "source": [
    "from typing import Type, Union      # For type hints\n",
    "from processing import process      # Custom module for processing metadata\n",
    "\n",
    "data_dir: Path = path[\"images\"]     # Path to directory containing metadata.csv file\n",
    "csv_filename: str = \"metadata.csv\"  # The filename\n",
    "\n",
    "restrict_to: Union[None, dict] = {'dx' : ['mel', 'nv']}\n",
    "\n",
    "tvr: int = 3              # Ratio of training set to validation set. See discussion below for explanation.\n",
    "seed: int = 0             # Random seed for parts of the process where randomness is called for.\n",
    "keep_first: bool = False  # If False, then, for each lesion, we choose a random image to assign to our training set.\n",
    "stratified: bool = True   # If True, we stratify classes so that the proportions remain as stable as possible after train/val split.\n",
    "                          # If False, the proportions will be roughly similar.\n",
    "\n",
    "to_classify: Union[list, dict] = { 'mel' : ['mel'], 'nv' : ['nv']}\n",
    "\n",
    "train_one_img_per_lesion: Union[None, bool] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e2538b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2e2538b",
    "outputId": "1f6e799c-c726-4e7d-a2d3-790383953181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded file 'D:\\projects\\skin-lesion-classification\\images\\metadata.csv'.\n",
      "- Removing all records unless:\n",
      "  dx in ['mel', 'nv']\n",
      "- Inserted 'num_images' column in dataframe, to the right of 'lesion_id' column.\n",
      "- Inserted 'label' column in dataframe, to the right of 'dx' column: \n",
      "  {'mel': 0, 'nv': 1}\n",
      "- Added 'set' column to dataframe, with values 't1', 'v1', 'ta', and 'va', to the right of 'localization' column.\n",
      "- Basic, overall dataframe (pre-train/test split): self.df\n",
      "- Training set (not balanced, one image per lesion): self.df_train\n",
      "- Validation set (not expanded, one image per lesion): self.df_val1\n",
      "- Validation set (not expanded, use all images of each lesion): self.df_val_a\n",
      "- Small sample dataframes for code testing: self._df_train_code_test, self._df_val1_code_test, self._df_val_a_code_test\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the process class with attribute values as above.\n",
    "melnv_t1 = process(data_dir=data_dir,\n",
    "                  csv_filename=csv_filename,\n",
    "                  restrict_to=restrict_to,\n",
    "                  tvr=tvr,\n",
    "                  seed=seed,\n",
    "                  keep_first=keep_first,\n",
    "                  stratified=stratified,\n",
    "                  to_classify=to_classify,\n",
    "                  train_one_img_per_lesion=train_one_img_per_lesion,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a312c5d",
   "metadata": {
    "id": "7a312c5d"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose([\n",
    "transforms.Resize((224,224)), # Resize images to fit ResNet input size\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet stats\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "812d42e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "812d42e8",
    "outputId": "4fc8351a-b630-4cb4-8226-25f62c078c52"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Union, List, Callable\n",
    "import torchvision.models as models\n",
    "\n",
    "source: Union[process, pd.DataFrame] = melnv_t1        # Processed data to be fed into model for training.\n",
    "                                                      # Must either be an instance of the process class, or a dataframe of the same format as source.df if source were an instance of the process class.\n",
    "model_dir: Path = path[\"models\"]                      # Path to directory where models/model info/model results are stored.\n",
    "\n",
    "transform: Union[None,\n",
    "                 transforms.Compose,\n",
    "                 List[Callable]] = transform     # Transform to be applied to images before feeding into neural network.\n",
    "\n",
    "filename_stem: Union[None, str] = \"rn18\"         # For saving model and related files. Default \"rn18\" (if ResNet model) or \"EffNet\" (if EfficientNet), or \"cnn\".\n",
    "filename_suffix: Union[None, str] = \"melnv_base\"   # Something descriptive and unique for future reference. Default empty string \"\".\n",
    "\n",
    "# model: Union[None, models.ResNet, models.EfficientNet] = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT) # Pre-trained model. Default: ResNet18.\n",
    "model: Union[None, models.ResNet, models.EfficientNet] = models.resnet18(weights=\"ResNet18_Weights.DEFAULT\")\n",
    "base_learning_rate: Union[None, float] = 0.01\n",
    "unfreeze_all: Union[None, bool] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6549485",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6549485",
    "outputId": "7725e488-4e34-4ba3-9a22-81a3232801e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New files will be created. \n",
      "Base filename: rn18_t1_ufall_10e_melnv_base_01\n",
      "Attributes saved to file: D:\\projects\\skin-lesion-classification\\models\\rn18_t1_ufall_10e_melnv_base_01_attributes.json\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the resnet18 class with attribute values as above.\n",
    "from multiclass_models import cnn\n",
    "\n",
    "rn18_melnv_t1 = cnn(source=source,\n",
    "                    model_dir=model_dir,\n",
    "                    transform=transform,\n",
    "                    filename_stem=filename_stem,\n",
    "                    filename_suffix=filename_suffix,\n",
    "                    model=model,\n",
    "                    base_learning_rate=base_learning_rate,\n",
    "                    unfreeze_all=unfreeze_all,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "WqOT_GSELriP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WqOT_GSELriP",
    "outputId": "8a85a31e-09bd-4865-d53e-e448c28fad3c"
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# tic = time.time()\n",
    "# rn18_melnv_t1.train()\n",
    "# toc = time.time()\n",
    "# print(f\"Elapsed time: {toc - tic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8f19b2b",
   "metadata": {
    "id": "d8f19b2b"
   },
   "outputs": [],
   "source": [
    "# from utils import print_header\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# instance = melnv_t1\n",
    "\n",
    "# model = models.resnet18()\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "\n",
    "# file_path_pth = instance.model_dir.joinpath(instance._filename + \".pth\")\n",
    "# state_dict = torch.load(file_path_pth)\n",
    "# model.load_state_dict(state_dict)\n",
    "\n",
    "# # model = models.efficientnet_b0()\n",
    "# # num_ftrs = model.classifier[1].in_features\n",
    "# # model.classifier[1] = nn.Linear(num_ftrs, len(instance.label_codes))\n",
    "\n",
    "# instance.model = model\n",
    "# instance.state_dict = state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f89e26a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4f89e26a",
    "outputId": "eb7b00b6-5ac8-4308-97e6-7a05329123d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving probabilities: /content/drive/MyDrive/Colab Notebooks/skin-lesion-classification/models/rn18_t1_ufall_10e_melnv_base_00_val1_probabilities.csv\n",
      "Elapsed time: 18.10058069229126\n",
      "Saving probabilities: /content/drive/MyDrive/Colab Notebooks/skin-lesion-classification/models/rn18_t1_ufall_10e_melnv_base_00_val_a_probabilities.csv\n",
      "Elapsed time: 23.145163536071777\n"
     ]
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "# from multiclass_models import get_probabilities\n",
    "\n",
    "# instance = rn18_melnv_t1\n",
    "\n",
    "# tic = time.time()\n",
    "\n",
    "# instance.df_probabilities_val1 = get_probabilities(df=instance.df_val1,\n",
    "#                                                    data_dir=instance.data_dir,\n",
    "#                                                    model_dir=instance.model_dir,\n",
    "#                                                    model=instance.model,\n",
    "#                                                    filename=instance._filename,\n",
    "#                                                    label_codes=instance.label_codes,\n",
    "#                                                    transform=instance.transform,\n",
    "#                                                    batch_size=instance.batch_size,\n",
    "#                                                    Print=False,\n",
    "#                                                    save_as=instance._filename + \"_val1\",)\n",
    "\n",
    "# toc = time.time()\n",
    "\n",
    "# print(f\"Elapsed time: {toc - tic}\")\n",
    "\n",
    "# instance.df_probabilities_val_a = get_probabilities(df=instance.df_val_a,\n",
    "#                                                     data_dir=instance.data_dir,\n",
    "#                                                     model_dir=instance.model_dir,\n",
    "#                                                     model=instance.model,\n",
    "#                                                     filename=instance._filename,\n",
    "#                                                     label_codes=instance.label_codes,\n",
    "#                                                     transform=instance.transform,\n",
    "#                                                     batch_size=instance.batch_size,\n",
    "#                                                     Print=False,\n",
    "#                                                     save_as=instance._filename + \"_val_a\",)\n",
    "# tic = time.time()\n",
    "# print(f\"Elapsed time: {tic - toc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb08376c",
   "metadata": {
    "id": "bb08376c"
   },
   "outputs": [],
   "source": [
    "instance = rn18_melnv_t1\n",
    "\n",
    "file_path1 = instance.model_dir.joinpath(\"rn18_t1_ufall_10e_melnv_base_00_val1_probabilities.csv\")\n",
    "file_path_a = instance.model_dir.joinpath(\"rn18_t1_ufall_10e_melnv_base_00_val_a_probabilities.csv\")\n",
    "\n",
    "instance.df_probabilities_val1 = pd.read_csv(file_path1, index_col=0)\n",
    "instance.df_probabilities_val_a = pd.read_csv(file_path_a, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8096a8d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "a8096a8d",
    "outputId": "7d30b0d1-5279-4770-d492-43d853bd3fb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================\n",
      "VALIDATION SET: ONE IMAGE PER LESION\n",
      "====================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_nv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0001751</td>\n",
       "      <td>ISIC_0024698</td>\n",
       "      <td>nv</td>\n",
       "      <td>0.218357</td>\n",
       "      <td>0.781643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>mel</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.588688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0005191</td>\n",
       "      <td>ISIC_0031177</td>\n",
       "      <td>mel</td>\n",
       "      <td>0.370893</td>\n",
       "      <td>0.629107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0004476</td>\n",
       "      <td>ISIC_0030417</td>\n",
       "      <td>mel</td>\n",
       "      <td>0.176949</td>\n",
       "      <td>0.823051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000876</td>\n",
       "      <td>ISIC_0032396</td>\n",
       "      <td>mel</td>\n",
       "      <td>0.289566</td>\n",
       "      <td>0.710434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx  prob_mel   prob_nv\n",
       "0  HAM_0001751  ISIC_0024698   nv  0.218357  0.781643\n",
       "1  HAM_0005678  ISIC_0031023  mel  0.411312  0.588688\n",
       "2  HAM_0005191  ISIC_0031177  mel  0.370893  0.629107\n",
       "3  HAM_0004476  ISIC_0030417  mel  0.176949  0.823051\n",
       "4  HAM_0000876  ISIC_0032396  mel  0.289566  0.710434"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================\n",
      "VALIDATION SET: ALL IMAGES PER LESION\n",
      "=====================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_nv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0001751</td>\n",
       "      <td>ISIC_0024698</td>\n",
       "      <td>nv</td>\n",
       "      <td>0.218357</td>\n",
       "      <td>0.781643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>mel</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.588688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>ISIC_0028086</td>\n",
       "      <td>mel</td>\n",
       "      <td>0.435894</td>\n",
       "      <td>0.564106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0005191</td>\n",
       "      <td>ISIC_0031177</td>\n",
       "      <td>mel</td>\n",
       "      <td>0.370893</td>\n",
       "      <td>0.629107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0004476</td>\n",
       "      <td>ISIC_0030417</td>\n",
       "      <td>mel</td>\n",
       "      <td>0.176949</td>\n",
       "      <td>0.823051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx  prob_mel   prob_nv\n",
       "0  HAM_0001751  ISIC_0024698   nv  0.218357  0.781643\n",
       "1  HAM_0005678  ISIC_0031023  mel  0.411312  0.588688\n",
       "2  HAM_0005678  ISIC_0028086  mel  0.435894  0.564106\n",
       "3  HAM_0005191  ISIC_0031177  mel  0.370893  0.629107\n",
       "4  HAM_0004476  ISIC_0030417  mel  0.176949  0.823051"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import print_header\n",
    "\n",
    "instance = rn18_melnv_t1\n",
    "\n",
    "print_header(\"Validation set: one image per lesion\")\n",
    "display_columns = ['lesion_id', 'image_id', 'dx'] + [col for col in instance.df_probabilities_val1.columns if col.startswith('prob')]\n",
    "display(instance.df_probabilities_val1[display_columns].head())\n",
    "\n",
    "print_header(\"Validation set: all images per lesion\")\n",
    "display(instance.df_probabilities_val_a[display_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c397a32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4c397a32",
    "outputId": "782e7d68-6b00-40b4-e47d-030ad9de8dbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================\n",
      "VALIDATION SET, ONE IMAGE PER LESION: COMBINING PROBABILITIES AND MAKING PREDICTIONS\n",
      "====================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0001751</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0024698</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.218357</td>\n",
       "      <td>0.781643</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>mel</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.588688</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0005191</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0031177</td>\n",
       "      <td>mel</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.370893</td>\n",
       "      <td>0.629107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0004476</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0030417</td>\n",
       "      <td>mel</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.176949</td>\n",
       "      <td>0.823051</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000876</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0032396</td>\n",
       "      <td>mel</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.289566</td>\n",
       "      <td>0.710434</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>HAM_0004857</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031222</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.155081</td>\n",
       "      <td>0.844919</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>HAM_0003384</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028438</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>55.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.055855</td>\n",
       "      <td>0.944145</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>HAM_0001410</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0024830</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>15.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.162379</td>\n",
       "      <td>0.837621</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>HAM_0003322</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031649</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>50.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.156353</td>\n",
       "      <td>0.843647</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>HAM_0003521</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0032258</td>\n",
       "      <td>mel</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.094808</td>\n",
       "      <td>0.905192</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1505 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id  num_images      image_id   dx  label    dx_type   age  \\\n",
       "0     HAM_0001751           1  ISIC_0024698   nv      1  consensus  70.0   \n",
       "1     HAM_0005678           2  ISIC_0031023  mel      0      histo  60.0   \n",
       "2     HAM_0005191           1  ISIC_0031177  mel      0      histo  40.0   \n",
       "3     HAM_0004476           1  ISIC_0030417  mel      0      histo  70.0   \n",
       "4     HAM_0000876           2  ISIC_0032396  mel      0      histo  55.0   \n",
       "...           ...         ...           ...  ...    ...        ...   ...   \n",
       "1500  HAM_0004857           2  ISIC_0031222   nv      1  consensus  70.0   \n",
       "1501  HAM_0003384           2  ISIC_0028438   nv      1  consensus  55.0   \n",
       "1502  HAM_0001410           2  ISIC_0024830   nv      1  consensus  15.0   \n",
       "1503  HAM_0003322           2  ISIC_0031649   nv      1  consensus  50.0   \n",
       "1504  HAM_0003521           2  ISIC_0032258  mel      0      histo  70.0   \n",
       "\n",
       "         sex     localization set  prob_mel   prob_nv  pred  pred_final  \n",
       "0       male             face  v1  0.218357  0.781643     1           1  \n",
       "1       male            chest  v1  0.411312  0.588688     1           1  \n",
       "2     female             back  v1  0.370893  0.629107     1           1  \n",
       "3       male             face  v1  0.176949  0.823051     1           1  \n",
       "4       male          abdomen  v1  0.289566  0.710434     1           1  \n",
       "...      ...              ...  ..       ...       ...   ...         ...  \n",
       "1500    male  lower extremity  v1  0.155081  0.844919     1           1  \n",
       "1501  female            chest  v1  0.055855  0.944145     1           1  \n",
       "1502  female            chest  v1  0.162379  0.837621     1           1  \n",
       "1503  female             face  v1  0.156353  0.843647     1           1  \n",
       "1504  female             back  v1  0.094808  0.905192     1           1  \n",
       "\n",
       "[1505 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================================================================================\n",
      "VALIDATION SET, ALL IMAGES PER LESION: COMBINING PROBABILITIES, MAKING PREDICTIONS, AND COMBINING PREDICTIONS\n",
      "=============================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0001751</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0024698</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.218357</td>\n",
       "      <td>0.781643</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>mel</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.588688</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028086</td>\n",
       "      <td>mel</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>va</td>\n",
       "      <td>0.435894</td>\n",
       "      <td>0.564106</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0005191</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0031177</td>\n",
       "      <td>mel</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.370893</td>\n",
       "      <td>0.629107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0004476</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0030417</td>\n",
       "      <td>mel</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.176949</td>\n",
       "      <td>0.823051</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>HAM_0001410</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0024830</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>15.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.162371</td>\n",
       "      <td>0.837630</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>HAM_0004857</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0029038</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>va</td>\n",
       "      <td>0.189378</td>\n",
       "      <td>0.810622</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>HAM_0004857</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031222</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.155075</td>\n",
       "      <td>0.844925</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>HAM_0003384</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031299</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>55.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>va</td>\n",
       "      <td>0.045434</td>\n",
       "      <td>0.954566</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>HAM_0003384</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028438</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>55.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.055853</td>\n",
       "      <td>0.944147</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1970 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id  num_images      image_id   dx  label    dx_type   age  \\\n",
       "0     HAM_0001751           1  ISIC_0024698   nv      1  consensus  70.0   \n",
       "1     HAM_0005678           2  ISIC_0031023  mel      0      histo  60.0   \n",
       "2     HAM_0005678           2  ISIC_0028086  mel      0      histo  60.0   \n",
       "3     HAM_0005191           1  ISIC_0031177  mel      0      histo  40.0   \n",
       "4     HAM_0004476           1  ISIC_0030417  mel      0      histo  70.0   \n",
       "...           ...         ...           ...  ...    ...        ...   ...   \n",
       "1967  HAM_0001410           2  ISIC_0024830   nv      1  consensus  15.0   \n",
       "1963  HAM_0004857           2  ISIC_0029038   nv      1  consensus  70.0   \n",
       "1964  HAM_0004857           2  ISIC_0031222   nv      1  consensus  70.0   \n",
       "1965  HAM_0003384           2  ISIC_0031299   nv      1  consensus  55.0   \n",
       "1966  HAM_0003384           2  ISIC_0028438   nv      1  consensus  55.0   \n",
       "\n",
       "         sex     localization set  prob_mel   prob_nv  pred  pred_final  \n",
       "0       male             face  v1  0.218357  0.781643     1           1  \n",
       "1       male            chest  v1  0.411312  0.588688     1           1  \n",
       "2       male            chest  va  0.435894  0.564106     1           1  \n",
       "3     female             back  v1  0.370893  0.629107     1           1  \n",
       "4       male             face  v1  0.176949  0.823051     1           1  \n",
       "...      ...              ...  ..       ...       ...   ...         ...  \n",
       "1967  female            chest  v1  0.162371  0.837630     1           1  \n",
       "1963    male  lower extremity  va  0.189378  0.810622     1           1  \n",
       "1964    male  lower extremity  v1  0.155075  0.844925     1           1  \n",
       "1965  female            chest  va  0.045434  0.954566     1           1  \n",
       "1966  female            chest  v1  0.055853  0.944147     1           1  \n",
       "\n",
       "[1970 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List\n",
    "from multiclass_models import final_prediction\n",
    "\n",
    "instance = rn18_melnv_t1\n",
    "\n",
    "raw_probabilities_df1: pd.DataFrame = instance.df_probabilities_val1\n",
    "raw_probabilities_df_a: pd.DataFrame = instance.df_probabilities_val_a\n",
    "aggregate_method: Union[None, Dict[str, List[str]]] = None#{ 'max' : ['mel', 'bcc', 'akiec'], 'min' : ['nv'], 'mean' : ['other']}\n",
    "threshold_dict_help: Union[None, OrderedDict[str, float]] = None# OrderedDict([('mel',0.4), ('bcc', 0.4), ('akiec', 0.4)])\n",
    "threshold_dict_hinder: Union[None, OrderedDict[str, float]] = None#OrderedDict([('nv',0.6)])\n",
    "votes_to_win_dict: Union[None, OrderedDict[str, int]] = None #OrderedDict([('mel',1), ('bcc',1), ('akiec',1)])\n",
    "label_codes: Dict[int, str] = instance.label_codes\n",
    "prefix: Union[None, str] = 'prob_'\n",
    "\n",
    "print_header(\"Validation set, one image per lesion: combining probabilities and making predictions\")\n",
    "\n",
    "instance.df_pred_val1 = final_prediction(raw_probabilities_df=raw_probabilities_df1,\n",
    "                                          threshold_dict_help=threshold_dict_help,\n",
    "                                          threshold_dict_hinder=threshold_dict_hinder,\n",
    "                                          votes_to_win_dict=votes_to_win_dict,\n",
    "                                          label_codes=label_codes,)\n",
    "\n",
    "display(instance.df_pred_val1)\n",
    "\n",
    "print_header(\"Validation set, all images per lesion: combining probabilities, making predictions, and combining predictions\")\n",
    "\n",
    "instance.df_pred_val_a = final_prediction(raw_probabilities_df=raw_probabilities_df_a,\n",
    "                                          threshold_dict_help=threshold_dict_help,\n",
    "                                          threshold_dict_hinder=threshold_dict_hinder,\n",
    "                                          votes_to_win_dict=votes_to_win_dict,\n",
    "                                          label_codes=label_codes,)\n",
    "\n",
    "display(instance.df_pred_val_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feffd04b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "feffd04b",
    "outputId": "956259a7-d696-4816-b7ae-b766afe17249"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================\n",
      "CONFUSION MATRIX: VALIDATION SET, ONE IMAGE PER LESION\n",
      "======================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>mel</th>\n",
       "      <th>nv</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>0</td>\n",
       "      <td>1,351</td>\n",
       "      <td>1,351</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0</td>\n",
       "      <td>1,505</td>\n",
       "      <td>1,505</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>_</td>\n",
       "      <td>0.897674</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted mel        nv    All recall\n",
       "actual                               \n",
       "mel         0       154    154    0.0\n",
       "nv          0     1,351  1,351    1.0\n",
       "All         0     1,505  1,505      _\n",
       "precision   _  0.897674      _      _"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "CONFUSION MATRIX: VALIDATION SET, ALL IMAGES PER LESION\n",
      "=======================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>mel</th>\n",
       "      <th>nv</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>0</td>\n",
       "      <td>1,351</td>\n",
       "      <td>1,351</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0</td>\n",
       "      <td>1,505</td>\n",
       "      <td>1,505</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>_</td>\n",
       "      <td>0.897674</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted mel        nv    All recall\n",
       "actual                               \n",
       "mel         0       154    154    0.0\n",
       "nv          0     1,351  1,351    1.0\n",
       "All         0     1,505  1,505      _\n",
       "precision   _  0.897674      _      _"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from evaluation import weighted_average_f, confusion_matrix_with_metric\n",
    "\n",
    "instance = rn18_melnv_t1\n",
    "map_labels = instance.label_codes\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label']\n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final']\n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']\n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']\n",
    "\n",
    "txp1 = pd.crosstab(target1,prediction1,margins=True,dropna=False)\n",
    "txp_a = pd.crosstab(target_a,prediction_a,margins=True,dropna=False)\n",
    "\n",
    "beta = 2\n",
    "# Weights inversely proportional to relative class size in the training set, giving more importance to smaller classes.\n",
    "weights = 1/instance.df_train['label'].value_counts(normalize=True).sort_index().values # None\n",
    "\n",
    "instance.cm1 = confusion_matrix_with_metric(AxB=txp1,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "instance.cm_a = confusion_matrix_with_metric(AxB=txp_a,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "print_header(\"Confusion matrix: validation set, one image per lesion\")\n",
    "display(instance.cm1.fillna('_'))\n",
    "\n",
    "print_header(\"Confusion matrix: validation set, all images per lesion\")\n",
    "display(instance.cm_a.fillna('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e98fa3a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "e98fa3a3",
    "outputId": "4e87e0c7-a9f8-4f2b-a158-82ea8a54aba2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================\n",
      "BASELINE MODEL: OTHER METRICS\n",
      "=============================\n",
      "\n",
      "\n",
      "ONE IMAGE PER LESION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.897674</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.897674</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.458215</td>\n",
       "      <td>0.473039</td>\n",
       "      <td>0.488855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC  BACC  precision  recall      F1/2        F1        F2  MCC  \\\n",
       "0  0.897674   0.5   0.897674     0.5  0.458215  0.473039  0.488855  0.0   \n",
       "\n",
       "   ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0          NaN         NaN          NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ALL IMAGES PER LESION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.897674</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.897674</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.458215</td>\n",
       "      <td>0.473039</td>\n",
       "      <td>0.488855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC  BACC  precision  recall      F1/2        F1        F2  MCC  \\\n",
       "0  0.897674   0.5   0.897674     0.5  0.458215  0.473039  0.488855  0.0   \n",
       "\n",
       "   ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0          NaN         NaN          NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from evaluation import metric_dictionary\n",
    "# import pandas as pd\n",
    "\n",
    "instance = rn18_melnv_t1\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label']\n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final']\n",
    "probabilities1 = instance.df_probabilities_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']\n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']\n",
    "probabilities_a = instance.df_probabilities_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "\n",
    "beta = 2\n",
    "# Weights inversely proportional to relative class size, giving more importance to smaller classes.\n",
    "weights = 1/instance.df_train['label'].value_counts(normalize=True).sort_index().values # None\n",
    "\n",
    "print_header(\"Baseline model: other metrics\")\n",
    "\n",
    "instance.metric_dict1 = metric_dictionary(target=target1,\n",
    "                                          prediction=prediction1,\n",
    "                                          probabilities=probabilities1)\n",
    "\n",
    "instance.metric_dict_a = metric_dictionary(target=target_a,\n",
    "                                          prediction=prediction_a,\n",
    "                                          probabilities=probabilities_a)\n",
    "\n",
    "print(\"\\nOne image per lesion\".upper())\n",
    "display(pd.DataFrame(instance.metric_dict1))\n",
    "\n",
    "print(\"\\nAll images per lesion\".upper())\n",
    "display(pd.DataFrame(instance.metric_dict_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "jgge1QYQrZkJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jgge1QYQrZkJ",
    "outputId": "45ffe5b0-9ae2-4a77-fb2e-385538a6e7db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================\n",
      "VALIDATION SET, ONE IMAGE PER LESION: COMBINING PROBABILITIES AND MAKING PREDICTIONS\n",
      "====================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0001751</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0024698</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.218357</td>\n",
       "      <td>0.781643</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>mel</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.588688</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0005191</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0031177</td>\n",
       "      <td>mel</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.370893</td>\n",
       "      <td>0.629107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0004476</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0030417</td>\n",
       "      <td>mel</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.176949</td>\n",
       "      <td>0.823051</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000876</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0032396</td>\n",
       "      <td>mel</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.289566</td>\n",
       "      <td>0.710434</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>HAM_0004857</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031222</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.155081</td>\n",
       "      <td>0.844919</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>HAM_0003384</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028438</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>55.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.055855</td>\n",
       "      <td>0.944145</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>HAM_0001410</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0024830</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>15.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.162379</td>\n",
       "      <td>0.837621</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>HAM_0003322</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031649</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>50.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.156353</td>\n",
       "      <td>0.843647</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>HAM_0003521</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0032258</td>\n",
       "      <td>mel</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.094808</td>\n",
       "      <td>0.905192</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1505 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id  num_images      image_id   dx  label    dx_type   age  \\\n",
       "0     HAM_0001751           1  ISIC_0024698   nv      1  consensus  70.0   \n",
       "1     HAM_0005678           2  ISIC_0031023  mel      0      histo  60.0   \n",
       "2     HAM_0005191           1  ISIC_0031177  mel      0      histo  40.0   \n",
       "3     HAM_0004476           1  ISIC_0030417  mel      0      histo  70.0   \n",
       "4     HAM_0000876           2  ISIC_0032396  mel      0      histo  55.0   \n",
       "...           ...         ...           ...  ...    ...        ...   ...   \n",
       "1500  HAM_0004857           2  ISIC_0031222   nv      1  consensus  70.0   \n",
       "1501  HAM_0003384           2  ISIC_0028438   nv      1  consensus  55.0   \n",
       "1502  HAM_0001410           2  ISIC_0024830   nv      1  consensus  15.0   \n",
       "1503  HAM_0003322           2  ISIC_0031649   nv      1  consensus  50.0   \n",
       "1504  HAM_0003521           2  ISIC_0032258  mel      0      histo  70.0   \n",
       "\n",
       "         sex     localization set  prob_mel   prob_nv  pred  pred_final  \n",
       "0       male             face  v1  0.218357  0.781643     1           1  \n",
       "1       male            chest  v1  0.411312  0.588688     0           0  \n",
       "2     female             back  v1  0.370893  0.629107     0           0  \n",
       "3       male             face  v1  0.176949  0.823051     1           1  \n",
       "4       male          abdomen  v1  0.289566  0.710434     1           1  \n",
       "...      ...              ...  ..       ...       ...   ...         ...  \n",
       "1500    male  lower extremity  v1  0.155081  0.844919     1           1  \n",
       "1501  female            chest  v1  0.055855  0.944145     1           1  \n",
       "1502  female            chest  v1  0.162379  0.837621     1           1  \n",
       "1503  female             face  v1  0.156353  0.843647     1           1  \n",
       "1504  female             back  v1  0.094808  0.905192     1           1  \n",
       "\n",
       "[1505 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================================================================================\n",
      "VALIDATION SET, ALL IMAGES PER LESION: COMBINING PROBABILITIES, MAKING PREDICTIONS, AND COMBINING PREDICTIONS\n",
      "=============================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>num_images</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>label</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>set</th>\n",
       "      <th>prob_mel</th>\n",
       "      <th>prob_nv</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0001751</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0024698</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.218357</td>\n",
       "      <td>0.781643</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031023</td>\n",
       "      <td>mel</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.588688</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0005678</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028086</td>\n",
       "      <td>mel</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>va</td>\n",
       "      <td>0.435894</td>\n",
       "      <td>0.564106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0005191</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0031177</td>\n",
       "      <td>mel</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.370893</td>\n",
       "      <td>0.629107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0004476</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0030417</td>\n",
       "      <td>mel</td>\n",
       "      <td>0</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.176949</td>\n",
       "      <td>0.823051</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>HAM_0001410</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0024830</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>15.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.162371</td>\n",
       "      <td>0.837630</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>HAM_0004857</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0029038</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>va</td>\n",
       "      <td>0.189378</td>\n",
       "      <td>0.810622</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>HAM_0004857</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031222</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.155075</td>\n",
       "      <td>0.844925</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>HAM_0003384</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0031299</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>55.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>va</td>\n",
       "      <td>0.045434</td>\n",
       "      <td>0.954566</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>HAM_0003384</td>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0028438</td>\n",
       "      <td>nv</td>\n",
       "      <td>1</td>\n",
       "      <td>consensus</td>\n",
       "      <td>55.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>v1</td>\n",
       "      <td>0.055853</td>\n",
       "      <td>0.944147</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1970 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id  num_images      image_id   dx  label    dx_type   age  \\\n",
       "0     HAM_0001751           1  ISIC_0024698   nv      1  consensus  70.0   \n",
       "1     HAM_0005678           2  ISIC_0031023  mel      0      histo  60.0   \n",
       "2     HAM_0005678           2  ISIC_0028086  mel      0      histo  60.0   \n",
       "3     HAM_0005191           1  ISIC_0031177  mel      0      histo  40.0   \n",
       "4     HAM_0004476           1  ISIC_0030417  mel      0      histo  70.0   \n",
       "...           ...         ...           ...  ...    ...        ...   ...   \n",
       "1967  HAM_0001410           2  ISIC_0024830   nv      1  consensus  15.0   \n",
       "1963  HAM_0004857           2  ISIC_0029038   nv      1  consensus  70.0   \n",
       "1964  HAM_0004857           2  ISIC_0031222   nv      1  consensus  70.0   \n",
       "1965  HAM_0003384           2  ISIC_0031299   nv      1  consensus  55.0   \n",
       "1966  HAM_0003384           2  ISIC_0028438   nv      1  consensus  55.0   \n",
       "\n",
       "         sex     localization set  prob_mel   prob_nv  pred  pred_final  \n",
       "0       male             face  v1  0.218357  0.781643     1           1  \n",
       "1       male            chest  v1  0.411312  0.588688     0           0  \n",
       "2       male            chest  va  0.435894  0.564106     0           0  \n",
       "3     female             back  v1  0.370893  0.629107     0           0  \n",
       "4       male             face  v1  0.176949  0.823051     1           1  \n",
       "...      ...              ...  ..       ...       ...   ...         ...  \n",
       "1967  female            chest  v1  0.162371  0.837630     1           1  \n",
       "1963    male  lower extremity  va  0.189378  0.810622     1           1  \n",
       "1964    male  lower extremity  v1  0.155075  0.844925     1           1  \n",
       "1965  female            chest  va  0.045434  0.954566     1           1  \n",
       "1966  female            chest  v1  0.055853  0.944147     1           1  \n",
       "\n",
       "[1970 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List\n",
    "from multiclass_models import final_prediction\n",
    "\n",
    "instance = rn18_melnv_t1\n",
    "\n",
    "raw_probabilities_df1: pd.DataFrame = instance.df_probabilities_val1\n",
    "raw_probabilities_df_a: pd.DataFrame = instance.df_probabilities_val_a\n",
    "aggregate_method: Union[None, Dict[str, List[str]]] = { 'max' : ['mel'], 'min' : ['nv']}\n",
    "threshold_dict_help: Union[None, OrderedDict[str, float]] = OrderedDict([('mel',0.3)])\n",
    "threshold_dict_hinder: Union[None, OrderedDict[str, float]] = OrderedDict([('nv',0.7)])\n",
    "votes_to_win_dict: Union[None, OrderedDict[str, int]] = OrderedDict([('mel',1)])\n",
    "label_codes: Dict[int, str] = instance.label_codes\n",
    "prefix: Union[None, str] = 'prob_'\n",
    "\n",
    "print_header(\"Validation set, one image per lesion: combining probabilities and making predictions\")\n",
    "\n",
    "instance.df_pred_val1 = final_prediction(raw_probabilities_df=raw_probabilities_df1,\n",
    "                                          threshold_dict_help=threshold_dict_help,\n",
    "                                          threshold_dict_hinder=threshold_dict_hinder,\n",
    "                                          votes_to_win_dict=votes_to_win_dict,\n",
    "                                          label_codes=label_codes,)\n",
    "\n",
    "display(instance.df_pred_val1)\n",
    "\n",
    "print_header(\"Validation set, all images per lesion: combining probabilities, making predictions, and combining predictions\")\n",
    "\n",
    "instance.df_pred_val_a = final_prediction(raw_probabilities_df=raw_probabilities_df_a,\n",
    "                                          threshold_dict_help=threshold_dict_help,\n",
    "                                          threshold_dict_hinder=threshold_dict_hinder,\n",
    "                                          votes_to_win_dict=votes_to_win_dict,\n",
    "                                          label_codes=label_codes,)\n",
    "\n",
    "display(instance.df_pred_val_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ukZ1WwQwrtIO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "ukZ1WwQwrtIO",
    "outputId": "865e4783-b910-4edc-a082-b0448a81b4b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================\n",
      "CONFUSION MATRIX: VALIDATION SET, ONE IMAGE PER LESION\n",
      "======================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>mel</th>\n",
       "      <th>nv</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>107</td>\n",
       "      <td>47</td>\n",
       "      <td>154</td>\n",
       "      <td>0.694805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>155</td>\n",
       "      <td>1,196</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0.88527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>262</td>\n",
       "      <td>1,243</td>\n",
       "      <td>1,505</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.408397</td>\n",
       "      <td>0.962188</td>\n",
       "      <td>_</td>\n",
       "      <td>0.638937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted       mel        nv    All    recall\n",
       "actual                                        \n",
       "mel             107        47    154  0.694805\n",
       "nv              155     1,196  1,351   0.88527\n",
       "All             262     1,243  1,505         _\n",
       "precision  0.408397  0.962188      _  0.638937"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "CONFUSION MATRIX: VALIDATION SET, ALL IMAGES PER LESION\n",
      "=======================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>mel</th>\n",
       "      <th>nv</th>\n",
       "      <th>All</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>115</td>\n",
       "      <td>39</td>\n",
       "      <td>154</td>\n",
       "      <td>0.746753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nv</th>\n",
       "      <td>184</td>\n",
       "      <td>1,167</td>\n",
       "      <td>1,351</td>\n",
       "      <td>0.863805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>299</td>\n",
       "      <td>1,206</td>\n",
       "      <td>1,505</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.967662</td>\n",
       "      <td>_</td>\n",
       "      <td>0.654345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted       mel        nv    All    recall\n",
       "actual                                        \n",
       "mel             115        39    154  0.746753\n",
       "nv              184     1,167  1,351  0.863805\n",
       "All             299     1,206  1,505         _\n",
       "precision  0.384615  0.967662      _  0.654345"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from evaluation import weighted_average_f, confusion_matrix_with_metric\n",
    "\n",
    "instance = rn18_melnv_t1\n",
    "map_labels = instance.label_codes\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label']\n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final']\n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']\n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']\n",
    "\n",
    "txp1 = pd.crosstab(target1,prediction1,margins=True,dropna=False)\n",
    "txp_a = pd.crosstab(target_a,prediction_a,margins=True,dropna=False)\n",
    "\n",
    "beta = 2\n",
    "# Weights inversely proportional to relative class size in the training set, giving more importance to smaller classes.\n",
    "weights = 1/instance.df_train['label'].value_counts(normalize=True).sort_index().values # None\n",
    "\n",
    "instance.cm1 = confusion_matrix_with_metric(AxB=txp1,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "instance.cm_a = confusion_matrix_with_metric(AxB=txp_a,\n",
    "                                            lst=None,\n",
    "                                            full_pad=True,\n",
    "                                            func=weighted_average_f,\n",
    "                                            beta=beta,\n",
    "                                            weights=weights,\n",
    "                                            percentage=False,\n",
    "                                            map_labels=map_labels)\n",
    "\n",
    "print_header(\"Confusion matrix: validation set, one image per lesion\")\n",
    "display(instance.cm1.fillna('_'))\n",
    "\n",
    "print_header(\"Confusion matrix: validation set, all images per lesion\")\n",
    "display(instance.cm_a.fillna('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "SKGQtsaAr4Dm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "SKGQtsaAr4Dm",
    "outputId": "0955fdd9-dc1d-4a76-f7bb-da4725abac98",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================\n",
      "BASELINE MODEL: OTHER METRICS\n",
      "=============================\n",
      "\n",
      "\n",
      "ONE IMAGE PER LESION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.865781</td>\n",
       "      <td>0.790038</td>\n",
       "      <td>0.685293</td>\n",
       "      <td>0.790038</td>\n",
       "      <td>0.695423</td>\n",
       "      <td>0.718276</td>\n",
       "      <td>0.754497</td>\n",
       "      <td>0.463646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC      BACC  precision    recall      F1/2        F1        F2  \\\n",
       "0  0.865781  0.790038   0.685293  0.790038  0.695423  0.718276  0.754497   \n",
       "\n",
       "        MCC  ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0  0.463646          NaN         NaN          NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ALL IMAGES PER LESION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "      <th>BACC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1/2</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>MCC</th>\n",
       "      <th>ROC-AUC mac</th>\n",
       "      <th>ROC-AUC wt</th>\n",
       "      <th>ROC-AUC wt*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.851827</td>\n",
       "      <td>0.805279</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>0.805279</td>\n",
       "      <td>0.685433</td>\n",
       "      <td>0.710257</td>\n",
       "      <td>0.755584</td>\n",
       "      <td>0.463773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACC      BACC  precision    recall      F1/2        F1        F2  \\\n",
       "0  0.851827  0.805279   0.676139  0.805279  0.685433  0.710257  0.755584   \n",
       "\n",
       "        MCC  ROC-AUC mac  ROC-AUC wt  ROC-AUC wt*  \n",
       "0  0.463773          NaN         NaN          NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from utils import print_header\n",
    "from evaluation import metric_dictionary\n",
    "# import pandas as pd\n",
    "\n",
    "instance = rn18_melnv_t1\n",
    "\n",
    "target1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['label']\n",
    "prediction1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id')['pred_final']\n",
    "probabilities1 = instance.df_probabilities_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities1 = instance.df_pred_val1.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "\n",
    "target_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['label']\n",
    "prediction_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id')['pred_final']\n",
    "probabilities_a = instance.df_probabilities_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "agg_probabilities_a = instance.df_pred_val_a.drop_duplicates(subset='lesion_id').filter(regex=r'^prob_')\n",
    "\n",
    "beta = 2\n",
    "# Weights inversely proportional to relative class size, giving more importance to smaller classes.\n",
    "weights = 1/instance.df_train['label'].value_counts(normalize=True).sort_index().values # None\n",
    "\n",
    "print_header(\"Baseline model: other metrics\")\n",
    "\n",
    "instance.metric_dict1 = metric_dictionary(target=target1,\n",
    "                                          prediction=prediction1,\n",
    "                                          probabilities=agg_probabilities1)\n",
    "\n",
    "instance.metric_dict_a = metric_dictionary(target=target_a,\n",
    "                                          prediction=prediction_a,\n",
    "                                          probabilities=agg_probabilities_a)\n",
    "\n",
    "print(\"\\nOne image per lesion\".upper())\n",
    "display(pd.DataFrame(instance.metric_dict1))\n",
    "\n",
    "print(\"\\nAll images per lesion\".upper())\n",
    "display(pd.DataFrame(instance.metric_dict_a))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
